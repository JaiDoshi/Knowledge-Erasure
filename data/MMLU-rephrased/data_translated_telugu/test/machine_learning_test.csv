ప్రకటన 1| అన్ని నిష్పక్షపాత అంచనాదారుల మధ్య లీనియర్ రిగ్రెషన్ అంచనాదారుడికి అత్యల్ప వ్యత్యాసం ఉంటుంది. ప్రకటన 2| AdaBoost ద్వారా సమీకరించబడిన వర్గీకరణకారులకు కేటాయించబడిన గుణకాలు α ఎల్లప్పుడూ సానుకూలంగా ఉంటాయి.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",D
"ప్రకటన 1| RoBERTa, BERT ప్రీట్రైన్ చేసిన కార్పస్ కంటే దాదాపు 10 రెట్లు పెద్దదైన కార్పస్‌పై ప్రీట్రైన్ చేస్తుంది. ప్రకటన 2| 2018లో ResNeXts సాధారణంగా tanh యాక్టివేషన్ ఫంక్షన్‌లను ఉపయోగించేవి.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",C
"ప్రకటన 1| లాజిస్టిక్ రిగ్రెషన్ మోడల్స్ వలె, సపోర్ట్ వెక్టర్ మెషీన్లు ఇన్‌పుట్ ఉదాహరణ ఇచ్చినప్పుడు సాధ్యమయ్యే లేబుల్స్‌పై ప్రాబాబిలిటీ డిస్ట్రిబ్యూషన్‌ను ఇస్తాయి. ప్రకటన 2| లీనియర్ కెర్నెల్ నుండి ఉన్నత క్రమ పాలినోమియల్ కెర్నెల్స్‌కు మారినప్పుడు సాధారణంగా సపోర్ట్ వెక్టర్లు అలాగే ఉంటాయని మనం ఆశించవచ్చు.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
"ఒక మెషీన్ లెర్నింగ్ సమస్య నాలుగు లక్షణాలు మరియు ఒక వర్గాన్ని కలిగి ఉంటుంది. లక్షణాలు వరుసగా 3, 2, 2 మరియు 2 సాధ్యమైన విలువలను కలిగి ఉన్నాయి. వర్గం 3 సాధ్యమైన విలువలను కలిగి ఉంది. గరిష్టంగా ఎన్ని వేర్వేరు ఉదాహరణలు సాధ్యం?",౧౨,ఇరవై నాలుగు,౪౮,౭౨,D
"2020 నాటికి, అధిక రిజల్యూషన్ చిత్రాలను వర్గీకరించడానికి ఏ ఆర్కిటెక్చర్ ఉత్తమమైనది?",కన్వల్యూషనల్ నెట్‌వర్క్‌లు,గ్రాఫ్ నెట్‌వర్క్‌లు,పూర్తిగా అనుసంధానించబడిన నెట్‌వర్క్‌లు,ఆర్బీఎఫ్ నెట్‌వర్క్‌లు,A
"ప్రకటన 1| అంచనా గరిష్ఠీకరణ అల్గారిథమ్‌లోని వరుస పునరావృతాల ద్వారా డేటా యొక్క లాగ్-సంభావ్యత ఎల్లప్పుడూ పెరుగుతుంది.

ప్రకటన 2| Q-లెర్నింగ్ యొక్క ఒక లోపం ఏమిటంటే, నేర్చుకునేవారికి తన చర్యలు తన పరిసరాలను ఎలా ప్రభావితం చేస్తాయనే పూర్వ జ్ఞానం ఉన్నప్పుడు మాత్రమే దీనిని ఉపయోగించవచ్చు.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
మనం మన వ్యయ ఫంక్షన్ యొక్క గ్రేడియంట్‌ను లెక్కించి దానిని g అనే వెక్టర్‌లో నిల్వ చేశామని అనుకుందాం. గ్రేడియంట్ ఇవ్వబడినప్పుడు ఒక గ్రేడియంట్ డిసెంట్ అప్‌డేట్ యొక్క ఖర్చు ఎంత?,O(D),O(N),O(ND),O(ND^2),A
"ప్రకటన 1| నిరంతర యాదృచ్ఛిక చరం x మరియు దాని సంభావ్యతా పంపిణీ ప్రమేయం p(x) కోసం, అన్ని x లకు 0 ≤ p(x) ≤ 1 అని నిలుస్తుంది. ప్రకటన 2| నిర్ణయ వృక్షం సమాచార లాభాన్ని కనిష్టీకరించడం ద్వారా నేర్చుకోబడుతుంది.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
క్రింద ఇవ్వబడిన బేయెసియన్ నెట్‌వర్క్‌ను పరిగణించండి. ఈ బేయెసియన్ నెట్‌వర్క్ H -> U <- P <- W కోసం ఎన్ని స్వతంత్ర పారామితులు అవసరం?,౨,౪,౮,౧౬,C
"సాధన ఉదాహరణల సంఖ్య అనంతానికి చేరుకునే కొద్దీ, ఆ డేటాపై శిక్షణ పొందిన మీ మోడల్ కలిగి ఉంటుంది:",తక్కువ వ్యత్యాసం,అధిక వ్యత్యాసం,ఒకే విచలనం,పైవేవీ కావు,A
ప్రకటన 1| 2D తలంలోని అన్ని దీర్ఘచతురస్రాల సమితి (అక్ష-సంరేఖిత కాని దీర్ఘచతురస్రాలను కూడా కలిగి ఉంటుంది) 5 బిందువుల సమితిని ఛేదించగలదు. ప్రకటన 2| k = 1 అయినప్పుడు k-సమీప పొరుగు వర్గీకరణ యొక్క VC-పరిమాణం అనంతం.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
_ అనేది శిక్షణ డేటాను మోడల్ చేయలేని మరియు కొత్త డేటాకు సాధారణీకరించలేని మోడల్‌ను సూచిస్తుంది.,మంచి సరిపోయే,అతిసరళీకరణ,అండర్‌ఫిట్టింగ్,పైన పేర్కొన్నవన్నీ,C
"ప్రకటన 1| తరగతి అసమతుల్యత అధికంగా ఉన్న డేటాసెట్‌లకు F1 స్కోర్ ప్రత్యేకంగా ఉపయోగపడుతుంది.

ప్రకటన 2| ROC వక్రరేఖ క్రింద ఉన్న ప్రాంతం అసాధారణ నిర్ధారకాలను అంచనా వేయడానికి ఉపయోగించే ప్రధాన కొలమానాలలో ఒకటి.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"ప్రకటన 1| బ్యాక్-ప్రాపగేషన్ అల్గారిథమ్ దాగిన పొరలతో ప్రపంచవ్యాప్తంగా అనుకూలమైన న్యూరల్ నెట్‌వర్క్‌ను నేర్చుకుంటుంది.

ప్రకటన 2| ఒక రేఖ యొక్క VC కొలత గరిష్టంగా 2 ఉండాలి, ఎందుకంటే ఏ రేఖ ద్వారా చీల్చబడని 3 బిందువుల కనీసం ఒక సందర్భాన్ని నేను కనుగొనగలను.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
అధిక ఎంట్రోపీ అంటే వర్గీకరణలో విభజనలు,శుద్ధమైన,శుద్ధం కాని,ఉపయోగకరమైన,నిరుపయోగమైన,B
ప్రకటన 1| అసలు ResNet పేపర్‌లో బ్యాచ్ నార్మలైజేషన్ కాకుండా లేయర్ నార్మలైజేషన్ ఉపయోగించబడింది. ప్రకటన 2| DCGANలు శిక్షణను స్థిరీకరించడానికి స్వీయ-శ్రద్ధను ఉపయోగిస్తాయి.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
"లైనియర్ రిగ్రెషన్ మోడల్‌ను ఒక నిర్దిష్ట డేటా సెట్ కోసం నిర్మించేటప్పుడు, మీరు ఒక ఫీచర్ యొక్క గుణకం చాలా ఎక్కువ ప్రతికూల విలువను కలిగి ఉండటాన్ని గమనిస్తారు. ఇది సూచిస్తుంది",ఈ లక్షణం మోడల్‌పై బలమైన ప్రభావాన్ని కలిగి ఉంటుంది (నిలుపుకోవాలి),ఈ లక్షణం మోడల్‌పై బలమైన ప్రభావాన్ని కలిగి ఉండదు (విస్మరించబడాలి),ఈ లక్షణం యొక్క ప్రాముఖ్యత గురించి అదనపు సమాచారం లేకుండా వ్యాఖ్యానించడం సాధ్యం కాదు,ఏమీ నిర్ధారించలేము.,C
"న్యూరల్ నెట్‌వర్క్ కోసం, ఈ నిర్మాణాత్మక ఊహలలో ఏది అండర్‌ఫిట్టింగ్ (అంటే అధిక పక్షపాత మోడల్) మరియు ఓవర్‌ఫిట్టింగ్ (అంటే అధిక వ్యత్యాస మోడల్) మధ్య ట్రేడ్-ఆఫ్‌ను అత్యధికంగా ప్రభావితం చేస్తుంది:",గుప్త నోడ్‌ల సంఖ్య,అభ్యాస రేటు,ప్రారంభ బరువుల ఎంపిక,నిరంతర-పద యూనిట్ ఇన్‌పుట్ యొక్క ఉపయోగం,A
"పాలినోమియల్ రిగ్రెషన్ కోసం, ఈ నిర్మాణాత్మక ఊహలలో ఏది అండర్‌ఫిట్టింగ్ మరియు ఓవర్‌ఫిట్టింగ్ మధ్య ట్రేడ్-ఆఫ్‌ను అత్యధికంగా ప్రభావితం చేస్తుంది:",పాలినోమియల్ డిగ్రీ,మేము బరువులను మాట్రిక్స్ ఇన్వర్షన్ ద్వారా నేర్చుకున్నా లేదా గ్రేడియంట్ డిసెంట్ ద్వారా నేర్చుకున్నా,గాసియన్ శబ్దం యొక్క అనుమానిత వ్యత్యాసం,నిరంతర-పద యూనిట్ ఇన్‌పుట్ యొక్క ఉపయోగం,A
"ప్రకటన 1| 2020 నాటికి, కొన్ని మోడల్స్ CIFAR-10 పై 98% కంటే ఎక్కువ ఖచ్చితత్వాన్ని సాధించాయి. ప్రకటన 2| అసలైన ResNets లు ఆడమ్ ఆప్టిమైజర్‌తో అనుకూలీకరించబడలేదు.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
కె-మీన్స్ అల్గారిథమ్,నమూనాల సంఖ్య కంటే ఫీచర్ స్పేస్ యొక్క పరిమాణం పెద్దది కాకూడదని అవసరం,లక్ష్య ఫంక్షన్ యొక్క అతి చిన్న విలువను K = 1 అయినప్పుడు కలిగి ఉంటుంది,ఇచ్చిన సంఖ్యలో క్లస్టర్ల కోసం తరగతి లోపల వ్యత్యాసాన్ని కనిష్టీకరిస్తుంది,ప్రారంభ సగటులు నమూనాలలో కొన్నింటిని ఎంచుకున్నప్పుడు మాత్రమే ప్రపంచ అత్యుత్తమ స్థితికి అభిసరిస్తుంది,C
ప్రకటన 1| VGGNets యొక్క కన్వల్యూషనల్ కెర్నెల్స్ AlexNet యొక్క మొదటి-పొర కెర్నెల్స్ కంటే తక్కువ వెడల్పు మరియు ఎత్తు కలిగి ఉంటాయి. ప్రకటన 2| బ్యాచ్ నార్మలైజేషన్ కంటే ముందు డేటా-ఆధారిత బరువు ప్రారంభీకరణ విధానాలు ప్రవేశపెట్టబడ్డాయి.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"క్రింది మాట్రిక్స్ యొక్క ర్యాంక్ ఏమిటి? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]",౦,౧,౨,౩,B
"ప్రకటన 1| సాంద్రత అంచనా (ఉదాహరణకు, కెర్నెల్ సాంద్రత అంచనాదారుని ఉపయోగించి) వర్గీకరణను నిర్వహించడానికి ఉపయోగించవచ్చు. ప్రకటన 2| లాజిస్టిక్ రిగ్రెషన్ మరియు గాసియన్ నైవ్ బేస్ (గుర్తింపు తరగతి సహసంబంధాలతో) మధ్య సంబంధం అంటే రెండు వర్గీకరణల పరామితుల మధ్య ఒక-ఒకటి సంబంధం ఉందని అర్థం.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",C
"భౌగోళిక స్థానాలు వంటి స్థానిక డేటాపై క్లస్టరింగ్ చేయాలనుకుంటున్నామని అనుకుందాం, ఉదాహరణకు ఇళ్ల భౌగోళిక స్థానాలు. మేము అనేక వివిధ పరిమాణాలు మరియు ఆకారాల క్లస్టర్లను ఉత్పత్తి చేయాలనుకుంటున్నాము. కింది పద్ధతుల్లో ఏది అత్యంత సముచితమైనది?",నిర్ణయ వృక్షాలు,సాంద్రత-ఆధారిత క్లస్టరింగ్,మోడల్-ఆధారిత క్లస్టరింగ్,కే-మీన్స్ క్లస్టరింగ్,B
"ప్రకటన 1| AdaBoost లో తప్పుగా వర్గీకరించబడిన ఉదాహరణల యొక్క బరువులు ఒకే గుణకార కారకం ద్వారా పెరుగుతాయి. ప్రకటన 2| AdaBoost లో, t వ బలహీన వర్గీకారిణి యొక్క భారిత శిక్షణ దోషం e_t, D_t బరువులతో శిక్షణ డేటాపై t ఫంక్షన్‌గా పెరిగే ధోరణిని కలిగి ఉంటుంది.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
MLE అంచనాలు తరచుగా అవాంఛనీయమైనవి ఎందుకంటే,వారు పక్షపాతంతో ఉన్నారు,వాటికి అధిక వ్యత్యాసం ఉంది,అవి స్థిరమైన అంచనాదారులు కావు,పైవేవీ కావు,B
"గ్రేడియంట్ డిసెంట్ యొక్క కంప్యూటేషనల్ సంక్లిష్టత,",డి లో రేఖీయం,N కి రేఖీయంగా,D లో బహుపదం,ఇటరేషన్ల సంఖ్యపై ఆధారపడి,C
అనేక నిర్ణయ వృక్షాల యొక్క ఫలితాలను సగటు చేయడం _ కి సహాయపడుతుంది.,పక్షపాతాన్ని పెంచండి,పక్షపాతాన్ని తగ్గించండి,వైవిధ్యాన్ని పెంచండి,వ్యత్యాసాన్ని తగ్గించండి,D
"లైనియర్ రిగ్రెషన్‌ను గుర్తించిన ఉప సమితి లక్షణాలపై వర్తింపజేయడం ద్వారా పొందిన మోడల్, ఉప సమితిని గుర్తించే ప్రక్రియ ముగిసిన తర్వాత పొందిన మోడల్ నుండి భిన్నంగా ఉండవచ్చు",ఉత్తమ-ఉపసమితి ఎంపిక,ముందుకు దశలవారీ ఎంపిక,ఫార్వర్డ్ స్టేజ్ వైజ్ సెలెక్షన్,పైన పేర్కొన్నవన్నీ,C
న్యూరల్ నెట్‌వర్క్‌లు,సంవృత లక్ష్య ప్రమేయాన్ని అనుకూలీకరించండి,స్టోకాస్టిక్ గ్రేడియంట్ డిసెంట్‌తో మాత్రమే శిక్షణ పొందగలదు,వివిధ యాక్టివేషన్ ఫంక్షన్‌ల మిశ్రమాన్ని ఉపయోగించవచ్చు,పైవేవీ కావు,C
"వ్యాధి D యొక్క సంభవనీయత 100 మందిలో సుమారు 5 కేసులు (అంటే, P(D) = 0.05). బూలియన్ యాదృచ్ఛిక చరరాశి D అంటే రోగి ""వ్యాధి D కలిగి ఉన్నాడు"" మరియు బూలియన్ యాదృచ్ఛిక చరరాశి TP అంటే ""పాజిటివ్ పరీక్ష"". వ్యాధి D కోసం పరీక్షలు చాలా ఖచ్చితమైనవిగా తెలుసు, ఎందుకంటే మీకు వ్యాధి ఉన్నప్పుడు పాజిటివ్ పరీక్ష చేయించుకునే సంభావ్యత 0.99, మరియు మీకు వ్యాధి లేనప్పుడు నెగటివ్ పరీక్ష చేయించుకునే సంభావ్యత 0.97. P(TP), పాజిటివ్ పరీక్ష చేయించుకునే పూర్వ సంభావ్యత ఏమిటి.",0.0368,0.473,0.078,పైవేవీ కావు,C
"ప్రకటన 1| రేడియల్ బేసిస్ కెర్నెల్ ఫంక్షన్ ద్వారా ఫీచర్ స్పేస్ Q లోకి మ్యాప్ చేయబడిన తర్వాత, భారం లేని యూక్లిడియన్ దూరాన్ని ఉపయోగించే 1-NN అసలు స్థలంలో కంటే మెరుగైన వర్గీకరణ ప్రదర్శనను సాధించగలదు (అయితే మనం దీనిని గ్యారంటీ చేయలేము). ప్రకటన 2| ఒక పెర్సెప్ట్రాన్ యొక్క VC పరిమాణం సాధారణ లీనియర్ SVM యొక్క VC పరిమాణం కంటే చిన్నది.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
గ్రిడ్ శోధన యొక్క ప్రతికూలత,దీన్ని భేదించలేని ప్రమేయాలకు వర్తింపజేయలేము.,అది అవిచ్ఛిన్న కాని ప్రమేయాలకు వర్తించదు.,అమలు చేయడం కష్టం.,అది బహుళ రేఖీయ ప్రతిగమనం కోసం సహేతుకంగా నెమ్మదిగా నడుస్తుంది.,D
ఒక ప్రాంతంలో వివిధ సూచనల ఆధారంగా వర్షపాతం మొత్తాన్ని అంచనా వేయడం ఒక ______ సమస్య.,పర్యవేక్షిత అభ్యాసం,పర్యవేక్షణ రహిత అభ్యాసం,క్లస్టరింగ్,పైవేవీ కావు,A
క్రింది వాక్యాలలో రిగ్రెషన్‌కు సంబంధించి ఏది తప్పు?,ఇది ఇన్‌పుట్‌లను అవుట్‌పుట్‌లతో సంబంధం కలిగి ఉంటుంది.,ఇది భవిష్యవాణి కోసం ఉపయోగించబడుతుంది.,ఇది వ్యాఖ్యానం కోసం ఉపయోగించబడవచ్చు.,ఇది కారణ సంబంధాలను కనుగొంటుంది,D
కింది వాటిలో ఏది నిర్ణయ వృక్షాన్ని కత్తిరించడానికి ప్రధాన కారణం?,పరీక్షల సమయంలో కంప్యూటింగ్ సమయాన్ని ఆదా చేయడానికి,నిర్ణయ వృక్షాన్ని నిల్వ చేయడానికి స్థలాన్ని ఆదా చేయడానికి,శిక్షణ సమితి లోపాన్ని చిన్నదిగా చేయడానికి,అధిక అనుసరణను నివారించడానికి శిక్షణా సమితిని,D
"ప్రకటన 1| కెర్నెల్ సాంద్రత అంచనాదారు అనేది మూల డేటా సెట్‌లోని ప్రతి బిందువు Xi వద్ద Yi = 1/n విలువతో కెర్నెల్ రిగ్రెషన్ నిర్వహించడానికి సమానం.

ప్రకటన 2| నేర్చుకున్న నిర్ణయ వృక్షం యొక్క లోతు, వృక్షాన్ని సృష్టించడానికి ఉపయోగించిన శిక్షణ ఉదాహరణల సంఖ్య కంటే ఎక్కువగా ఉండవచ్చు.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
మీ మోడల్ ఓవర్‌ఫిట్టింగ్ అవుతోందని అనుకోండి. కింది వాటిలో ఓవర్‌ఫిట్టింగ్‌ను తగ్గించడానికి ప్రయత్నించడానికి చెల్లని మార్గం ఏది?,శిక్షణా డేటా మొత్తాన్ని పెంచండి.,దోష న్యూనీకరణ కోసం ఉపయోగించబడుతున్న అనుకూలీకరణ అల్గారిథమ్‌ను మెరుగుపరచండి.,మోడల్ సంక్లిష్టతను తగ్గించండి.,శిక్షణ డేటాలో శబ్దాన్ని తగ్గించండి.,B
ప్రకటన 1| బహుళ-తరగతి లాజిస్టిక్ రిగ్రెషన్‌లో సాఫ్ట్‌మాక్స్ ఫంక్షన్ సాధారణంగా ఉపయోగించబడుతుంది. ప్రకటన 2| అసమాన సాఫ్ట్‌మాక్స్ పంపిణీ యొక్క ఉష్ణోగ్రత దాని ఎంట్రోపీని ప్రభావితం చేస్తుంది.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
క్రింది వాటిలో ఏది/ఏవి SVM కి సంబంధించి నిజమైనవి?,"రెండు పరిమాణాల డేటా పాయింట్ల కోసం, లీనియర్ SVM ద్వారా నేర్చుకున్న విభజన హైపర్‌ప్లేన్ ఒక సరళ రేఖ అవుతుంది.","సిద్ధాంతంలో, గాసియన్ కెర్నెల్ SVM ఏదైనా సంక్లిష్టమైన విభజన హైపర్‌ప్లేన్‌ను మోడల్ చేయలేదు.","ప్రతి SVM లో ఉపయోగించే కెర్నెల్ ఫంక్షన్ కోసం, సమానమైన మూసివేసిన రూప ఆధార విస్తరణను పొందవచ్చు.",ఒక SVM లో అతిసరిపోవడం మద్దతు వెక్టర్ల సంఖ్యకు సంబంధించిన ప్రమేయం కాదు.,A
"ఇచ్చిన బేయెసియన్ నెట్‌వర్క్ H -> U <- P <- W ద్వారా వివరించబడిన H, U, P మరియు W యొక్క సంయుక్త సంభావ్యత కింది వాటిలో ఏది? [గమనిక: షరతులతో కూడిన సంభావ్యతల లబ్ధంగా]","P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)",పైవేవీ కావు,C
"ప్రకటన 1| రేడియల్ బేస్ కెర్నెల్‌తో SVM యొక్క VC పరిమాణం అనంతమైనది కాబట్టి, అటువంటి SVM పరిమిత VC పరిమాణం కలిగిన పాలినోమియల్ కెర్నెల్‌తో SVM కంటే చెడ్డది అయి ఉండాలి.

ప్రకటన 2| లీనియర్ యాక్టివేషన్ ఫంక్షన్‌లతో రెండు పొరల న్యూరల్ నెట్‌వర్క్ అనేది ఇచ్చిన డేటాసెట్‌పై శిక్షణ పొందిన లీనియర్ సెపరేటర్‌ల భారిత సంయోగం; లీనియర్ సెపరేటర్‌లపై నిర్మించిన బూస్టింగ్ అల్గారిథమ్ కూడా లీనియర్ సెపరేటర్‌ల సంయోగాన్ని కనుగొంటుంది, కాబట్టి ఈ రెండు అల్గారిథమ్‌లు ఒకే ఫలితాన్ని ఇస్తాయి.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
"ప్రకటన 1| ID3 అల్గారిథమ్ అత్యుత్తమ నిర్ణయ వృక్షాన్ని కనుగొనడానికి హామీ ఇస్తుంది.

ప్రకటన 2| ప్రతిచోటా సున్నా కాని సాంద్రత f() తో నిరంతర సంభావ్యతా పంపిణీని పరిగణించండి. x విలువ యొక్క సంభావ్యత f(x) కి సమానం.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
"ఎన్ ఇన్‌పుట్ నోడ్‌లు, దాగిన పొరలు లేకుండా, ఒక అవుట్‌పుట్ నోడ్‌తో, ఎంట్రోపీ నష్టం మరియు సిగ్మాయిడ్ యాక్టివేషన్ ఫంక్షన్‌లతో కూడిన న్యూరల్ నెట్‌ను ఇచ్చినప్పుడు, కింది అల్గారిథమ్‌లలో ఏవి (సరైన హైపర్-పారామీటర్లు మరియు ప్రారంభీకరణతో) ప్రపంచ ఆప్టిమమ్‌ను కనుగొనడానికి ఉపయోగించవచ్చు?",స్టోకాస్టిక్ గ్రేడియెంట్ డిసెంట్,మినీ-బ్యాచ్ గ్రేడియంట్ డిసెంట్,బ్యాచ్ గ్రేడియంట్ డిసెంట్,పైన పేర్కొన్నవన్నీ,D
"లీనియర్ మోడల్‌లో మరిన్ని బేసిస్ ఫంక్షన్లను జోడించడం, అత్యంత సంభావ్య ఎంపికను ఎంచుకోండి:",మోడల్ పక్షపాతాన్ని తగ్గిస్తుంది,అంచనా పక్షపాతాన్ని తగ్గిస్తుంది,వ్యత్యాసాన్ని తగ్గిస్తుంది,బయాస్ మరియు వేరియన్స్‌ను ప్రభావితం చేయదు,A
క్రింద ఇవ్వబడిన బేయెసియన్ నెట్‌వర్క్‌ను పరిగణించండి. స్వతంత్రత లేదా షరతులతో కూడిన స్వతంత్రత గురించి ఎలాంటి అనుమానాలు చేయకపోతే మనకు ఎన్ని స్వతంత్ర పారామీటర్లు అవసరమవుతాయి H -> U <- P <- W?,౩,౪,౭,౧౫,D
మరొక పదం అవుట్-ఆఫ్-డిస్ట్రిబ్యూషన్ డిటెక్షన్ కోసం ఏమిటి?,అసాధారణ గుర్తింపు,ఒకే-తరగతి గుర్తింపు,ట్రైన్-టెస్ట్ అసమానత స్థిరత్వం,నేపథ్య గుర్తింపు,A
"ప్రకటన 1| బలహీన అభ్యాసకులను h బూస్ట్ చేయడం ద్వారా మేము ఒక వర్గీకరణ f ను నేర్చుకుంటాము. f యొక్క నిర్ణయ సరిహద్దు యొక్క క్రియాత్మక రూపం h తో సమానంగా ఉంటుంది, కానీ వేరే పారామితులతో. (ఉదా., h ఒక రేఖీయ వర్గీకరణ అయితే, అప్పుడు f కూడా ఒక రేఖీయ వర్గీకరణ).

ప్రకటన 2| బూస్టింగ్‌లో పునరావృత్తుల సంఖ్యను ఎంచుకోవడానికి క్రాస్ వాలిడేషన్ ఉపయోగించవచ్చు; ఈ విధానం అతిసర్దుబాటును తగ్గించడంలో సహాయపడవచ్చు.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",D
ప్రకటన 1| హైవే నెట్‌వర్క్‌లు రెస్‌నెట్‌ల తర్వాత పరిచయం చేయబడ్డాయి మరియు గరిష్ట పూలింగ్ బదులుగా కన్వల్యూషన్‌లను ఉపయోగిస్తాయి. ప్రకటన 2| డెన్స్‌నెట్‌లు సాధారణంగా రెస్‌నెట్‌ల కంటే ఎక్కువ మెమరీని ఖర్చు చేస్తాయి.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",D
"N అనేది శిక్షణ డేటాసెట్‌లోని ఉదాహరణల సంఖ్య అయితే, సమీప పొరుగువారు వర్గీకరణ రన్‌టైమ్‌ను కలిగి ఉంటారు",O(1),O( N ),O(log N ),O( N^2 ),B
"ప్రకటన 1| అసలైన ResNets మరియు ట్రాన్స్‌ఫార్మర్లు ఫీడ్‌ఫార్వర్డ్ న్యూరల్ నెట్‌వర్క్‌లు.

ప్రకటన 2| అసలైన ట్రాన్స్‌ఫార్మర్లు స్వీయ-అవధానాన్ని ఉపయోగిస్తాయి, కానీ అసలైన ResNet అలా చేయదు.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"ప్రకటన 1| RELUలు మోనోటోనిక్ కావు, కానీ సిగ్మాయిడ్‌లు మోనోటోనిక్. ప్రకటన 2| అధిక సంభావ్యతతో గ్రేడియంట్ డిసెంట్‌తో శిక్షణ పొందిన న్యూరల్ నెట్‌వర్క్‌లు గ్లోబల్ ఆప్టిమమ్‌కు అభిసరిస్తాయి.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",D
న్యూరల్ నెట్‌వర్క్‌లోని సిగ్మాయిడ్ నోడ్ యొక్క సంఖ్యాత్మక ఫలితం:,"అపరిమితమైనది, అన్ని వాస్తవిక సంఖ్యలను కలిగి ఉంటుంది.","అపరిమితమైనది, అన్ని పూర్ణాంకాలను కలిగి ఉంటుంది.",0 మరియు 1 మధ్య పరిమితమై ఉంటుంది.,-1 మరియు 1 మధ్య పరిమితమై ఉంటుంది.,C
క్రింది వాటిలో దేనిని కేవలం శిక్షణ డేటా రేఖీయంగా వేరుచేయదగినవి అయినప్పుడు మాత్రమే ఉపయోగించవచ్చు?,లైనియర్ హార్డ్-మార్జిన్ SVM,లైనియర్ లాజిస్టిక్ రిగ్రెషన్,లీనియర్ సాఫ్ట్ మార్జిన్ ఎస్‌వీఎమ్,కేంద్రక పద్ధతి.,A
క్రింది వాటిలో ఏవి స్థానిక క్లస్టరింగ్ అల్గారిథమ్‌లు?,విభజన ఆధారిత క్లస్టరింగ్,కే-మీన్స్ క్లస్టరింగ్,గ్రిడ్ ఆధారిత క్లస్టరింగ్,పైన పేర్కొన్నవన్నీ,D
ప్రకటన 1| సపోర్ట్ వెక్టర్ మెషీన్‌లు నిర్మించే గరిష్ట మార్జిన్ నిర్ణయ సరిహద్దులు అన్ని లీనియర్ క్లాసిఫయర్ల మధ్య అత్యల్ప జనరలైజేషన్ లోపాన్ని కలిగి ఉంటాయి. ప్రకటన 2| క్లాస్-కండిషనల్ గాసియన్ పంపిణీలతో జెనరేటివ్ మోడల్ నుండి మనం పొందే ఏ నిర్ణయ సరిహద్దు అయినా సూత్రప్రకారంగా మూడు లేదా అంతకంటే తక్కువ డిగ్రీ కలిగిన పాలినోమియల్ కెర్నెల్‌తో SVM ద్వారా పునరుత్పత్తి చేయబడవచ్చు.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",D
"ప్రకటన 1| లీనియర్ మోడల్స్ యొక్క L2 రెగ్యులరైజేషన్, L1 రెగ్యులరైజేషన్ కంటే మోడల్స్‌ను మరింత స్పార్స్‌గా చేస్తుంది.

ప్రకటన 2| రెసిడ్యువల్ కనెక్షన్లు రెస్‌నెట్స్ మరియు ట్రాన్స్‌ఫార్మర్స్‌లో కనుగొనబడతాయి.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",D
"అనుకోండి మనం P(H|E, F) ని లెక్కించాలనుకుంటున్నాం మరియు మనకు షరతుల స్వాతంత్ర్య సమాచారం లేదు. కింది సంఖ్యల సమితుల్లో ఏది లెక్కింపుకు సరిపోతుంది?","P(E, F), P(H), P(E|H), P(F|H)","P(E, F), P(H), P(E, F|H)","P(H), P(E|H), P(F|H)","P(E, F), P(E|H), P(F|H)",B
క్రింది వాటిలో ఏది బ్యాగింగ్ చేసేటప్పుడు అతిసరళీకరణను నివారిస్తుంది?,నమూనా పద్ధతిగా ప్రతిస్థాపనతో కూడిన నమూనాకరణ ఉపయోగం,బలహీన వర్గీకరణకారుల ఉపయోగం,అతిసరళీకరణకు గురికాని వర్గీకరణ అల్గారిథమ్‌ల ఉపయోగం,ప్రతి శిక్షణ పొందిన వర్గీకరణ పై నిర్వహించబడే ధృవీకరణ అభ్యాసం,B
"ప్రకటన 1| PCA మరియు స్పెక్ట్రల్ క్లస్టరింగ్ (ఆండ్రూ ఎన్జి వంటివి) రెండు వేర్వేరు మాట్రిక్స్‌లపై ఐగెన్ డీకంపోజిషన్‌ను నిర్వహిస్తాయి. అయితే, ఈ రెండు మాట్రిక్స్‌ల పరిమాణం ఒకేలా ఉంటుంది. ప్రకటన 2| వర్గీకరణ అనేది రిగ్రెషన్‌కు ప్రత్యేక సందర్భం కాబట్టి, లాజిస్టిక్ రిగ్రెషన్ అనేది లీనియర్ రిగ్రెషన్‌కు ప్రత్యేక సందర్భం.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
ప్రకటన 1| స్టాన్‌ఫోర్డ్ సెంటిమెంట్ ట్రీబ్యాంక్‌లో పుస్తక సమీక్షలు కాకుండా చలనచిత్ర సమీక్షలు ఉన్నాయి. ప్రకటన 2| పెన్ ట్రీబ్యాంక్‌ను భాషా మోడలింగ్ కోసం ఉపయోగించారు.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"కింది మాట్రిక్స్ యొక్క శూన్య స్థలం యొక్క పరిమాణం ఎంత? A = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]]",౦,౧,౨,౩,C
సపోర్ట్ వెక్టర్లు అంటే ఏమిటి?,నిర్ణయ సరిహద్దు నుండి అత్యంత దూరంగా ఉన్న ఉదాహరణలు.,SVM లో f(x) ని లెక్కించడానికి అవసరమైన ఏకైక ఉదాహరణలు.,డేటా కేంద్రకం.,SVM లో సున్నా కాని బరువు αk కలిగిన అన్ని ఉదాహరణలు.,B
ప్రకటన 1| వర్డ్2వెక్ పారామీటర్లు రెస్ట్రిక్టెడ్ బోల్ట్జ్‌మాన్ మెషీన్‌ని ఉపయోగించి ప్రారంభించబడలేదు. ప్రకటన 2| tanh ఫంక్షన్ ఒక నాన్‌లీనియర్ యాక్టివేషన్ ఫంక్షన్.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"మీ శిక్షణ నష్టం యుగాల సంఖ్యతో పెరిగితే, అభ్యాస ప్రక్రియలో కింది వాటిలో ఏది సంభావ్య సమస్య కావచ్చు?",రెగ్యులరైజేషన్ చాలా తక్కువగా ఉంది మరియు మోడల్ ఓవర్‌ఫిట్టింగ్ అవుతోంది,రెగ్యులరైజేషన్ చాలా ఎక్కువగా ఉంది మరియు మోడల్ అండర్‌ఫిట్టింగ్ అవుతోంది,అడుగు పరిమాణం చాలా పెద్దది,అడుగు పరిమాణం చాలా చిన్నది,C
"వ్యాధి D యొక్క సంభవనీయత సుమారు 100 మందిలో 5 కేసులు (అంటే, P(D) = 0.05). బూలియన్ యాదృచ్ఛిక చరం D అంటే రోగి ""వ్యాధి D కలిగి ఉన్నాడు"" అని అర్థం మరియు బూలియన్ యాదృచ్ఛిక చరం TP అంటే ""సానుకూలంగా పరీక్షించబడింది"" అని అర్థం. వ్యాధి D కోసం పరీక్షలు చాలా ఖచ్చితమైనవిగా తెలుసు, అంటే మీకు వ్యాధి ఉన్నప్పుడు సానుకూలంగా పరీక్షించబడే సంభావ్యత 0.99, మరియు మీకు వ్యాధి లేనప్పుడు ప్రతికూలంగా పరీక్షించబడే సంభావ్యత 0.97. పరీక్ష సానుకూలంగా ఉన్నప్పుడు మీకు వ్యాధి D ఉండే పోస్టీరియర్ సంభావ్యత అయిన P(D | TP) ఎంత?",0.0495,0.078,0.635,0.97,C
"ప్రకటన 1| సాంప్రదాయ మెషీన్ లెర్నింగ్ ఫలితాలు శిక్షణ మరియు పరీక్షా సెట్లు స్వతంత్రంగా మరియు అదే విధంగా పంపిణీ చేయబడతాయని అనుకుంటాయి. ప్రకటన 2| 2017లో, COCO మోడల్‌లు సాధారణంగా ImageNetపై ముందుగా శిక్షణ పొందేవి.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"ప్రకటన 1| ఒకే శిక్షణ సమితిపై రెండు వేర్వేరు కెర్నెల్స్ K1(x, x0) మరియు K2(x, x0) ద్వారా పొందిన మార్జిన్ల విలువలు, పరీక్షా సమితిపై ఏ వర్గీకరణి మెరుగ్గా పనిచేస్తుందో మనకు తెలియజేయవు. ప్రకటన 2| BERT యొక్క యాక్టివేషన్ ఫంక్షన్ GELU.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
క్రింది వాటిలో ఏది మెషీన్ లెర్నింగ్‌లో క్లస్టరింగ్ అల్గారిథమ్?,అంచనా గరిష్ఠీకరణ,కార్ట్,గాసియన్ నైవ్ బేయెస్,అప్రియోరి,A
"మీరు స్పామ్ వర్గీకరణ కోసం నిర్ణయ వృక్షాన్ని శిక్షణ ఇవ్వడం పూర్తి చేశారు, మరియు ఇది మీ శిక్షణ మరియు పరీక్ష సెట్‌లలో రెండింటిలోనూ అసాధారణంగా చెడ్డ పనితీరును పొందుతోంది. మీ అమలు లో ఎలాంటి లోపాలు లేవని మీకు తెలుసు, కాబట్టి సమస్యకు కారణం ఏమై ఉండవచ్చు?",మీ నిర్ణయ వృక్షాలు చాలా పైపైన ఉన్నాయి.,మీరు అభ్యాస రేటును పెంచాలి.,మీరు అతిగా అనుకూలీకరిస్తున్నారు.,పైవేవీ కావు.,A
K-ఫోల్డ్ క్రాస్-వాలిడేషన్ అనేది,K కి రేఖీయం,K లో వర్గాత్మకం,క్యూబిక్ లో K,K లో ఘాతాంకం,A
ప్రకటన 1| పారిశ్రామిక-స్థాయి న్యూరల్ నెట్‌వర్క్‌లు సాధారణంగా GPUలపై కాకుండా CPUలపై శిక్షణ పొందుతాయి. ప్రకటన 2| ResNet-50 మోడల్‌లో 1 బిలియన్ కంటే ఎక్కువ పారామితులు ఉన్నాయి.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
"రెండు బూలియన్ యాదృచ్ఛిక చరాలు, A మరియు B ఇవ్వబడినప్పుడు, ఇక్కడ P(A) = 1/2, P(B) = 1/3, మరియు P(A | ¬B) = 1/4, అయితే P(A | B) ఎంత?",౧/౬,౧/౪,3/4,౧,D
ఏఐ వల్ల కలిగే ఉనికి సంబంధిత ప్రమాదాలు సాధారణంగా కింది ప్రొఫెసర్లలో ఎవరితో అత్యధికంగా సంబంధం కలిగి ఉంటాయి?,నాండో డి ఫ్రీటాస్,యాన్ లెకున్,స్టువర్ట్ రస్సెల్,జితేంద్ర మాలిక్,C
"ప్రకటన 1| లాజిస్టిక్ రిగ్రెషన్ మోడల్ యొక్క సంభావ్యతను గరిష్టీకరించడం వలన అనేక స్థానిక గరిష్ట విలువలు ఏర్పడతాయి. ప్రకటన 2| డేటా యొక్క పంపిణీ తెలిసి ఉంటే, నైవ్ బేస్ క్లాసిఫైయర్ కంటే మెరుగైన పనితీరును ఏ క్లాసిఫైయర్ కూడా చూపించలేదు.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
"కెర్నెల్ రిగ్రెషన్ కోసం, ఈ నిర్మాణాత్మక ఊహలలో ఏది అండర్‌ఫిట్టింగ్ మరియు ఓవర్‌ఫిట్టింగ్ మధ్య ట్రేడ్-ఆఫ్‌ను అత్యధికంగా ప్రభావితం చేస్తుంది:",కెర్నెల్ ఫంక్షన్ గాసియన్ లేదా త్రికోణాకార లేదా పెట్టె ఆకారంలో ఉందో లేదో,మనం యూక్లిడియన్ మెట్రిక్స్ వర్సెస్ L1 మెట్రిక్స్ వర్సెస్ L∞ మెట్రిక్స్ ఉపయోగించినా,కెర్నెల్ వెడల్పు,కెర్నెల్ ఫంక్షన్ యొక్క గరిష్ట ఎత్తు,C
"ప్రకటన 1| SVM అభ్యాస అల్గారిథమ్ దాని వస్తు ఫంక్షన్‌కు సంబంధించి ప్రపంచవ్యాప్తంగా అత్యుత్తమ పరికల్పనను కనుగొనడానికి హామీ ఇస్తుంది.

ప్రకటన 2| రేడియల్ బేసిస్ కెర్నెల్ ఫంక్షన్ ద్వారా ఫీచర్ స్పేస్ Q లోకి మ్యాప్ చేయబడిన తర్వాత, ఒక పెర్సెప్ట్రాన్ దాని అసలు స్థలం కంటే మెరుగైన వర్గీకరణ పనితీరును సాధించగలదు (అయితే మనం దీనికి హామీ ఇవ్వలేము).","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"గాసియన్ బేస్ క్లాసిఫైయర్ కోసం, అండర్‌ఫిట్టింగ్ మరియు ఓవర్‌ఫిట్టింగ్ మధ్య ట్రేడ్-ఆఫ్‌ను అత్యధికంగా ప్రభావితం చేసే నిర్మాణాత్మక ఊహ వీటిలో ఏది:",మేము తరగతి కేంద్రాలను గరిష్ట సంభావ్యత లేదా గ్రేడియంట్ డిసెంట్ ద్వారా నేర్చుకున్నా,మనం పూర్తి తరగతి సహ వ్యత్యాస మాట్రిక్స్‌లను లేదా విభాజిత తరగతి సహ వ్యత్యాస మాట్రిక్స్‌లను ఊహించినా,సమాన తరగతి పూర్వాలు లేదా డేటా నుండి అంచనా వేసిన పూర్వాలు మనకు ఉన్నాయో లేదో.,క్లాసులు వేర్వేరు మీన్ వెక్టర్లను కలిగి ఉండటానికి మనం అనుమతిస్తామా లేదా అవి ఒకే మీన్ వెక్టర్‌ను పంచుకోవడానికి బలవంతం చేస్తామా,B
"ప్రకటన 1| శిక్షణ డేటా సెట్ చిన్నదిగా ఉన్నప్పుడు అతిసర్దుబాటు సంభవించే అవకాశం ఎక్కువ.
ప్రకటన 2| పరికల్పన స్థలం చిన్నదిగా ఉన్నప్పుడు అతిసర్దుబాటు సంభవించే అవకాశం ఎక్కువ.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",D
"ప్రకటన 1| EM కాకుండా, గాసియన్ మిశ్రమ మోడల్‌పై అనుమానం లేదా అభ్యాసం చేయడానికి గ్రేడియంట్ డిసెంట్‌ను ఉపయోగించవచ్చు. ప్రకటన 2 | స్థిరమైన సంఖ్యలో లక్షణాలను అనుకుంటే, డేటాసెట్‌లోని రికార్డుల సంఖ్యకు రేఖీయంగా సమయంలో గాసియన్ ఆధారిత బేస్ ఆప్టిమల్ క్లాసిఫైయర్‌ను నేర్చుకోవచ్చు.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"ప్రకటన 1| బేయేసియన్ నెట్‌వర్క్‌లో, జంక్షన్ ట్రీ అల్గారిథమ్ యొక్క అనుమాన ఫలితాలు వేరియబుల్ ఎలిమినేషన్ యొక్క అనుమాన ఫలితాలతో సమానంగా ఉంటాయి. ప్రకటన 2| ఒక యాదృచ్ఛిక చరం Z ఇవ్వబడినప్పుడు రెండు యాదృచ్ఛిక చరాలు X మరియు Y షరతులతో కూడిన స్వతంత్రమైనవి అయితే, సంబంధిత బేయేసియన్ నెట్‌వర్క్‌లో, X మరియు Y కోసం నోడ్‌లు Z ఇవ్వబడినప్పుడు d-వేరు చేయబడతాయి.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",C
"హృద్రోగంతో బాధపడుతున్న రోగుల నుండి పెద్ద మొత్తంలో వైద్య రికార్డుల డేటాసెట్ ఇవ్వబడినప్పుడు, అటువంటి రోగుల వేర్వేరు క్లస్టర్లు ఉండవచ్చో లేదో తెలుసుకోవడానికి ప్రయత్నించండి, వాటికి మేము ప్రత్యేక చికిత్సలను అనుకూలీకరించవచ్చు. ఇది ఎలాంటి అభ్యాస సమస్య?",పర్యవేక్షిత అభ్యాసం,పర్యవేక్షణ రహిత అభ్యాసం,(ఎ) మరియు (బి) రెండూ,ఎ) కాదు బి) కాదు,B
పిసిఏలో ఎస్వీడీ లాంటి ప్రొజెక్షన్ పొందడానికి మీరు ఏమి చేస్తారు?,డేటాను సున్న సగటుకు మార్చండి,డేటాను సున్న మధ్యస్థానికి మార్చండి,సాధ్యం కాదు,వీటిలో ఏదీ కాదు,A
"ప్రకటన 1| 1-సమీప పొరుగు వర్గీకరణ యొక్క శిక్షణ దోషం 0.

ప్రకటన 2| డేటా పాయింట్ల సంఖ్య అనంతానికి పెరిగినప్పుడు, అన్ని సాధ్యమైన పూర్వానుమానాల కోసం MAP అంచనా MLE అంచనాను సమీపిస్తుంది. మరోవిధంగా చెప్పాలంటే, తగినంత డేటా ఉన్నప్పుడు, పూర్వానుమానం ఎంపిక అప్రస్తుతం.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",C
"లీస్ట్-స్క్వేర్స్ రిగ్రెషన్‌ను రెగ్యులరైజేషన్‌తో చేసేటప్పుడు (ఆప్టిమైజేషన్ ఖచ్చితంగా చేయగలిగినట్లు భావిస్తే), రెగ్యులరైజేషన్ పారామీటర్ λ విలువను పెంచడం వలన పరీక్షా దోషం.",ఎప్పటికీ శిక్షణ లోపాన్ని తగ్గించదు.,ఎప్పటికీ శిక్షణ లోపాన్ని పెంచదు.,ఎప్పటికీ పరీక్షా దోషాన్ని తగ్గించదు.,ఎప్పటికీ పెరగదు,A
క్రింది వాటిలో ఏది వివక్షాత్మక విధానాలు మోడల్ చేయడానికి ప్రయత్నించే దానిని ఉత్తమంగా వర్ణిస్తుంది? (w మోడల్‌లోని పారామీటర్లు),"p(y|x, w)","p(y, x)","p(w|x, w)",పైవేవీ కావు,A
ప్రకటన 1| కన్వల్యూషన్ న్యూరల్ నెట్‌వర్క్‌ల కోసం CIFAR-10 వర్గీకరణ పనితీరు 95% కంటే ఎక్కువ ఉండవచ్చు. ప్రకటన 2| న్యూరల్ నెట్‌వర్క్‌ల సమితులు వర్గీకరణ ఖచ్చితత్వాన్ని మెరుగుపరచవు ఎందుకంటే అవి నేర్చుకునే ప్రాతినిధ్యాలు అధిక సహసంబంధం కలిగి ఉంటాయి.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",C
క్రింది వాటిలో ఏ అంశాలపై బేయేసియన్లు మరియు ఫ్రీక్వెంటిస్ట్‌లు విభేదించవచ్చు?,గాసియన్ కాని శబ్ద నమూనాను ప్రాబాబిలిస్టిక్ రిగ్రెషన్‌లో ఉపయోగించడం.,ప్రతిగమన కోసం సంభావ్య నమూనాకరణ ఉపయోగం.,ప్రాబాబిలిస్టిక్ మోడల్‌లోని పారామీటర్లపై పూర్వ పంపిణీల ఉపయోగం.,గాసియన్ డిస్క్రిమినెంట్ అనాలిసిస్‌లో క్లాస్ ప్రయర్స్ ఉపయోగం.,C
"ప్రకటన 1| BLEU మెట్రిక్ ప్రిసిషన్‌ను ఉపయోగిస్తుంది, అయితే ROGUE మెట్రిక్ రీకాల్‌ను ఉపయోగిస్తుంది. ప్రకటన 2| ఇంగ్లీష్ వాక్యాలను మోడల్ చేయడానికి హిడెన్ మార్కోవ్ మోడల్స్ తరచుగా ఉపయోగించబడేవి.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
ప్రకటన 1| ImageNet వివిధ రిజల్యూషన్ల చిత్రాలను కలిగి ఉంది. ప్రకటన 2| Caltech-101 ImageNet కంటే ఎక్కువ చిత్రాలను కలిగి ఉంది.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",C
క్రింది వాటిలో ఏది ఫీచర్ సెలెక్షన్ చేయడానికి మరింత సముచితమైనది?,రిడ్జ్,లాసో,(ఎ) మరియు (బి) రెండూ,(ఎ) కాదు మరియు (బి) కాదు,B
అనుకోండి మీకు సుప్త చరాశులతో కూడిన మోడల్ కోసం గరిష్ట సంభావ్యత అంచనాలను కనుగొనే EM అల్గారిథమ్ ఇవ్వబడింది. దానికి బదులుగా MAP అంచనాలను కనుగొనేలా అల్గారిథమ్‌ను సవరించమని మిమ్మల్ని అడిగారు. మీరు ఏ దశ లేదా దశలను సవరించాలి?,ఆశ,గరిష్ఠీకరణ,మార్పు అవసరం లేదు,రెండూ,B
"గాసియన్ బేస్ క్లాసిఫైయర్ కోసం, అండర్‌ఫిట్టింగ్ మరియు ఓవర్‌ఫిట్టింగ్ మధ్య ట్రేడ్-ఆఫ్‌ను అత్యధికంగా ప్రభావితం చేసే నిర్మాణాత్మక ఊహ వీటిలో ఏది:",మేము తరగతి కేంద్రాలను గరిష్ట సంభావ్యత లేదా గ్రేడియంట్ డిసెంట్ ద్వారా నేర్చుకున్నా,మనం పూర్తి తరగతి సహ వ్యత్యాస మాట్రిక్స్‌లను లేదా విభాజిత తరగతి సహ వ్యత్యాస మాట్రిక్స్‌లను ఊహించినా,సమాన తరగతి పూర్వాలు లేదా డేటా నుండి అంచనా వేసిన పూర్వాలు మనకు ఉన్నాయో లేదో,క్లాసులు వేర్వేరు మీన్ వెక్టర్లను కలిగి ఉండటానికి మనం అనుమతిస్తామా లేదా అవి ఒకే మీన్ వెక్టర్‌ను పంచుకోవడానికి బలవంతం చేస్తామా,B
"ప్రకటన 1| ఏవైనా రెండు చరాశులు x మరియు y సంయుక్త వితరణ p(x, y) కలిగి ఉన్నప్పుడు, మనకు ఎల్లప్పుడూ H[x, y] ≥ H[x] + H[y] ఉంటుంది, ఇక్కడ H అనేది ఎంట్రోపీ ఫంక్షన్. ప్రకటన 2| కొన్ని దిశానిర్దేశిత గ్రాఫ్‌లకు, నైతికీకరణ గ్రాఫ్‌లో ఉన్న అంచుల సంఖ్యను తగ్గిస్తుంది.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",B
క్రింది వాటిలో ఏది పర్యవేక్షిత అభ్యసనం కాదు?,పిసిఎ,నిర్ణయ వృక్షం,లైనియర్ రిగ్రెషన్,నైవ్ బేయేసియన్,A
ప్రకటన 1| ఒక న్యూరల్ నెట్‌వర్క్ యొక్క అభిసరణ లెర్నింగ్ రేటుపై ఆధారపడి ఉంటుంది. ప్రకటన 2| డ్రాప్‌అవుట్ యాదృచ్ఛికంగా ఎంచుకున్న యాక్టివేషన్ విలువలను సున్నాతో గుణిస్తుంది.,"నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"కింది వాటిలో ఏది P(A, B, C)కి సమానం, బూలియన్ యాదృచ్ఛిక చరాశులు A, B మరియు C ఇవ్వబడినప్పుడు, మరియు వాటి మధ్య స్వాతంత్ర్యం లేదా షరతుల స్వాతంత్ర్యం అనుమానాలు లేనప్పుడు?",P(A | B) * P(B | C) * P(C | A),"P(C | A, B) * P(A) * P(B)","P(A, B | C) * P(C)","P(A | B, C) * P(B | A, C) * P(C | A, B)",C
క్రింది పనులలో దేనిని క్లస్టరింగ్ ఉపయోగించి ఉత్తమంగా పరిష్కరించవచ్చు.,వివిధ సూచనల ఆధారంగా వర్షపాతం మొత్తాన్ని అంచనా వేయడం,మోసపూరిత క్రెడిట్ కార్డు లావాదేవీలను గుర్తించడం,రోబోట్‌ను మేజ్‌ను పరిష్కరించడానికి శిక్షణ ఇవ్వడం,పైన పేర్కొన్నవన్నీ,B
"లీనియర్ రిగ్రెషన్‌లో రెగ్యులరైజేషన్ పెనాల్టీని అనువర్తించిన తర్వాత, w యొక్క కొన్ని గుణకాలు సున్నాగా మారినట్లు మీరు కనుగొన్నారు. కింది పెనాల్టీలలో ఏవి ఉపయోగించబడి ఉండవచ్చు?",L0 నార్మ్,L1 నార్మ్,L2 నార్మ్,ఏది (ఎ) లేదా (బి),D
"A మరియు B రెండు సంఘటనలు. ఒకవేళ P(A, B) తగ్గుతున్నప్పుడు P(A) పెరుగుతుంటే, కింది వాటిలో ఏది నిజం?",P(A|B) తగ్గుతుంది,P(B|A) తగ్గుతుంది,P(B) తగ్గుతుంది,పైన పేర్కొన్నవన్నీ,B
"ప్రకటన 1| ఒక స్థిర పరిశీలనల సెట్ కోసం HMM ను నేర్చుకునేటప్పుడు, నిజమైన దాగిన స్థితుల సంఖ్య తెలియదని అనుకుంటే (ఇది తరచుగా జరుగుతుంది), మరిన్ని దాగిన స్థితులను అనుమతించడం ద్వారా శిక్షణ డేటా సంభావ్యతను మనం ఎల్లప్పుడూ పెంచవచ్చు.

ప్రకటన 2| సహకార ఫిల్టరింగ్ తరచుగా వినియోగదారుల చలనచిత్ర ప్రాధాన్యతను మోడల్ చేయడానికి ఉపయోగకరమైన మోడల్.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
"మీరు సాధారణ అంచనా పనికి ఒక లీనియర్ రిగ్రెషన్ మోడల్‌ను శిక్షణ ఇస్తున్నారు, మరియు మోడల్ డేటాకు అతిగా సరిపోతున్నట్లు గమనించారు. మీరు బరువులను శిక్షించడానికి $\ell_2$ రెగ్యులరైజేషన్‌ను జోడించాలని నిర్ణయించుకున్నారు. మీరు $\ell_2$ రెగ్యులరైజేషన్ గుణకాన్ని పెంచినప్పుడు, మోడల్ యొక్క పక్షపాతం మరియు వ్యత్యాసం ఏమి జరుగుతుంది?",పక్షపాతం పెరుగుదల ; వ్యత్యాసం పెరుగుదల,పక్షపాతం పెరుగుదల ; వ్యత్యాసం తగ్గుదల,పక్షపాతం తగ్గుదల ; వ్యత్యాసం పెరుగుదల,పక్షపాతం తగ్గుదల ; వ్యత్యాసం తగ్గుదల,B
"ఏ PyTorch 1.8 ఆదేశం(లు) $10\times 5$ గాసియన్ మాట్రిక్స్‌ను ఉత్పత్తి చేస్తాయి, ప్రతి ఎంట్రీ $\mathcal{N}(\mu=5,\sigma^2=16)$ నుండి i.i.d. నమూనా చేయబడుతుంది మరియు $10\times 10$ యూనిఫార్మ్ మాట్రిక్స్‌ను ప్రతి ఎంట్రీ $U[-1,1)$ నుండి i.i.d. నమూనా చేయబడుతుంది?","\texttt{5 + torch.randn(10,5) * 16} ; \texttt{torch.rand(10,10,low=-1,high=1)}","\texttt{5 + torch.randn(10,5) * 16} ; \texttt{(torch.rand(10,10) - 0.5) / 0.5}","\texttt{5 + torch.randn(10,5) * 4} ; \texttt{2 * torch.rand(10,10) - 1}","\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \texttt{2 * torch.rand(10,10) - 1}",C
"ప్రకటన 1| ReLU యొక్క గ్రేడియంట్ $x<0$ కోసం సున్నా, మరియు సిగ్మాయిడ్ గ్రేడియంట్ $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ అన్ని $x$ ల కోసం. ప్రకటన 2| సిగ్మాయిడ్ కు నిరంతర గ్రేడియంట్ ఉంది మరియు ReLU కు అవిచ్ఛిన్న గ్రేడియంట్ ఉంది.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",A
బ్యాచ్ నార్మలైజేషన్ గురించి ఏది నిజం?,"బ్యాచ్ నార్మలైజేషన్ అనువర్తించిన తర్వాత, లేయర్ యొక్క యాక్టివేషన్లు ప్రామాణిక గాసియన్ పంపిణీని అనుసరిస్తాయి.","అఫైన్ పొరల యొక్క బైయాస్ పారామీటర్ అనవసరం అవుతుంది, ఒకవేళ బ్యాచ్ నార్మలైజేషన్ పొర వెంటనే అనుసరిస్తే.",ప్రమాణ బరువు ప్రారంభీకరణను బ్యాచ్ నార్మలైజేషన్ ఉపయోగించేటప్పుడు మార్చాలి.,బ్యాచ్ నార్మలైజేషన్ అనేది కన్వల్యూషనల్ న్యూరల్ నెట్‌వర్క్‌లకు లేయర్ నార్మలైజేషన్‌కు సమానం.,B
అనుకోండి మనకు కింది ఉద్దేశ్య ఫంక్షన్ ఉంది: $\argmin_{w} \frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\gamma \norm{w}^2_2$ $\frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\lambda \norm{w}^2_2$ యొక్క $w$ కు సంబంధించిన గ్రేడియంట్ ఏమిటి?,$\nabla_w f(w) = (X^\top X + \lambda I)w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + (\lambda+1) w$,C
క్రింది వాటిలో ఏది కన్వల్యూషన్ కెర్నెల్‌కు సంబంధించి నిజం?,చిత్రాన్ని $\begin{bmatrix}1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ తో కన్వోల్వ్ చేయడం వలన చిత్రం మారదు,చిత్రాన్ని $\begin{bmatrix}0 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ తో కన్వోల్వ్ చేయడం వలన చిత్రం మారదు,చిత్రాన్ని $\begin{bmatrix}1 & 1 & 1\\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}$ తో కన్వోల్వ్ చేయడం వలన చిత్రం మారదు,చిత్రాన్ని $\begin{bmatrix}0 & 0 & 0\\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ తో కన్వోల్వ్ చేయడం వలన చిత్రం మారదు,B
క్రింది వాటిలో ఏది తప్పు?,"సెమాంటిక్ సెగ్మెంటేషన్ మోడల్స్ ప్రతి పిక్సెల్ యొక్క వర్గాన్ని అంచనా వేస్తాయి, అయితే మల్టీక్లాస్ ఇమేజ్ క్లాసిఫైయర్లు మొత్తం చిత్రం యొక్క వర్గాన్ని అంచనా వేస్తాయి.",ఒక IoU (ఇంటర్సెక్షన్ ఓవర్ యూనియన్) $96\%$ కి సమానమైన బౌండింగ్ బాక్స్ సాధారణంగా నిజమైన పాజిటివ్‌గా పరిగణించబడుతుంది.,"ఒక అంచనా వేయబడిన బౌండింగ్ బాక్స్ దృశ్యంలోని ఏ వస్తువుకు సరిపోకపోతే, దానిని తప్పుడు పాజిటివ్‌గా పరిగణిస్తారు.",ఒక IoU (ఇంటర్సెక్షన్ ఓవర్ యూనియన్) $3\%$ కి సమానమైన బౌండింగ్ బాక్స్ సాధారణంగా తప్పుడు నెగటివ్‌గా పరిగణించబడుతుంది.,D
క్రింది వాటిలో ఏది తప్పు?,"క్రింది పూర్తిగా అనుసంధానమైన నెట్‌వర్క్ యాక్టివేషన్ ఫంక్షన్‌లు లేకుండా లీనియర్: $g_3(g_2(g_1(x)))$, ఇక్కడ $g_i(x) = W_i x$ మరియు $W_i$ మాట్రిసెస్.","లీకీ రెలు $\max\{0.01x,x\}$ సంవృత్తమైనది.",ReLU ల కలయిక ఉదాహరణకు $ReLU(x) - ReLU(x-1)$ సంవృత్తమైనది.,నష్టం $\log \sigma(x)= -\log(1+e^{-x})$ అవతల వంపు కలిగి ఉంటుంది,C
"మేము రెండు దాగిన పొరలతో పూర్తిగా అనుసంధానించబడిన నెట్‌వర్క్‌ను గృహ ధరలను అంచనా వేయడానికి శిక్షణ ఇస్తున్నాము. ఇన్‌పుట్‌లు $100$-పరిమాణాత్మకమైనవి మరియు చదరపు అడుగుల సంఖ్య, మధ్యస్థ కుటుంబ ఆదాయం మొదలైన అనేక లక్షణాలను కలిగి ఉన్నాయి. మొదటి దాగిన పొర $1000$ యాక్టివేషన్లను కలిగి ఉంది. రెండవ దాగిన పొర $10$ యాక్టివేషన్లను కలిగి ఉంది. అవుట్‌పుట్ ఇంటి ధరను సూచించే స్కాలర్. అఫైన్ పరివర్తనలతో కూడిన సాధారణ నెట్‌వర్క్‌ను అనుకుంటూ మరియు బ్యాచ్ నార్మలైజేషన్ లేకుండా మరియు యాక్టివేషన్ ఫంక్షన్‌లో నేర్చుకోగల పారామితులు లేకుండా, ఈ నెట్‌వర్క్‌కు ఎన్ని పారామితులు ఉన్నాయి?",111021,110010,111110,110011,A
"ప్రకటన 1| సిగ్మాయిడ్ $\sigma(x)=(1+e^{-x})^{-1}$ యొక్క $x$ పట్ల వ్యుత్పన్నం $\text{Var}(B)$ కి సమానం, ఇక్కడ $B\sim \text{Bern}(\sigma(x))$ అనేది ఒక బెర్నౌలీ యాదృచ్ఛిక చరరాశి. ప్రకటన 2| న్యూరల్ నెట్‌వర్క్‌లోని ప్రతి పొరలో బయాస్ పారామీటర్లను 0కి సెట్ చేయడం వలన బయాస్-వేరియన్స్ ట్రేడ్-ఆఫ్ మారుతుంది, తద్వారా మోడల్ యొక్క వేరియన్స్ పెరుగుతుంది మరియు మోడల్ యొక్క బయాస్ తగ్గుతుంది.","నిజం, నిజం","తప్పు, తప్పు","నిజం, తప్పు","తప్పు, నిజం",C
