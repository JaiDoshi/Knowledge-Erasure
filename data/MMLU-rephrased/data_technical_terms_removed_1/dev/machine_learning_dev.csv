"A small cube with 6 flat sides is thrown 15 times, and the number of times each side lands facing up is counted as follows: one side never comes up, one side comes up once, one side comes up twice, one side comes up three times, one side comes up four times, and one side comes up five times. If we make a small adjustment to the counts by adding 1 to each count, what is the chance that the side that originally came up twice will show up on the next throw?",2.0/15,1.0/7,3.0/16,1.0/5,B
"What type of change or tweak to image files is typically done for normal, everyday pictures?",random crop and horizontal flip,random crop and vertical flip,posterization,dithering,A
Which claims should be accepted for the important conference on learning from data?,My method achieves a training error lower than all previous methods!,My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter λ is chosen so as to minimise test error.),My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter λ is chosen so as to minimise cross-validaton error.),My method achieves a cross-validation error lower than all previous methods! (Footnote: When regularisation parameter λ is chosen so as to minimise cross-validaton error.),C
How many examples do we need in the test set to be 95% sure that the difference between the true and estimated error rates is less than 1%?,around 10 examples,around 100 examples,between 100 and 500 examples,more than 1000 examples,D
"When working with data that has numbers, the usual approach is to split the data into two groups based on whether the number is above or below a certain value. Pat suggests splitting the data into multiple groups, with one group for each different number value. From the options below, choose the main issue with Pat's approach:",It is too computationally expensive.,It would probably result in a decision tree that scores badly on the training set and a testset.,It would probably result in a decision tree that scores well on the training set but badly on a testset.,It would probably result in a decision tree that scores well on a testset but badly on a training set.,C
