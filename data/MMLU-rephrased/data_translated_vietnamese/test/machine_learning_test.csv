Phát biểu 1| Ước lượng hồi quy tuyến tính có phương sai nhỏ nhất trong tất cả các ước lượng không thiên lệch. Phát biểu 2| Các hệ số α được gán cho các bộ phân loại được tập hợp bởi AdaBoost luôn không âm.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",D
Phát biểu 1| RoBERTa được huấn luyện trước trên một kho ngữ liệu có kích thước xấp xỉ lớn hơn 10 lần so với kho ngữ liệu mà BERT được huấn luyện trước. Phát biểu 2| Các mạng ResNeXt vào năm 2018 thường sử dụng hàm kích hoạt tanh.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",C
"Câu 1| Các máy vector hỗ trợ, giống như các mô hình hồi quy logistic, đưa ra phân phối xác suất cho các nhãn có thể có dựa trên một ví dụ đầu vào.

Câu 2| Chúng ta sẽ kỳ vọng các vector hỗ trợ nhìn chung vẫn giữ nguyên khi chúng ta chuyển từ một kernel tuyến tính sang các kernel đa thức bậc cao hơn.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
"Một bài toán học máy bao gồm bốn thuộc tính cộng với một lớp. Các thuộc tính có lần lượt 3, 2, 2 và 2 giá trị khả dĩ. Lớp có 3 giá trị khả dĩ. Có bao nhiêu ví dụ khác nhau tối đa có thể có?",12,24,48,72,D
"Tính đến năm 2020, kiến trúc nào là tốt nhất để phân loại hình ảnh có độ phân giải cao?",mạng tích chập,mạng lưới đồ thị,mạng kết nối đầy đủ,Mạng RBF,A
"Phát biểu 1| Độ hợp lý logarit của dữ liệu sẽ luôn tăng qua các lần lặp liên tiếp của thuật toán kỳ vọng tối đa hóa.

Phát biểu 2| Một nhược điểm của học Q là nó chỉ có thể được sử dụng khi người học có kiến thức trước về cách hành động của mình ảnh hưởng đến môi trường.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
Giả sử chúng ta đã tính toán gradient của hàm chi phí và lưu trữ nó trong một vector g. Chi phí của một lần cập nhật gradient descent là gì khi đã biết gradient?,O(D),O(N),O(ND),O(ND^2),A
"Phát biểu 1| Đối với một biến ngẫu nhiên liên tục x và hàm phân phối xác suất của nó p(x), ta có 0 ≤ p(x) ≤ 1 cho mọi x. Phát biểu 2| Cây quyết định được học bằng cách tối thiểu hóa độ lợi thông tin.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
Hãy xem xét mạng Bayes được cho dưới đây. Cần bao nhiêu tham số độc lập cho Mạng Bayes này H -> U <- P <- W?,2,4,8,16,C
"Khi số lượng mẫu huấn luyện tiến đến vô cùng, mô hình của bạn được đào tạo trên dữ liệu đó sẽ có:",Phương sai thấp hơn,Phương sai cao hơn,Phương sai bằng nhau,Không có phương án nào ở trên,A
"Phát biểu 1| Tập hợp tất cả các hình chữ nhật trong mặt phẳng 2D (bao gồm cả các hình chữ nhật không song song với trục) có thể chia cắt một tập hợp 5 điểm.

Phát biểu 2| Chiều VC của bộ phân loại k-Láng giềng gần nhất khi k = 1 là vô hạn.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
_ đề cập đến một mô hình không thể mô phỏng dữ liệu huấn luyện cũng như không thể khái quát hóa cho dữ liệu mới.,vừa vặn,quá khớp,thiếu khớp,tất cả những điều trên,C
"Statement 1| Điểm F1 có thể đặc biệt hữu ích cho các bộ dữ liệu có sự mất cân bằng lớp cao.

Statement 2| Diện tích dưới đường cong ROC là một trong những chỉ số chính được sử dụng để đánh giá các bộ phát hiện bất thường.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Phát biểu 1| Thuật toán lan truyền ngược học một mạng nơ-ron tối ưu toàn cục với các lớp ẩn. Phát biểu 2| Chiều VC của một đường thẳng nên tối đa là 2, vì tôi có thể tìm thấy ít nhất một trường hợp của 3 điểm không thể bị chia cắt bởi bất kỳ đường thẳng nào.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
Entropy cao có nghĩa là các phân vùng trong phân loại là,thuần khiết,không tinh khiết,hữu ích,vô dụng,B
"Phát biểu 1| Chuẩn hóa lớp được sử dụng trong bài báo ResNet gốc, không phải Chuẩn hóa theo lô. Phát biểu 2| DCGANs sử dụng cơ chế tự chú ý để ổn định quá trình huấn luyện.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
"Khi xây dựng một mô hình hồi quy tuyến tính cho một tập dữ liệu cụ thể, bạn quan sát thấy hệ số của một trong các đặc trưng có giá trị âm tương đối cao. Điều này cho thấy rằng",Tính năng này có ảnh hưởng mạnh mẽ đến mô hình (nên được giữ lại),Tính năng này không có ảnh hưởng mạnh đến mô hình (nên được bỏ qua),Không thể bình luận về tầm quan trọng của tính năng này mà không có thêm thông tin,Không thể xác định được gì.,C
"Đối với một mạng nơ-ron, trong số những giả định cấu trúc này, giả định nào ảnh hưởng nhiều nhất đến sự cân bằng giữa underfitting (tức là mô hình có độ chệch cao) và overfitting (tức là mô hình có phương sai cao):",Số lượng nút ẩn,Tốc độ học,Sự lựa chọn ban đầu của trọng số,Việc sử dụng một đầu vào đơn vị hằng số,A
"Đối với hồi quy đa thức, trong số các giả định cấu trúc này, giả định nào ảnh hưởng nhiều nhất đến sự đánh đổi giữa underfitting và overfitting:",Bậc của đa thức,Cho dù chúng ta học các trọng số bằng phép đảo ma trận hay bằng phương pháp hạ gradient,Phương sai giả định của nhiễu Gauss,Việc sử dụng một đầu vào đơn vị hằng số,A
"Câu 1| Tính đến năm 2020, một số mô hình đạt độ chính xác hơn 98% trên CIFAR-10. Câu 2| Các mạng ResNet ban đầu không được tối ưu hóa bằng bộ tối ưu hóa Adam.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
Thuật toán K-means:,Yêu cầu kích thước của không gian đặc trưng không được lớn hơn số lượng mẫu,Có giá trị nhỏ nhất của hàm mục tiêu khi K = 1,Giảm thiểu phương sai trong lớp cho một số lượng cụm nhất định,Hội tụ đến điểm tối ưu toàn cục nếu và chỉ nếu các giá trị trung bình ban đầu được chọn là một số mẫu trong chính tập dữ liệu,C
Phát biểu 1| VGGNets có các nhân tích chập với chiều rộng và chiều cao nhỏ hơn so với các nhân lớp đầu tiên của AlexNet. Phát biểu 2| Các quy trình khởi tạo trọng số phụ thuộc vào dữ liệu đã được giới thiệu trước khi có Chuẩn hóa theo lô.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Hạng của ma trận sau đây là bao nhiêu? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]",0,1,2,3,B
Phát biểu 1| Ước tính mật độ (sử dụng chẳng hạn như bộ ước tính mật độ hạt nhân) có thể được sử dụng để thực hiện phân loại. Phát biểu 2| Sự tương ứng giữa hồi quy logistic và Naive Bayes Gaussian (với ma trận hiệp phương sai lớp đồng nhất) có nghĩa là có một sự tương ứng một-một giữa các tham số của hai bộ phân loại.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",C
Giả sử chúng ta muốn thực hiện phân cụm trên dữ liệu không gian như vị trí địa lý của các ngôi nhà. Chúng ta muốn tạo ra các cụm có nhiều kích thước và hình dạng khác nhau. Phương pháp nào sau đây là phù hợp nhất?,Cây quyết định,Phân cụm dựa trên mật độ,Phân cụm dựa trên mô hình,Phân cụm K-means,B
"Phát biểu 1| Trong AdaBoost, trọng số của các ví dụ bị phân loại sai tăng lên bởi cùng một hệ số nhân.

Phát biểu 2| Trong AdaBoost, lỗi huấn luyện có trọng số e_t của bộ phân loại yếu thứ t trên dữ liệu huấn luyện với trọng số D_t có xu hướng tăng lên theo hàm của t.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
Các ước tính MLE thường không mong muốn vì,họ có thành kiến,chúng có độ biến thiên cao,chúng không phải là những ước lượng nhất quán,Không có câu trả lời nào ở trên,B
"Độ phức tạp tính toán của Gradient descent là,",tuyến tính theo D,tuyến tính theo N,đa thức theo D,phụ thuộc vào số lần lặp lại,C
Lấy trung bình kết quả của nhiều cây quyết định giúp _.,Tăng độ thiên vị,Giảm thiểu thành kiến,Tăng phương sai,Giảm phương sai,D
Mô hình thu được bằng cách áp dụng hồi quy tuyến tính trên tập hợp con các đặc trưng đã được xác định có thể khác với mô hình thu được vào cuối quá trình xác định tập hợp con trong quá trình,Lựa chọn tập con tốt nhất,Lựa chọn từng bước tiến,Lựa chọn từng giai đoạn tiến tới,Tất cả những điều trên,C
Mạng nơ-ron,Tối ưu hóa một hàm mục tiêu lồi,Chỉ có thể được huấn luyện bằng phương pháp gradient giảm dần ngẫu nhiên,Có thể sử dụng kết hợp các hàm kích hoạt khác nhau,Không có câu trả lời nào ở trên,C
"Giả sử tỷ lệ mắc bệnh D là khoảng 5 ca trên 100 người (tức là P(D) = 0,05). Gọi biến ngẫu nhiên Boolean D có nghĩa là một bệnh nhân ""mắc bệnh D"" và biến ngẫu nhiên Boolean TP có nghĩa là ""xét nghiệm dương tính"". Các xét nghiệm cho bệnh D được biết là rất chính xác theo nghĩa là xác suất xét nghiệm dương tính khi bạn mắc bệnh là 0,99, và xác suất xét nghiệm âm tính khi bạn không mắc bệnh là 0,97. P(TP) là gì, xác suất tiên nghiệm của việc xét nghiệm dương tính.","0,0368","0,473","0,078",Không có phương án nào ở trên,C
"Phát biểu 1| Sau khi được ánh xạ vào không gian đặc trưng Q thông qua hàm nhân cơ sở xuyên tâm, phương pháp 1-NN sử dụng khoảng cách Euclidean không trọng số có thể đạt được hiệu suất phân loại tốt hơn so với trong không gian ban đầu (mặc dù chúng ta không thể đảm bảo điều này). Phát biểu 2| Chiều VC của một Perceptron nhỏ hơn chiều VC của một SVM tuyến tính đơn giản.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
Nhược điểm của tìm kiếm lưới là,Nó không thể được áp dụng cho các hàm không khả vi.,Nó không thể được áp dụng cho các hàm không liên tục.,Nó khó để thực hiện.,Nó chạy khá chậm đối với hồi quy tuyến tính đa biến.,D
Dự đoán lượng mưa trong một khu vực dựa trên các dấu hiệu khác nhau là một vấn đề ______.,Học có giám sát,Học không giám sát,Phân cụm,Không có câu trả lời nào ở trên,A
Câu nào sau đây là SAI về hồi quy?,Nó liên kết các đầu vào với các đầu ra.,Nó được sử dụng để dự đoán.,Nó có thể được sử dụng để phiên dịch.,Nó khám phá các mối quan hệ nhân quả,D
Lý do chính nào sau đây là để cắt tỉa một Cây Quyết định?,Để tiết kiệm thời gian tính toán trong quá trình kiểm thử,Để tiết kiệm không gian lưu trữ cho Cây Quyết định,Để làm cho lỗi tập huấn luyện nhỏ hơn,Để tránh quá khớp tập huấn luyện,D
Phát biểu 1| Bộ ước lượng mật độ hạt nhân tương đương với việc thực hiện hồi quy hạt nhân với giá trị Yi = 1/n tại mỗi điểm Xi trong tập dữ liệu gốc. Phát biểu 2| Độ sâu của một cây quyết định đã học có thể lớn hơn số lượng mẫu huấn luyện được sử dụng để tạo ra cây đó.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
"Giả sử mô hình của bạn đang bị overfitting. Trong số các cách sau đây, cách nào KHÔNG phải là cách hợp lệ để cố gắng giảm overfitting?",Tăng lượng dữ liệu huấn luyện.,Cải thiện thuật toán tối ưu hóa đang được sử dụng để giảm thiểu lỗi.,Giảm độ phức tạp của mô hình.,Giảm nhiễu trong dữ liệu huấn luyện.,B
Câu 1| Hàm softmax thường được sử dụng trong hồi quy logistic đa lớp. Câu 2| Nhiệt độ của một phân phối softmax không đồng nhất ảnh hưởng đến entropy của nó.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
Điều nào sau đây là đúng về SVM (Máy Vector Hỗ trợ)?,"Đối với các điểm dữ liệu hai chiều, siêu phẳng phân tách được học bởi một SVM tuyến tính sẽ là một đường thẳng.","Về mặt lý thuyết, một SVM với nhân Gaussian không thể mô hình hóa bất kỳ siêu phẳng phân tách phức tạp nào.","Đối với mỗi hàm nhân được sử dụng trong SVM, người ta có thể thu được một khai triển cơ sở dạng đóng tương đương.",Overfitting trong SVM không phải là một hàm của số lượng vector hỗ trợ.,A
"Trong các phương án sau đây, đâu là xác suất đồng thời của H, U, P và W được mô tả bởi Mạng Bayes cho trước H -> U <- P <- W? [lưu ý: dưới dạng tích của các xác suất có điều kiện]","P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)",Không có phương án nào ở trên,C
"Phát biểu 1| Vì chiều VC của một SVM với Kernel Cơ sở Xuyên tâm là vô hạn, nên một SVM như vậy phải kém hơn một SVM với kernel đa thức có chiều VC hữu hạn.

Phát biểu 2| Một mạng nơ-ron hai lớp với các hàm kích hoạt tuyến tính về cơ bản là một tổ hợp có trọng số của các bộ phân tách tuyến tính, được huấn luyện trên một tập dữ liệu cho trước; thuật toán tăng cường được xây dựng trên các bộ phân tách tuyến tính cũng tìm ra một tổ hợp của các bộ phân tách tuyến tính, do đó hai thuật toán này sẽ cho kết quả giống nhau.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
Phát biểu 1| Thuật toán ID3 được đảm bảo tìm ra cây quyết định tối ưu. Phát biểu 2| Xét một phân phối xác suất liên tục với hàm mật độ f() khác không ở mọi nơi. Xác suất của một giá trị x bằng f(x).,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
"Với một Mạng Nơ-ron có N nút đầu vào, không có lớp ẩn, một nút đầu ra, sử dụng Hàm mất mát Entropy và Hàm kích hoạt Sigmoid, thuật toán nào trong số các thuật toán sau đây (với các siêu tham số và khởi tạo phù hợp) có thể được sử dụng để tìm ra điểm tối ưu toàn cục?",Giảm Gradient Ngẫu nhiên,Giảm Gradient theo Lô Nhỏ,Hạ gradient theo lô,Tất cả những điều trên,D
"Thêm nhiều hàm cơ sở hơn vào một mô hình tuyến tính, chọn phương án có khả năng xảy ra nhất:",Giảm thiểu độ lệch của mô hình,Giảm độ chệch ước lượng,Giảm phương sai,Không ảnh hưởng đến độ chệch và phương sai,A
Hãy xem xét mạng Bayes được cho dưới đây. Chúng ta sẽ cần bao nhiêu tham số độc lập nếu chúng ta không đưa ra bất kỳ giả định nào về tính độc lập hoặc độc lập có điều kiện H -> U <- P <- W?,3,4,7,15,D
Một thuật ngữ khác cho phát hiện ngoài phân phối là gì?,phát hiện bất thường,phát hiện một lớp,Độ mạnh mẽ trước sự không khớp giữa tập huấn luyện và tập kiểm tra,phát hiện nền,A
"Phát biểu 1| Chúng ta học một bộ phân loại f bằng cách tăng cường các bộ học yếu h. Dạng hàm của đường biên quyết định của f giống như của h, nhưng với các tham số khác nhau. (ví dụ, nếu h là một bộ phân loại tuyến tính, thì f cũng là một bộ phân loại tuyến tính).

Phát biểu 2| Kiểm chứng chéo có thể được sử dụng để chọn số lần lặp trong quá trình tăng cường; quy trình này có thể giúp giảm thiểu hiện tượng quá khớp.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",D
Câu 1| Các mạng lưới đường cao tốc được giới thiệu sau ResNets và tránh sử dụng max pooling để ưu tiên cho các phép tích chập. Câu 2| DenseNets thường tốn nhiều bộ nhớ hơn so với ResNets.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",D
"Nếu N là số lượng trường hợp trong tập dữ liệu huấn luyện, thời gian chạy phân loại của phương pháp láng giềng gần nhất là",O(1),O( N ),O(log N),O( N^2 ),B
"Câu 1| Các mạng ResNet và Transformer nguyên bản là các mạng nơ-ron truyền xuôi.
Câu 2| Các mạng Transformer nguyên bản sử dụng cơ chế tự chú ý, nhưng mạng ResNet nguyên bản thì không.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Phát biểu 1| RELUs không đơn điệu, nhưng sigmoid thì đơn điệu. Phát biểu 2| Các mạng nơ-ron được huấn luyện bằng phương pháp gradient descent có xác suất cao hội tụ đến điểm tối ưu toàn cục.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",D
Đầu ra số của một nút sigmoid trong mạng nơ-ron:,"Là không giới hạn, bao gồm tất cả các số thực.","Không giới hạn, bao gồm tất cả các số nguyên.",Bị giới hạn giữa 0 và 1.,Bị giới hạn giữa -1 và 1.,C
Cái nào trong số những điều sau đây chỉ có thể được sử dụng khi dữ liệu huấn luyện có thể tách biệt tuyến tính?,SVM biên cứng tuyến tính.,Hồi quy Logistic Tuyến tính,SVM biên mềm tuyến tính,Phương pháp trọng tâm.,A
Thuật toán phân cụm không gian nào trong số các thuật toán sau đây?,Phân cụm dựa trên phân vùng,Phân cụm K-means,Phân cụm dựa trên lưới,Tất cả những điều trên,D
Phát biểu 1| Các ranh giới quyết định biên tối đa mà máy vector hỗ trợ xây dựng có lỗi tổng quát hóa thấp nhất trong số tất cả các bộ phân loại tuyến tính. Phát biểu 2| Bất kỳ ranh giới quyết định nào mà chúng ta nhận được từ một mô hình sinh với phân phối Gaussian có điều kiện lớp về nguyên tắc có thể được tái tạo bằng một SVM và một nhân đa thức có bậc nhỏ hơn hoặc bằng ba.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",D
Phát biểu 1| Chuẩn hóa L2 của các mô hình tuyến tính có xu hướng làm cho các mô hình thưa thớt hơn so với chuẩn hóa L1. Phát biểu 2| Các kết nối phần dư có thể được tìm thấy trong ResNets và Transformers.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",D
"Giả sử chúng ta muốn tính P(H|E, F) và chúng ta không có thông tin về tính độc lập có điều kiện. Trong các tập số sau đây, tập nào đủ để thực hiện phép tính?","P(E, F), P(H), P(E|H), P(F|H)","P(E, F), P(H), P(E, F|H)","P(H), P(E|H), P(F|H)","P(E, F), P(E|H), P(F|H)",B
"Trong số những điều sau đây, điều gì ngăn chặn việc quá khớp khi chúng ta thực hiện kỹ thuật bagging?",Việc sử dụng lấy mẫu có hoàn lại như là kỹ thuật lấy mẫu,Việc sử dụng các bộ phân loại yếu,Việc sử dụng các thuật toán phân loại không dễ bị overfitting,Thực hành xác thực được thực hiện trên mọi bộ phân loại đã được huấn luyện,B
"Phát biểu 1| PCA và Phân cụm phổ (như của Andrew Ng) thực hiện phân tích trị riêng trên hai ma trận khác nhau. Tuy nhiên, kích thước của hai ma trận này là giống nhau. Phát biểu 2| Vì phân loại là một trường hợp đặc biệt của hồi quy, hồi quy logistic là một trường hợp đặc biệt của hồi quy tuyến tính.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
"Phát biểu 1| Ngân hàng cây cảm xúc Stanford chứa các bài đánh giá phim, không phải đánh giá sách. Phát biểu 2| Ngân hàng cây Penn đã được sử dụng cho việc mô hình hóa ngôn ngữ.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Chiều của không gian null của ma trận sau đây là bao nhiêu? A = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]]",0,1,2,3,C
Các vectơ hỗ trợ là gì?,Các ví dụ xa nhất từ ranh giới quyết định.,Những ví dụ duy nhất cần thiết để tính toán f(x) trong một SVM.,Tâm dữ liệu.,Tất cả các ví dụ có trọng số αk khác không trong một SVM.,B
"Statement 1| Các tham số Word2Vec không được khởi tạo bằng cách sử dụng Máy Boltzman Hạn chế.
Statement 2| Hàm tanh là một hàm kích hoạt phi tuyến tính.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Nếu tổn thất huấn luyện của bạn tăng lên theo số lượng epoch, điều nào sau đây có thể là vấn đề tiềm ẩn trong quá trình học?",Sự điều chỉnh quá thấp và mô hình đang bị quá khớp,Sự điều chỉnh quá cao và mô hình đang bị khớp dưới mức,Kích thước bước quá lớn,Kích thước bước quá nhỏ,C
"Giả sử tỷ lệ mắc bệnh D là khoảng 5 ca trên 100 người (tức là P(D) = 0,05). Gọi biến ngẫu nhiên Boolean D có nghĩa là một bệnh nhân ""mắc bệnh D"" và biến ngẫu nhiên Boolean TP có nghĩa là ""xét nghiệm dương tính"". Các xét nghiệm cho bệnh D được biết là rất chính xác theo nghĩa là xác suất xét nghiệm dương tính khi bạn mắc bệnh là 0,99, và xác suất xét nghiệm âm tính khi bạn không mắc bệnh là 0,97. P(D | TP) là bao nhiêu, tức là xác suất hậu nghiệm rằng bạn mắc bệnh D khi xét nghiệm dương tính?","0,0495","0,078","0,635","0,97",C
"Statement 1| Các kết quả học máy truyền thống giả định rằng tập huấn luyện và tập kiểm tra là độc lập và có cùng phân phối.

Statement 2| Vào năm 2017, các mô hình COCO thường được huấn luyện trước trên ImageNet.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Phát biểu 1| Các giá trị của lề thu được bởi hai hạt nhân khác nhau K1(x, x0) và K2(x, x0) trên cùng một tập huấn luyện không cho chúng ta biết bộ phân loại nào sẽ hoạt động tốt hơn trên tập kiểm tra. Phát biểu 2| Hàm kích hoạt của BERT là GELU.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
Thuật toán phân cụm nào sau đây được sử dụng trong học máy?,Cực đại hóa kỳ vọng,XE ĐẨY,Naïve Bayes Gauss,Apriori,A
"Bạn vừa hoàn thành việc huấn luyện một cây quyết định để phân loại thư rác, và nó đang cho kết quả bất thường kém trên cả tập huấn luyện và tập kiểm tra của bạn. Bạn biết rằng việc triển khai của mình không có lỗi, vậy điều gì có thể gây ra vấn đề này?",Cây quyết định của bạn quá nông.,Bạn cần tăng tốc độ học.,Bạn đang quá khớp.,Không có câu trả lời nào ở trên.,A
Kiểm chứng chéo K-fold là,tuyến tính theo K,bậc hai theo K,lập phương trong K,hàm mũ theo K,A
"Câu 1| Các mạng nơ-ron quy mô công nghiệp thường được huấn luyện trên CPU, không phải GPU. Câu 2| Mô hình ResNet-50 có hơn 1 tỷ tham số.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
"Cho hai biến ngẫu nhiên Boolean, A và B, trong đó P(A) = 1/2, P(B) = 1/3, và P(A | ¬B) = 1/4, hãy tính P(A | B)?",1/6,1/4,3/4,1,D
Các rủi ro hiện hữu do AI gây ra thường được liên kết nhiều nhất với giáo sư nào trong số các giáo sư sau đây?,Nando de Frietas,Yann LeCun,Stuart Russell,Jitendra Malik,C
Phát biểu 1| Việc tối đa hóa khả năng xảy ra của mô hình hồi quy logistic tạo ra nhiều điểm tối ưu cục bộ. Phát biểu 2| Không có bộ phân loại nào có thể hoạt động tốt hơn bộ phân loại Bayes ngây thơ nếu phân phối của dữ liệu được biết.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
"Đối với Hồi quy Kernel, trong số những giả định cấu trúc này, giả định nào ảnh hưởng nhiều nhất đến sự cân bằng giữa underfitting và overfitting:",Liệu hàm nhân có phải là Gaussian so với hình tam giác so với hình hộp,"Cho dù chúng ta sử dụng các phép đo Euclidean, L1 hay L∞",Độ rộng của nhân,Chiều cao tối đa của hàm nhân,C
"Phát biểu 1| Thuật toán học SVM được đảm bảo tìm ra giả thuyết tối ưu toàn cục đối với hàm mục tiêu của nó. Phát biểu 2| Sau khi được ánh xạ vào không gian đặc trưng Q thông qua hàm nhân cơ sở xuyên tâm, một Perceptron có thể đạt được hiệu suất phân loại tốt hơn so với trong không gian ban đầu của nó (mặc dù chúng ta không thể đảm bảo điều này).","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Đối với bộ phân loại Bayes Gaussian, giả định cấu trúc nào trong số này là giả định ảnh hưởng nhiều nhất đến sự cân bằng giữa underfitting và overfitting:",Cho dù chúng ta học các tâm lớp bằng phương pháp Hợp lý Cực đại hay Giảm Gradient,Cho dù chúng ta giả định các ma trận hiệp phương sai lớp đầy đủ hay các ma trận hiệp phương sai lớp đường chéo,Cho dù chúng ta có các xác suất tiên nghiệm của các lớp bằng nhau hay các xác suất tiên nghiệm được ước tính từ dữ liệu.,Liệu chúng ta cho phép các lớp có các vector trung bình khác nhau hay chúng ta buộc chúng phải chia sẻ cùng một vector trung bình,B
Phát biểu 1| Overfitting có khả năng xảy ra hơn khi tập dữ liệu huấn luyện nhỏ. Phát biểu 2| Overfitting có khả năng xảy ra hơn khi không gian giả thuyết nhỏ.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",D
"Statement 1| Ngoài EM, phương pháp gradient descent có thể được sử dụng để thực hiện suy luận hoặc học trên mô hình hỗn hợp Gaussian.

Statement 2 | Giả sử số lượng thuộc tính cố định, một bộ phân loại tối ưu Bayes dựa trên Gaussian có thể được học trong thời gian tuyến tính với số lượng bản ghi trong tập dữ liệu.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Phát biểu 1| Trong một mạng Bayes, kết quả suy luận của thuật toán cây nối là giống như kết quả suy luận của phương pháp loại bỏ biến.

Phát biểu 2| Nếu hai biến ngẫu nhiên X và Y độc lập có điều kiện khi biết một biến ngẫu nhiên khác Z, thì trong mạng Bayes tương ứng, các nút cho X và Y được d-tách biệt khi biết Z.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",C
"Với một tập dữ liệu lớn về hồ sơ y tế của các bệnh nhân mắc bệnh tim, hãy cố gắng tìm hiểu xem có thể có các nhóm bệnh nhân khác nhau mà chúng ta có thể điều chỉnh các phương pháp điều trị riêng biệt hay không. Đây là loại vấn đề học tập nào?",Học có giám sát,Học không giám sát,Cả (a) và (b),Không phải (a) cũng không phải (b),B
Bạn sẽ làm gì trong PCA để có được cùng một phép chiếu như SVD?,Chuyển đổi dữ liệu về trung bình bằng không,Chuyển đổi dữ liệu về trung vị bằng không,Không thể,Không có cái nào trong số này,A
"Phát biểu 1| Sai số huấn luyện của bộ phân loại 1-láng giềng gần nhất là 0.

Phát biểu 2| Khi số lượng điểm dữ liệu tăng đến vô cùng, ước lượng MAP tiến gần đến ước lượng MLE cho tất cả các tiên nghiệm có thể. Nói cách khác, với đủ dữ liệu, việc lựa chọn tiên nghiệm là không quan trọng.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",C
"Khi thực hiện hồi quy bình phương tối thiểu với điều chỉnh (giả định rằng việc tối ưu hóa có thể được thực hiện chính xác), việc tăng giá trị của tham số điều chỉnh λ sẽ ảnh hưởng đến lỗi kiểm tra.",sẽ không bao giờ làm giảm lỗi huấn luyện.,sẽ không bao giờ làm tăng lỗi huấn luyện.,sẽ không bao giờ làm giảm lỗi kiểm tra.,sẽ không bao giờ tăng,A
"Trong các phương án sau đây, phương án nào mô tả chính xác nhất những gì mà các phương pháp phân biệt cố gắng mô hình hóa? (w là các tham số trong mô hình)","p(y|x, w)","p(y, x)","p(w|x, w)",Không có câu trả lời nào ở trên,A
Phát biểu 1| Hiệu suất phân loại CIFAR-10 cho các mạng nơ-ron tích chập có thể vượt quá 95%. Phát biểu 2| Các tổ hợp mạng nơ-ron không cải thiện độ chính xác phân loại vì các biểu diễn mà chúng học được có tương quan cao.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",C
Bayesians và những người theo thuyết tần suất sẽ không đồng ý về điểm nào trong những điểm sau đây?,Việc sử dụng mô hình nhiễu phi Gauss trong hồi quy xác suất.,Sử dụng mô hình xác suất cho hồi quy.,Việc sử dụng các phân phối tiên nghiệm cho các tham số trong một mô hình xác suất.,Việc sử dụng các xác suất tiên nghiệm của lớp trong Phân tích Phân biệt Gaussian.,C
"Câu 1| Chỉ số BLEU sử dụng độ chính xác, trong khi chỉ số ROGUE sử dụng độ bao phủ. Câu 2| Mô hình Markov ẩn thường được sử dụng để mô hình hóa các câu tiếng Anh.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
Câu 1| ImageNet có hình ảnh với nhiều độ phân giải khác nhau. Câu 2| Caltech-101 có nhiều hình ảnh hơn ImageNet.,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",C
Phương pháp nào sau đây phù hợp hơn để thực hiện lựa chọn đặc trưng?,Sống núi,Dây thòng lọng,cả (a) và (b),không phải (a) cũng không phải (b),B
Giả sử bạn được cung cấp một thuật toán EM tìm ước lượng hợp lý cực đại cho một mô hình có các biến ẩn. Bạn được yêu cầu sửa đổi thuật toán để nó tìm ước lượng MAP thay vào đó. Bạn cần sửa đổi bước hoặc các bước nào?,Kỳ vọng,Tối đa hóa,Không cần sửa đổi,Cả hai,B
"Đối với bộ phân loại Bayes Gaussian, giả định cấu trúc nào trong số này là giả định ảnh hưởng nhiều nhất đến sự cân bằng giữa underfitting và overfitting:",Cho dù chúng ta học các tâm lớp bằng phương pháp Hợp lý Cực đại hay Giảm Gradient,Cho dù chúng ta giả định các ma trận hiệp phương sai lớp đầy đủ hay các ma trận hiệp phương sai lớp đường chéo,Cho dù chúng ta có các xác suất tiên nghiệm của các lớp bằng nhau hay các xác suất tiên nghiệm được ước tính từ dữ liệu,Liệu chúng ta cho phép các lớp có các vector trung bình khác nhau hay chúng ta buộc chúng phải chia sẻ cùng một vector trung bình,B
"Phát biểu 1| Đối với bất kỳ hai biến x và y có phân phối đồng thời p(x, y), chúng ta luôn có H[x, y] ≥ H[x] + H[y] trong đó H là hàm entropy. Phát biểu 2| Đối với một số đồ thị có hướng, việc đạo đức hóa làm giảm số cạnh hiện có trong đồ thị.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",B
Cái nào trong số sau đây KHÔNG phải là học có giám sát?,PCA,Cây quyết định,Hồi quy tuyến tính,Bayes ngây thơ,A
"Phát biểu 1| Sự hội tụ của một mạng nơ-ron phụ thuộc vào tốc độ học.
Phát biểu 2| Dropout nhân các giá trị kích hoạt được chọn ngẫu nhiên với số không.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Trong các phương án sau đây, phương án nào bằng P(A, B, C) khi A, B và C là các biến ngẫu nhiên Boolean, và không có giả định về tính độc lập hoặc độc lập có điều kiện giữa bất kỳ biến nào trong số chúng?",P(A | B) * P(B | C) * P(C | A),"P(C | A, B) * P(A) * P(B)","P(A, B | C) * P(C)","P(A | B, C) * P(B | A, C) * P(C | A, B)",C
"Trong số các nhiệm vụ sau đây, nhiệm vụ nào có thể được giải quyết tốt nhất bằng cách sử dụng Phân cụm (Clustering).",Dự đoán lượng mưa dựa trên các dấu hiệu khác nhau,Phát hiện các giao dịch thẻ tín dụng gian lận,Huấn luyện robot giải mê cung,Tất cả những điều trên,B
"Sau khi áp dụng một hình phạt điều chỉnh trong hồi quy tuyến tính, bạn thấy rằng một số hệ số của w bị triệt tiêu về 0. Những hình phạt nào sau đây có thể đã được sử dụng?",Chuẩn L0,Chuẩn L1,Chuẩn L2,hoặc (a) hoặc (b),D
"A và B là hai sự kiện. Nếu P(A, B) giảm trong khi P(A) tăng, điều nào sau đây là đúng?",P(A|B) giảm,P(B|A) giảm,P(B) giảm,Tất cả những điều trên,B
"Phát biểu 1| Khi học một HMM cho một tập hợp quan sát cố định, giả sử chúng ta không biết số lượng trạng thái ẩn thực sự (thường là trường hợp này), chúng ta luôn có thể tăng khả năng của dữ liệu huấn luyện bằng cách cho phép nhiều trạng thái ẩn hơn. Phát biểu 2| Lọc cộng tác thường là một mô hình hữu ích để mô hình hóa sở thích phim của người dùng.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
"Bạn đang huấn luyện một mô hình hồi quy tuyến tính cho một nhiệm vụ ước tính đơn giản, và nhận thấy rằng mô hình đang quá khớp với dữ liệu. Bạn quyết định thêm vào phương pháp điều chỉnh $\ell_2$ để phạt các trọng số. Khi bạn tăng hệ số điều chỉnh $\ell_2$, điều gì sẽ xảy ra với độ chệch và phương sai của mô hình?",Độ chệch tăng ; Phương sai tăng,Độ chệch tăng; Phương sai giảm,Độ chệch giảm ; Phương sai tăng,Độ chệch giảm ; Phương sai giảm,B
"Lệnh (các lệnh) PyTorch 1.8 nào tạo ra ma trận Gaussian $10\times 5$ với mỗi phần tử được lấy mẫu độc lập và đồng nhất từ $\mathcal{N}(\mu=5,\sigma^2=16)$ và một ma trận đồng nhất $10\times 10$ với mỗi phần tử được lấy mẫu độc lập và đồng nhất từ $U[-1,1)$?","\texttt{5 + torch.randn(10,5) * 16} ; \texttt{torch.rand(10,10,low=-1,high=1)}","\texttt{5 + torch.randn(10,5) * 16} ; \texttt{(torch.rand(10,10) - 0,5) / 0,5}","\texttt{5 + torch.randn(10,5) * 4} ; \texttt{2 * torch.rand(10,10) - 1}","\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \texttt{2 * torch.rand(10,10) - 1}",C
"Phát biểu 1| Gradient của ReLU bằng không khi $x<0$, và gradient của sigmoid $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ với mọi $x$. Phát biểu 2| Sigmoid có gradient liên tục và ReLU có gradient không liên tục.","Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",A
Điều nào sau đây đúng về Chuẩn hóa theo lô (Batch Normalization)?,"Sau khi áp dụng chuẩn hóa theo lô, các kích hoạt của lớp sẽ tuân theo phân phối Gaussian chuẩn.",Tham số độ lệch của các lớp affine trở nên dư thừa nếu một lớp chuẩn hóa theo batch được đặt ngay sau đó.,Việc khởi tạo trọng số tiêu chuẩn phải được thay đổi khi sử dụng Chuẩn hóa theo lô.,Chuẩn hóa theo lô tương đương với chuẩn hóa theo lớp đối với các mạng nơ-ron tích chập.,B
Giả sử chúng ta có hàm mục tiêu sau: $\argmin_{w} \frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\gamma \norm{w}^2_2$ Gradient của $\frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\lambda \norm{w}^2_2$ đối với $w$ là gì?,$\nabla_w f(w) = (X^\top X + \lambda I)w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + (\lambda+1) w$,C
Điều nào sau đây đúng với một nhân tích chập?,Tích chập một hình ảnh với $\begin{bmatrix}1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ sẽ không làm thay đổi hình ảnh,Tích chập một hình ảnh với $\begin{bmatrix}0 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ sẽ không làm thay đổi hình ảnh,Tích chập một hình ảnh với $\begin{bmatrix}1 & 1 & 1\\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}$ sẽ không làm thay đổi hình ảnh,Tích chập một hình ảnh với $\begin{bmatrix}0 & 0 & 0\\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ sẽ không làm thay đổi hình ảnh,B
Điều nào sau đây là sai?,"Các mô hình phân đoạn ngữ nghĩa dự đoán lớp của từng pixel, trong khi các bộ phân loại ảnh đa lớp dự đoán lớp của toàn bộ hình ảnh.",Một hộp giới hạn với IoU (giao điểm trên hợp) bằng 96% có thể được coi là dương tính thật.,"Khi một hộp giới hạn dự đoán không tương ứng với bất kỳ đối tượng nào trong cảnh, nó được coi là dương tính giả.",Một hộp giới hạn với IoU (giao điểm trên hợp) bằng 3% có thể được coi là âm tính giả.,D
Điều nào sau đây là sai?,"Mạng lưới kết nối đầy đủ sau đây không có hàm kích hoạt là tuyến tính: $g_3(g_2(g_1(x)))$, trong đó $g_i(x) = W_i x$ và $W_i$ là các ma trận.","Leaky ReLU $\max\{0.01x,x\}$ là lồi.",Một sự kết hợp của các hàm ReLU như $ReLU(x) - ReLU(x-1)$ là lồi.,Hàm mất mát $\log \sigma(x)= -\log(1+e^{-x})$ là lõm,C
"Chúng ta đang huấn luyện một mạng nơ-ron kết nối đầy đủ với hai lớp ẩn để dự đoán giá nhà. Đầu vào có kích thước $100$ chiều, và có nhiều đặc trưng như số feet vuông, thu nhập trung bình của gia đình, v.v. Lớp ẩn đầu tiên có $1000$ đơn vị kích hoạt. Lớp ẩn thứ hai có $10$ đơn vị kích hoạt. Đầu ra là một số vô hướng đại diện cho giá nhà. Giả sử đây là một mạng thông thường với các phép biến đổi affine và không có chuẩn hóa theo batch cũng như không có tham số có thể học được trong hàm kích hoạt, mạng này có bao nhiêu tham số?",111021,110010,111110,110011,A
Phát biểu 1| Đạo hàm của hàm sigmoid $\sigma(x)=(1+e^{-x})^{-1}$ đối với $x$ bằng $\text{Var}(B)$ trong đó $B\sim \text{Bern}(\sigma(x))$ là một biến ngẫu nhiên Bernoulli. Phát biểu 2| Đặt các tham số độ lệch trong mỗi tầng của mạng nơ-ron bằng 0 sẽ thay đổi sự cân bằng giữa độ chệch và phương sai sao cho phương sai của mô hình tăng lên và độ chệch của mô hình giảm xuống,"Đúng, Đúng","Sai, Sai","Đúng, Sai","Sai, Đúng",C
