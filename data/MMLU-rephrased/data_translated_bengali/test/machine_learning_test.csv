বিবৃতি ১| সমস্ত নিরপেক্ষ অনুমানকারীদের মধ্যে রৈখিক প্রতিগমন অনুমানকারীর ক্ষুদ্রতম পরিবর্তনশীলতা রয়েছে। বিবৃতি ২| AdaBoost দ্বারা সংযুক্ত শ্রেণীবিভাজকগুলিতে নির্ধারিত α গুণাঙ্কগুলি সর্বদা অঋণাত্মক হয়।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",D
বিবৃতি ১| RoBERTa যে কর্পাসে প্রি-ট্রেইন করে তা BERT যে কর্পাসে প্রি-ট্রেইন করেছিল তার প্রায় ১০ গুণ বড়। বিবৃতি ২| ২০১৮ সালে ResNeXts সাধারণত tanh অ্যাক্টিভেশন ফাংশন ব্যবহার করত।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",C
"বিবৃতি ১| সাপোর্ট ভেক্টর মেশিন, লজিস্টিক রিগ্রেশন মডেলের মতো, একটি ইনপুট উদাহরণ দেওয়া হলে সম্ভাব্য লেবেলগুলির উপর একটি সম্ভাবনা বিতরণ দেয়। বিবৃতি ২| আমরা আশা করব যে সাপোর্ট ভেক্টরগুলি সাধারণভাবে একই থাকবে যখন আমরা একটি লিনিয়ার কার্নেল থেকে উচ্চতর ক্রমের পলিনোমিয়াল কার্নেলে যাব।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
"একটি মেশিন লার্নিং সমস্যায় চারটি বৈশিষ্ট্য এবং একটি শ্রেণি জড়িত। বৈশিষ্ট্যগুলির যথাক্রমে 3, 2, 2, এবং 2টি সম্ভাব্য মান রয়েছে। শ্রেণিটির 3টি সম্ভাব্য মান রয়েছে। সর্বাধিক কতগুলি সম্ভাব্য ভিন্ন উদাহরণ থাকতে পারে?",১২,২৪,৪৮,৭২,D
"২০২০ সাল পর্যন্ত, উচ্চ রেজোলিউশনের ছবি শ্রেণীবদ্ধ করার জন্য কোন আর্কিটেকচার সর্বোত্তম?",কনভলিউশনাল নেটওয়ার্ক,গ্রাফ নেটওয়ার্ক,সম্পূর্ণ সংযুক্ত নেটওয়ার্ক,আরবিএফ নেটওয়ার্ক,A
"বিবৃতি ১| প্রত্যাশা সর্বাধিকরণ অ্যালগরিদমের ক্রমাগত পুনরাবৃত্তির মাধ্যমে ডেটার লগ-সম্ভাব্যতা সর্বদা বৃদ্ধি পাবে।

বিবৃতি ২| Q-লার্নিং এর একটি অসুবিধা হল এটি শুধুমাত্র তখনই ব্যবহার করা যায় যখন শিক্ষার্থীর তার ক্রিয়াকলাপ কীভাবে তার পরিবেশকে প্রভাবিত করে সে সম্পর্কে পূর্ব জ্ঞান থাকে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
আসুন আমরা ধরে নিই যে আমরা আমাদের খরচ ফাংশনের গ্রেডিয়েন্ট গণনা করেছি এবং এটি একটি ভেক্টর g তে সংরক্ষণ করেছি। গ্রেডিয়েন্ট দেওয়া থাকলে একটি গ্রেডিয়েন্ট ডিসেন্ট আপডেটের খরচ কত?,O(D),O(N),O(ND),O(ND^2),A
"বিবৃতি ১| একটি নিরবিচ্ছিন্ন এলোমেলো চলক x এবং তার সম্ভাবনা বণ্টন ফাংশন p(x) এর জন্য, সকল x এর জন্য 0 ≤ p(x) ≤ 1 প্রযোজ্য। বিবৃতি ২| সিদ্ধান্ত বৃক্ষ তথ্য লাভ কমিয়ে শেখানো হয়।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
নিচে দেওয়া বেইজিয়ান নেটওয়ার্কটি বিবেচনা করুন। এই বেইজিয়ান নেটওয়ার্কের জন্য কতগুলি স্বাধীন প্যারামিটার প্রয়োজন H -> U <- P <- W?,২,৪,৮,১৬,C
"যখন প্রশিক্ষণের উদাহরণের সংখ্যা অসীমের দিকে যায়, তখন সেই তথ্যের উপর প্রশিক্ষিত আপনার মডেলের থাকবে:",নিম্ন পরিবর্তনশীলতা,উচ্চতর পরিবর্তনশীলতা,একই পরিবর্তনশীলতা,উপরের কোনোটিই নয়,A
"বিবৃতি ১| দ্বিমাত্রিক তলে সমস্ত আয়তক্ষেত্রের সেট (যার মধ্যে অক্ষ-সমান্তরাল নয় এমন আয়তক্ষেত্রও অন্তর্ভুক্ত) ৫টি বিন্দুর একটি সেটকে বিদীর্ণ করতে পারে। বিবৃতি ২| যখন k = 1, তখন k-নিকটতম প্রতিবেশী শ্রেণিবিন্যাসকারীর VC-মাত্রা অসীম।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
_ একটি মডেলকে বোঝায় যা প্রশিক্ষণ ডেটা মডেল করতে পারে না এবং নতুন ডেটাতে সাধারণীকরণ করতে পারে না।,ভালো ফিটিং,অতিমাত্রায় ফিটিং,আন্ডারফিটিং,উপরের সবগুলো,C
"বিবৃতি ১| ক্লাস উচ্চ অসাম্য সহ ডেটাসেটগুলির জন্য F1 স্কোর বিশেষভাবে উপযোগী হতে পারে।

বিবৃতি ২| ROC কার্ভের নীচের এলাকা হল অস্বাভাবিকতা সনাক্তকারীদের মূল্যায়ন করতে ব্যবহৃত প্রধান মেট্রিক্সগুলির মধ্যে একটি।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"বিবৃতি ১| ব্যাক-প্রপাগেশন অ্যালগরিদম গোপন স্তর সহ একটি বিশ্বব্যাপী অনুকূল নিউরাল নেটওয়ার্ক শেখে। বিবৃতি ২| একটি রেখার VC মাত্রা সর্বোচ্চ ২ হওয়া উচিত, কারণ আমি কমপক্ষে একটি ক্ষেত্রে ৩টি বিন্দু খুঁজে পেতে পারি যা কোনো রেখা দ্বারা বিচ্ছিন্ন করা যায় না।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
উচ্চ এনট্রপি মানে শ্রেণীবিভাগে বিভাজনগুলি হল,বিশুদ্ধ,শুদ্ধ নয়,উপযোগী,অপ্রয়োজনীয়,B
"বিবৃতি ১| মূল ResNet পেপারে ব্যাচ নরমালাইজেশন নয়, লেয়ার নরমালাইজেশন ব্যবহার করা হয়েছে। বিবৃতি ২| DCGANs প্রশিক্ষণ স্থিতিশীল করতে সেলফ-অ্যাটেনশন ব্যবহার করে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
"একটি নির্দিষ্ট ডেটা সেটের জন্য একটি লিনিয়ার রিগ্রেশন মডেল তৈরি করার সময়, আপনি একটি বৈশিষ্ট্যের গুণাঙ্কের তুলনামূলকভাবে উচ্চ ঋণাত্মক মান লক্ষ্য করেন। এটি ইঙ্গিত করে যে",এই বৈশিষ্ট্যটির মডেলের উপর একটি শক্তিশালী প্রভাব রয়েছে (সংরক্ষণ করা উচিত),এই বৈশিষ্ট্যটির মডেলের উপর শক্তিশালী প্রভাব নেই (উপেক্ষা করা উচিত),এই বৈশিষ্ট্যের গুরুত্ব সম্পর্কে অতিরিক্ত তথ্য ছাড়া মন্তব্য করা সম্ভব নয়,কিছুই নির্ধারণ করা যায় না।,C
"একটি নিউরাল নেটওয়ার্কের জন্য, এই কাঠামোগত অনুমানগুলির মধ্যে কোনটি সবচেয়ে বেশি প্রভাবিত করে অন্ডারফিটিং (অর্থাৎ একটি উচ্চ পক্ষপাতযুক্ত মডেল) এবং ওভারফিটিং (অর্থাৎ একটি উচ্চ পরিবর্তনশীল মডেল) এর মধ্যে ট্রেড-অফকে:",গোপন নোডের সংখ্যা,শিক্ষণের হার,প্রাথমিক ওজন নির্বাচন,ধ্রুবক-পদ একক ইনপুট ব্যবহার,A
"পলিনোমিয়াল রিগ্রেশনের ক্ষেত্রে, এই কাঠামোগত অনুমানগুলির মধ্যে কোনটি অন্ডারফিটিং এবং ওভারফিটিংয়ের মধ্যে ভারসাম্যকে সবচেয়ে বেশি প্রভাবিত করে:",বহুপদের ডিগ্রি,আমরা ম্যাট্রিক্স বিপরীতকরণ বা গ্রেডিয়েন্ট অবনমন দ্বারা ওজনগুলি শিখি কিনা,গাউসীয় শব্দের অনুমিত পরিবর্তনশীলতা,ধ্রুবক-পদ একক ইনপুট ব্যবহার,A
"বিবৃতি ১| ২০২০ সাল পর্যন্ত, কিছু মডেল CIFAR-10 এ ৯৮% এর বেশি নির্ভুলতা অর্জন করেছে। বিবৃতি ২| মূল ResNet গুলি Adam অপটিমাইজার দিয়ে অপটিমাইজ করা হয়নি।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
কে-মিনস অ্যালগরিদম,ফিচার স্পেসের মাত্রা নমুনার সংখ্যার চেয়ে বড় না হওয়া প্রয়োজন,যখন K = 1 হয় তখন উদ্দেশ্য ফাংশনের সর্বনিম্ন মান থাকে,একটি নির্দিষ্ট সংখ্যক ক্লাস্টারের জন্য ক্লাসের মধ্যকার পার্থক্য ন্যূনতম করে,যদি এবং কেবলমাত্র যদি প্রাথমিক গড়গুলি নমুনাগুলির কিছু হিসাবে নির্বাচিত করা হয় তবেই বৈশ্বিক অপটিমামে অভিসারিত হয়,C
বিবৃতি ১| VGGNets-এর কনভোলিউশনাল কার্নেলগুলির প্রস্থ এবং উচ্চতা AlexNet-এর প্রথম স্তরের কার্নেলগুলির তুলনায় ছোট। বিবৃতি ২| ব্যাচ নরমালাইজেশনের আগে ডেটা-নির্ভর ওজন প্রারম্ভিকীকরণ পদ্ধতিগুলি প্রবর্তিত হয়েছিল।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"নিম্নলিখিত ম্যাট্রিক্সের র‍্যাঙ্ক কত? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]",০,১,২,৩,B
"বিবৃতি ১| ঘনত্ব অনুমান (যেমন, কার্নেল ঘনত্ব অনুমানকারী ব্যবহার করে) শ্রেণীবিন্যাস করতে ব্যবহার করা যেতে পারে। বিবৃতি ২| লজিস্টিক রিগ্রেশন এবং গাউসীয় নাইভ বেইজ (একক শ্রেণী সহগতি সহ) এর মধ্যে সম্পর্ক মানে যে দুটি শ্রেণীবিন্যাসকারীর পরামিতিগুলির মধ্যে একটি এক-এক সম্পর্ক রয়েছে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",C
"ধরা যাক আমরা স্থানিক তথ্যের উপর ক্লাস্টারিং করতে চাই, যেমন বাড়িগুলির জ্যামিতিক অবস্থান। আমরা বিভিন্ন আকার ও আকৃতির অনেক ক্লাস্টার তৈরি করতে চাই। নিম্নলিখিত পদ্ধতিগুলির মধ্যে কোনটি সবচেয়ে উপযুক্ত?",সিদ্ধান্ত বৃক্ষ,ঘনত্ব-ভিত্তিক ক্লাস্টারিং,মডেল-ভিত্তিক ক্লাস্টারিং,কে-মিনস ক্লাস্টারিং,B
"বিবৃতি ১| অ্যাডাবুস্টে ভুলভাবে শ্রেণীবদ্ধ উদাহরণগুলির ওজন একই গুণনীয় কারক দ্বারা বৃদ্ধি পায়। বিবৃতি ২| অ্যাডাবুস্টে, D_t ওজন সহ প্রশিক্ষণ ডেটার উপর t-তম দুর্বল শ্রেণীবিন্যাসকারীর ভারযুক্ত প্রশিক্ষণ ত্রুটি e_t, t-এর একটি ফাংশন হিসাবে বৃদ্ধি পাওয়ার প্রবণতা দেখায়।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
এমএলই অনুমানগুলি প্রায়শই অবাঞ্ছিত কারণ,তারা পক্ষপাতদুষ্ট,তাদের উচ্চ পরিবর্তনশীলতা রয়েছে,তারা সামঞ্জস্যপূর্ণ পরিমাপক নয়,উপরের কোনোটিই নয়,B
"গ্রেডিয়েন্ট ডিসেন্টের কম্পিউটেশনাল জটিলতা হল,",D এর সাপেক্ষে রৈখিক,N এর সাপেক্ষে রৈখিক,D এর বহুপদী,সংখ্যক পুনরাবৃত্তির উপর নির্ভরশীল,C
একাধিক সিদ্ধান্ত গাছের আউটপুট গড় করা সাহায্য করে _।,পক্ষপাতিত্ব বৃদ্ধি করুন,পক্ষপাতিত্ব হ্রাস করুন,ভিন্নতা বাড়ান,ভিন্নতা কমান,D
"লিনিয়ার রিগ্রেশন প্রয়োগ করে চিহ্নিত বৈশিষ্ট্যের উপসেটের উপর প্রাপ্ত মডেলটি, উপসেট চিহ্নিতকরণ প্রক্রিয়ার শেষে প্রাপ্ত মডেল থেকে ভিন্ন হতে পারে",সর্বোত্তম-উপসেট নির্বাচন,পরবর্তী ধাপে নির্বাচন,পরবর্তী ধাপে ক্রমানুসারে নির্বাচন,উপরের সবগুলো,C
নিউরাল নেটওয়ার্ক,উত্তল উদ্দেশ্য ফাংশন অপটিমাইজ করুন,শুধুমাত্র স্টোকাস্টিক গ্রেডিয়েন্ট ডিসেন্ট দিয়ে প্রশিক্ষণ দেওয়া যেতে পারে,বিভিন্ন অ্যাক্টিভেশন ফাংশনের মিশ্রণ ব্যবহার করা যেতে পারে,উপরের কোনোটিই নয়,C
"ধরা যাক একটি রোগ D-এর প্রাদুর্ভাব প্রতি 100 জনে প্রায় 5টি ক্ষেত্রে (অর্থাৎ, P(D) = 0.05)। বুলিয়ান র‍্যান্ডম ভেরিয়েবল D মানে একজন রোগী ""রোগ D আছে"" এবং বুলিয়ান র‍্যান্ডম ভেরিয়েবল TP মানে ""পরীক্ষায় পজিটিভ""। রোগ D-এর পরীক্ষাগুলি খুব নির্ভুল বলে জানা যায় যেহেতু আপনার রোগ থাকলে পজিটিভ পরীক্ষার সম্ভাবনা 0.99, এবং আপনার রোগ না থাকলে নেগেটিভ পরীক্ষার সম্ভাবনা 0.97। P(TP) কত, অর্থাৎ পজিটিভ পরীক্ষার পূর্ব সম্ভাবনা কত।",০.০৩৬৮,০.৪৭৩,০.০৭৮,উপরের কোনোটিই নয়,C
"বিবৃতি ১| রেডিয়াল বেসিস কার্নেল ফাংশনের মাধ্যমে ফিচার স্পেস Q-তে ম্যাপ করার পরে, অওজনহীন ইউক্লিডীয় দূরত্ব ব্যবহার করে ১-NN মূল স্পেসের তুলনায় ভাল শ্রেণীবিন্যাস কর্মক্ষমতা অর্জন করতে পারে (যদিও আমরা এটি নিশ্চিত করতে পারি না)। বিবৃতি ২| একটি পারসেপ্ট্রনের VC মাত্রা একটি সাধারণ লিনিয়ার SVM-এর VC মাত্রার চেয়ে ছোট।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
গ্রিড সার্চের অসুবিধা হল,এটি অবিভাজ্য ফাংশনগুলিতে প্রয়োগ করা যায় না।,এটি অবিচ্ছিন্ন ফাংশনে প্রয়োগ করা যায় না।,এটা বাস্তবায়ন করা কঠিন।,এটি একাধিক রৈখিক রিগ্রেশনের জন্য যুক্তিসঙ্গতভাবে ধীর গতিতে চলে।,D
একটি অঞ্চলে বিভিন্ন সূচকের উপর ভিত্তি করে বৃষ্টিপাতের পরিমাণ পূর্বাভাস দেওয়া একটি ______ সমস্যা।,তত্ত্বাবধানযুক্ত শিক্ষণ,অতত্ত্বাবধায়িত শিক্ষণ,ক্লাস্টারিং,উপরের কোনোটিই নয়,A
নিম্নলিখিত কোন বাক্যটি রিগ্রেশন সম্পর্কে মিথ্যা?,এটি ইনপুটগুলিকে আউটপুটের সাথে সম্পর্কিত করে।,এটি পূর্বাভাস করার জন্য ব্যবহৃত হয়।,এটি ব্যাখ্যার জন্য ব্যবহার করা যেতে পারে।,এটি কারণ-কার্য সম্পর্ক আবিষ্কার করে,D
নিম্নলিখিতগুলির মধ্যে কোনটি একটি সিদ্ধান্ত বৃক্ষ ছাঁটাইয়ের প্রধান কারণ?,পরীক্ষার সময় কম্পিউটিং সময় বাঁচাতে,সিদ্ধান্ত বৃক্ষ সংরক্ষণের জন্য জায়গা বাঁচাতে,প্রশিক্ষণ সেটের ত্রুটি আরও ছোট করতে,প্রশিক্ষণ সেটের অতিমাত্রায় ফিটিং এড়াতে,D
বিবৃতি ১| কার্নেল ঘনত্ব অনুমানকারী মূল ডেটা সেটের প্রতিটি বিন্দু Xi তে Yi = 1/n মানের সাথে কার্নেল রিগ্রেশন সম্পাদন করার সমতুল্য। বিবৃতি ২| একটি শিক্ষিত সিদ্ধান্ত বৃক্ষের গভীরতা বৃক্ষটি তৈরি করতে ব্যবহৃত প্রশিক্ষণ উদাহরণের সংখ্যার চেয়ে বেশি হতে পারে।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
ধরা যাক আপনার মডেল ওভারফিটিং করছে। নিম্নলিখিত কোনটি ওভারফিটিং কমানোর জন্য একটি বৈধ উপায় নয়?,প্রশিক্ষণ তথ্যের পরিমাণ বাড়ান।,ত্রুটি হ্রাসকরণের জন্য ব্যবহৃত অপটিমাইজেশন অ্যালগরিদমটি উন্নত করুন।,মডেলের জটিলতা কমান।,প্রশিক্ষণ ডেটায় শব্দ কমান।,B
বিবৃতি ১| বহুশ্রেণীর লজিস্টিক রিগ্রেশনে সফটম্যাক্স ফাংশন সাধারণত ব্যবহৃত হয়। বিবৃতি ২| একটি অসম সফটম্যাক্স বিতরণের তাপমাত্রা তার এনট্রপিকে প্রভাবিত করে।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
নিম্নলিখিত কোনটি/কোনগুলি SVM সম্পর্কে সত্য?,"দুই মাত্রিক ডেটা পয়েন্টের জন্য, একটি লিনিয়ার এসভিএম দ্বারা শেখা বিভাজক হাইপারপ্লেন একটি সরল রেখা হবে।","তত্ত্বগতভাবে, একটি গাউসীয় কার্নেল এসভিএম কোনো জটিল বিভাজক হাইপারপ্লেন মডেল করতে পারে না।","প্রতিটি কার্নেল ফাংশনের জন্য যা একটি SVM-এ ব্যবহৃত হয়, একটি সমতুল্য বদ্ধ ফর্ম বেসিস এক্সপানশন পাওয়া যায়।",এসভিএম-এ ওভারফিটিং সাপোর্ট ভেক্টরের সংখ্যার একটি ফাংশন নয়।,A
"নিম্নলিখিত কোনটি প্রদত্ত বেইজিয়ান নেটওয়ার্ক H -> U <- P <- W দ্বারা বর্ণিত H, U, P এবং W এর যৌথ সম্ভাবনা? [দ্রষ্টব্য: শর্তাধীন সম্ভাবনাগুলির গুণফল হিসাবে]","P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)","পি(এইচ, ইউ, পি, ডব্লিউ) = পি(এইচ) * পি(ডব্লিউ) * পি(পি | ডব্লিউ) * পি(ডব্লিউ | এইচ, পি)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)",উপরের কোনোটিই নয়,C
"বিবৃতি ১| যেহেতু রেডিয়াল বেস কার্নেল সহ একটি SVM-এর VC মাত্রা অসীম, এমন একটি SVM অবশ্যই পলিনোমিয়াল কার্নেল সহ একটি SVM-এর চেয়ে খারাপ হতে হবে যার একটি সীমিত VC মাত্রা রয়েছে। বিবৃতি ২| লিনিয়ার অ্যাক্টিভেশন ফাংশন সহ একটি দুই স্তরের নিউরাল নেটওয়ার্ক মূলত লিনিয়ার সেপারেটরগুলির একটি ওজনযুক্ত সংমিশ্রণ, যা একটি নির্দিষ্ট ডেটাসেটে প্রশিক্ষিত; লিনিয়ার সেপারেটরগুলির উপর নির্মিত বুস্টিং অ্যালগরিদমও লিনিয়ার সেপারেটরগুলির একটি সংমিশ্রণ খুঁজে পায়, তাই এই দুটি অ্যালগরিদম একই ফলাফল দেবে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
বিবৃতি ১| ID3 অ্যালগরিদম সর্বোত্তম সিদ্ধান্ত বৃক্ষ খুঁজে পাওয়ার নিশ্চয়তা দেয়। বিবৃতি ২| একটি নিরবিচ্ছিন্ন সম্ভাব্যতা বণ্টন বিবেচনা করুন যার ঘনত্ব f() সর্বত্র অশূন্য। একটি মান x এর সম্ভাব্যতা f(x) এর সমান।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
"একটি নিউরাল নেট দেওয়া আছে যার N টি ইনপুট নোড, কোনো হিডেন লেয়ার নেই, একটি আউটপুট নোড আছে, এন্ট্রপি লস এবং সিগময়েড অ্যাক্টিভেশন ফাংশন সহ, নিম্নলিখিত কোন অ্যালগরিদমগুলি (যথাযথ হাইপার-প্যারামিটার এবং ইনিশিয়ালাইজেশন সহ) গ্লোবাল অপটিমাম খুঁজে পেতে ব্যবহার করা যেতে পারে?",স্টোকাস্টিক গ্রেডিয়েন্ট ডিসেন্ট,মিনি-ব্যাচ গ্রেডিয়েন্ট ডিসেন্ট,ব্যাচ গ্রেডিয়েন্ট ডিসেন্ট,উপরের সবগুলো,D
"লিনিয়ার মডেলে আরও বেসিস ফাংশন যোগ করা, সবচেয়ে সম্ভাব্য বিকল্পটি বেছে নিন:",মডেল পক্ষপাতিত্ব হ্রাস করে,পূর্বাভাস পক্ষপাত হ্রাস করে,ভিন্নতা হ্রাস করে,পক্ষপাতিত্ব এবং পরিবর্তনশীলতাকে প্রভাবিত করে না,A
নিচে দেওয়া বেইজিয়ান নেটওয়ার্কটি বিবেচনা করুন। যদি আমরা স্বাধীনতা বা শর্তাধীন স্বাধীনতা সম্পর্কে কোনও অনুমান না করি তবে আমাদের কতগুলি স্বাধীন প্যারামিটার প্রয়োজন হবে H -> U <- P <- W?,৩,৪,৭,১৫,D
আউট-অফ-ডিস্ট্রিবিউশন ডিটেকশনের আরেকটি পরিভাষা কী?,অস্বাভাবিকতা সনাক্তকরণ,একক-শ্রেণি সনাক্তকরণ,ট্রেন-টেস্ট অমিল সহনশীলতা,পটভূমি সনাক্তকরণ,A
"বিবৃতি ১| আমরা দুর্বল শিক্ষার্থীদের h কে বুস্টিং করে একটি শ্রেণীবিভাজক f শিখি। f এর সিদ্ধান্ত সীমার কার্যকরী রূপটি h এর মতোই, তবে ভিন্ন পরামিতি সহ। (যেমন, যদি h একটি রৈখিক শ্রেণীবিভাজক হয়, তাহলে f-ও একটি রৈখিক শ্রেণীবিভাজক)। বিবৃতি ২| বুস্টিং-এ পুনরাবৃত্তির সংখ্যা নির্বাচন করতে ক্রস ভ্যালিডেশন ব্যবহার করা যেতে পারে; এই পদ্ধতিটি অতিফিটিং কমাতে সাহায্য করতে পারে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",D
বিবৃতি ১| হাইওয়ে নেটওয়ার্কগুলি ResNets এর পরে প্রবর্তিত হয়েছিল এবং কনভোলিউশনের পক্ষে ম্যাক্স পুলিং পরিহার করে। বিবৃতি ২| DenseNets সাধারণত ResNets এর তুলনায় বেশি মেমরি ব্যয় করে।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",D
"যদি N প্রশিক্ষণ ডেটাসেটের উদাহরণের সংখ্যা হয়, তাহলে নিকটতম প্রতিবেশীর শ্রেণীবিন্যাসের চালানোর সময় হবে",O(1),O( N ),O(লগ N),O( N^2 ),B
"বিবৃতি ১| মূল ResNets এবং ট্রান্সফরমারগুলি হল ফিডফরওয়ার্ড নিউরাল নেটওয়ার্ক। বিবৃতি ২| মূল ট্রান্সফরমারগুলি সেলফ-অ্যাটেনশন ব্যবহার করে, কিন্তু মূল ResNet তা করে না।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"বিবৃতি ১| RELUs মনোটোনিক নয়, কিন্তু সিগময়েডগুলি মনোটোনিক। বিবৃতি ২| উচ্চ সম্ভাবনার সাথে গ্রেডিয়েন্ট ডিসেন্ট দিয়ে প্রশিক্ষিত নিউরাল নেটওয়ার্কগুলি গ্লোবাল অপটিমামে পৌঁছায়।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",D
একটি নিউরাল নেটওয়ার্কের সিগময়েড নোডের সংখ্যাগত আউটপুট:,"অসীম, সমস্ত বাস্তব সংখ্যাকে অন্তর্ভুক্ত করে।","অসীম, সমস্ত পূর্ণসংখ্যাকে অন্তর্ভুক্ত করে।",০ এবং ১ এর মধ্যে সীমাবদ্ধ।,-১ এবং ১ এর মধ্যে সীমাবদ্ধ।,C
নিম্নলিখিতগুলির মধ্যে কোনটি শুধুমাত্র তখনই ব্যবহার করা যেতে পারে যখন প্রশিক্ষণ তথ্য রৈখিকভাবে বিচ্ছেদযোগ্য?,রৈখিক হার্ড-মার্জিন এসভিএম,রৈখিক লজিস্টিক রিগ্রেশন,লিনিয়ার সফট মার্জিন এসভিএম,কেন্দ্রক পদ্ধতি।,A
নিম্নলিখিত কোনগুলি স্থানিক ক্লাস্টারিং অ্যালগরিদম?,বিভাজন ভিত্তিক ক্লাস্টারিং,কে-মিনস ক্লাস্টারিং,গ্রিড ভিত্তিক ক্লাস্টারিং,উপরের সবগুলো,D
বিবৃতি ১| সাপোর্ট ভেক্টর মেশিনগুলি যে সর্বোচ্চ মার্জিন সিদ্ধান্ত সীমানা তৈরি করে তার সকল রৈখিক শ্রেণিবিভাজকের মধ্যে সর্বনিম্ন সাধারণীকরণ ত্রুটি রয়েছে। বিবৃতি ২| শ্রেণি-শর্তাধীন গাউসীয় বণ্টন সহ একটি জেনারেটিভ মডেল থেকে আমরা যে কোনও সিদ্ধান্ত সীমানা পাই তা নীতিগতভাবে একটি এসভিএম এবং তিন বা তার কম ডিগ্রির একটি পলিনোমিয়াল কার্নেল দিয়ে পুনরুত্পাদন করা যেতে পারে।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",D
"বিবৃতি ১| লিনিয়ার মডেলের L2 নিয়মিতকরণ L1 নিয়মিতকরণের তুলনায় মডেলগুলিকে আরও বিরল করে তোলে।
বিবৃতি ২| অবশিষ্ট সংযোগ ResNets এবং ট্রান্সফরমারগুলিতে পাওয়া যায়।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",D
"ধরা যাক আমরা P(H|E, F) গণনা করতে চাই এবং আমাদের কাছে কোনো শর্তাধীন স্বাধীনতার তথ্য নেই। নিম্নলিখিত সংখ্যার সেটগুলির মধ্যে কোনটি গণনার জন্য যথেষ্ট?","পি(ই, এফ), পি(এইচ), পি(ই|এইচ), পি(এফ|এইচ)","P(E, F), P(H), P(E, F|H)","পি(এইচ), পি(ই|এইচ), পি(এফ|এইচ)","P(E, F), P(E|H), P(F|H)",B
নিম্নলিখিতগুলির মধ্যে কোনটি ব্যাগিং করার সময় ওভারফিটিং প্রতিরোধ করে?,নমুনা প্রযুক্তি হিসাবে প্রতিস্থাপনের সাথে নমুনা সংগ্রহের ব্যবহার,দুর্বল শ্রেণীবিভাজকের ব্যবহার,অতিমাত্রায় ফিটিং-এর প্রবণতা নেই এমন শ্রেণীবিভাজন অ্যালগরিদমগুলির ব্যবহার,প্রতিটি প্রশিক্ষিত শ্রেণীবিভাজকের উপর সম্পাদিত বৈধতা যাচাইয়ের অনুশীলন,B
"বিবৃতি ১| পিসিএ এবং স্পেকট্রাল ক্লাস্টারিং (যেমন অ্যান্ড্রু এনজি-এর) দুটি ভিন্ন ম্যাট্রিক্সের উপর আইগেন বিশ্লেষণ সম্পাদন করে। তবে, এই দুটি ম্যাট্রিক্সের আকার একই। বিবৃতি ২| যেহেতু শ্রেণীবিন্যাস রিগ্রেশনের একটি বিশেষ ক্ষেত্র, লজিস্টিক রিগ্রেশন লিনিয়ার রিগ্রেশনের একটি বিশেষ ক্ষেত্র।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
"বিবৃতি ১| স্ট্যানফোর্ড সেন্টিমেন্ট ট্রিব্যাংকে বই পর্যালোচনা নয়, চলচ্চিত্র পর্যালোচনা ছিল। বিবৃতি ২| পেন ট্রিব্যাংক ভাষা মডেলিং এর জন্য ব্যবহৃত হয়েছে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"নিম্নলিখিত ম্যাট্রিক্সের শূন্য স্থানের মাত্রিকতা কত? A = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]]",০,১,২,৩,C
সাপোর্ট ভেক্টর কী?,সিদ্ধান্ত সীমানা থেকে সবচেয়ে দূরের উদাহরণগুলি।,এসভিএম-এ f(x) গণনা করার জন্য শুধুমাত্র প্রয়োজনীয় উদাহরণগুলি।,ডেটা কেন্দ্রবিন্দু।,এসভিএম-এ যে সকল উদাহরণের একটি অশূন্য ওজন αk রয়েছে।,B
"বিবৃতি ১| ওয়ার্ড২ভেক পরামিতিগুলি একটি সীমিত বোল্টজম্যান মেশিন ব্যবহার করে আরম্ভ করা হয়নি।

বিবৃতি ২| tanh ফাংশনটি একটি অরৈখিক সক্রিয়করণ ফাংশন।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"আপনার প্রশিক্ষণ ক্ষতি যদি এপোক সংখ্যার সাথে বৃদ্ধি পায়, তাহলে শিক্ষণ প্রক্রিয়ার সাথে নিম্নলিখিত কোনটি একটি সম্ভাব্য সমস্যা হতে পারে?",রেগুলারাইজেশন খুব কম এবং মডেল ওভারফিটিং করছে,রেগুলারাইজেশন অত্যধিক উচ্চ এবং মডেল আন্ডারফিটিং করছে,পদক্ষেপের আকার অত্যন্ত বড়,পদক্ষেপের আকার খুব ছোট,C
"ধরা যাক একটি রোগ D-এর প্রাদুর্ভাব প্রতি ১০০ জনে ৫টি ক্ষেত্রে (অর্থাৎ, P(D) = 0.05)। বুলিয়ান র‍্যান্ডম ভেরিয়েবল D মানে একজন রোগী ""রোগ D আছে"" এবং বুলিয়ান র‍্যান্ডম ভেরিয়েবল TP মানে ""পরীক্ষায় পজিটিভ""। রোগ D-এর পরীক্ষাগুলি খুব নির্ভুল বলে জানা যায় যেহেতু আপনার রোগ থাকলে পজিটিভ পরীক্ষার সম্ভাবনা 0.99, এবং আপনার রোগ না থাকলে নেগেটিভ পরীক্ষার সম্ভাবনা 0.97। P(D | TP) কত, অর্থাৎ পরীক্ষা পজিটিভ হলে আপনার রোগ D থাকার পরবর্তী সম্ভাবনা কত?",০.০৪৯৫,০.০৭৮,০.৬৩৫,০.৯৭,C
"বিবৃতি ১| প্রথাগত মেশিন লার্নিং ফলাফলগুলি ধরে নেয় যে প্রশিক্ষণ এবং পরীক্ষা সেটগুলি স্বাধীন এবং একইভাবে বিতরণ করা হয়। বিবৃতি ২| ২০১৭ সালে, COCO মডেলগুলি সাধারণত ImageNet এ প্রি-ট্রেইন করা হত।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"বিবৃতি ১| একই প্রশিক্ষণ সেটে দুটি ভিন্ন কার্নেল K1(x, x0) এবং K2(x, x0) দ্বারা প্রাপ্ত মার্জিনের মানগুলি আমাদের বলে না যে কোন শ্রেণিবিন্যাসকারী পরীক্ষা সেটে ভালো কাজ করবে। বিবৃতি ২| BERT-এর সক্রিয়করণ ফাংশন হল GELU।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
নিম্নলিখিতগুলির মধ্যে কোনটি মেশিন লার্নিংয়ে একটি ক্লাস্টারিং অ্যালগরিদম?,প্রত্যাশা সর্বাধিকরণ,কার্ট,গাউসীয় নাইভ বেইজ,অপ্রিওরি,A
"আপনি স্প্যাম শ্রেণীবিন্যাসের জন্য একটি সিদ্ধান্ত বৃক্ষ প্রশিক্ষণ শেষ করেছেন, এবং এটি আপনার প্রশিক্ষণ এবং পরীক্ষা উভয় সেটেই অস্বাভাবিকভাবে খারাপ কর্মক্ষমতা পাচ্ছে। আপনি জানেন যে আপনার বাস্তবায়নে কোনো বাগ নেই, তাহলে কী সমস্যার কারণ হতে পারে?",আপনার সিদ্ধান্ত গাছগুলি খুব অগভীর।,আপনাকে শিক্ষণের হার বাড়াতে হবে।,আপনি অতিমাত্রায় ফিটিং করছেন।,উপরের কোনোটিই নয়।,A
K-ফোল্ড ক্রস-ভ্যালিডেশন হল,কে-তে রৈখিক,K এর বর্গাকার,কে-তে ঘনক,K এর ঘাতীয়,A
"বিবৃতি ১| শিল্প-স্তরের নিউরাল নেটওয়ার্কগুলি সাধারণত জিপিইউ নয়, সিপিইউতে প্রশিক্ষণ দেওয়া হয়। বিবৃতি ২| ResNet-50 মডেলে ১ বিলিয়নেরও বেশি প্যারামিটার রয়েছে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
"দুটি বুলিয়ান র‍্যান্ডম ভেরিয়েবল A এবং B দেওয়া আছে, যেখানে P(A) = 1/2, P(B) = 1/3, এবং P(A | ¬B) = 1/4, P(A | B) কত?",১/৬,১/৪,৩/৪,১,D
এআই দ্বারা সৃষ্ট অস্তিত্বগত ঝুঁকিগুলি সাধারণত নিম্নলিখিত কোন অধ্যাপকদের সাথে সবচেয়ে বেশি সম্পর্কিত?,নান্দো দে ফ্রেইতাস,ইয়ান লেকুন,স্টুয়ার্ট রাসেল,জিতেন্দ্র মালিক,C
বিবৃতি ১| লজিস্টিক রিগ্রেশন মডেলের সম্ভাব্যতা সর্বাধিক করা হলে একাধিক স্থানীয় সর্বোচ্চ মান পাওয়া যায়। বিবৃতি ২| যদি ডেটার বিতরণ জানা থাকে তবে কোনো ক্লাসিফায়ার নাইভ বেইজ ক্লাসিফায়ারের চেয়ে ভালো কাজ করতে পারে না।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
"কার্নেল রিগ্রেশনের ক্ষেত্রে, এই কাঠামোগত অনুমানগুলির মধ্যে কোনটি অন্ডারফিটিং এবং ওভারফিটিংয়ের মধ্যে ভারসাম্যকে সবচেয়ে বেশি প্রভাবিত করে:",কার্নেল ফাংশন গাউসীয় নাকি ত্রিকোণাকার নাকি বাক্স-আকৃতির কিনা,আমরা ইউক্লিডিয়ান বনাম L1 বনাম L∞ মেট্রিক্স ব্যবহার করি কিনা,কার্নেল প্রস্থ,কার্নেল ফাংশনের সর্বোচ্চ উচ্চতা,C
"বিবৃতি ১| SVM শিক্ষণ অ্যালগরিদম তার উদ্দেশ্য ফাংশনের সাপেক্ষে বিশ্বব্যাপী সর্বোত্তম প্রকল্পটি খুঁজে পাওয়ার নিশ্চয়তা দেয়।

বিবৃতি ২| একটি রেডিয়াল বেসিস কার্নেল ফাংশনের মাধ্যমে বৈশিষ্ট্য স্থান Q-তে ম্যাপ করার পরে, একটি পারসেপট্রন তার মূল স্থানের তুলনায় আরও ভাল শ্রেণীবিভাগ কর্মক্ষমতা অর্জন করতে পারে (যদিও আমরা এটি নিশ্চিত করতে পারি না)।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"একটি গাউসীয় বেইজ শ্রেণিবিন্যাসকারীর জন্য, এই কাঠামোগত অনুমানগুলির মধ্যে কোনটি অন্ডারফিটিং এবং ওভারফিটিংয়ের মধ্যে ভারসাম্যকে সবচেয়ে বেশি প্রভাবিত করে:",আমরা ক্লাস সেন্টারগুলি সর্বোচ্চ সম্ভাবনা বা গ্রেডিয়েন্ট ডিসেন্ট দ্বারা শিখি কিনা,আমরা পূর্ণ শ্রেণি সহগতি ম্যাট্রিক্স বা কর্ণাকার শ্রেণি সহগতি ম্যাট্রিক্স ধরে নিই কিনা,আমাদের সমান ক্লাস প্রায়োর আছে কিনা বা ডেটা থেকে অনুমানিত প্রায়োর আছে কিনা।,আমরা ক্লাসগুলিকে বিভিন্ন গড় ভেক্টর থাকতে দিই কিনা বা আমরা তাদেরকে একই গড় ভেক্টর শেয়ার করতে বাধ্য করি কিনা,B
বিবৃতি ১| প্রশিক্ষণ তথ্যের সেট ছোট হলে ওভারফিটিং হওয়ার সম্ভাবনা বেশি থাকে। বিবৃতি ২| হাইপোথেসিস স্পেস ছোট হলে ওভারফিটিং হওয়ার সম্ভাবনা বেশি থাকে।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",D
"বিবৃতি ১| ইএম ছাড়াও, গ্রেডিয়েন্ট ডিসেন্ট ব্যবহার করে গাউসিয়ান মিশ্রণ মডেলে অনুমান বা শিক্ষণ সম্পাদন করা যেতে পারে। বিবৃতি ২ | নির্দিষ্ট সংখ্যক বৈশিষ্ট্য ধরে নিয়ে, একটি গাউসিয়ান-ভিত্তিক বেইজ অপটিমাল ক্লাসিফায়ার ডেটাসেটে রেকর্ডের সংখ্যার সাথে রৈখিক সময়ে শেখানো যেতে পারে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"বিবৃতি ১| একটি বেইজিয়ান নেটওয়ার্কে, জংশন ট্রি অ্যালগরিদমের অনুমান ফলাফল এবং ভেরিয়েবল এলিমিনেশনের অনুমান ফলাফল একই হয়।

বিবৃতি ২| যদি দুটি র‍্যান্ডম ভেরিয়েবল X এবং Y অন্য একটি র‍্যান্ডম ভেরিয়েবল Z দেওয়া থাকলে শর্তাধীন স্বাধীন হয়, তাহলে সংশ্লিষ্ট বেইজিয়ান নেটওয়ার্কে, X এবং Y এর নোডগুলি Z দেওয়া থাকলে d-সেপারেটেড হয়।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",C
"হৃদরোগে আক্রান্ত রোগীদের বৃহৎ চিকিৎসা রেকর্ডের ডেটাসেট দেওয়া আছে, এই রোগীদের মধ্যে বিভিন্ন ক্লাস্টার থাকতে পারে কিনা তা জানার চেষ্টা করুন যার জন্য আমরা পৃথক চিকিৎসা পদ্ধতি তৈরি করতে পারি। এটি কি ধরনের শিক্ষণ সমস্যা?",তত্ত্বাবধানযুক্ত শিক্ষণ,অতত্ত্বাবধায়িত শিক্ষণ,উভয় (ক) এবং (খ),না (ক) এবং না (খ),B
পিসিএ-তে আপনি কী করবেন এসভিডি-এর মতো একই প্রক্ষেপণ পেতে?,ডেটাকে শূন্য গড়ে রূপান্তর করুন,ডেটাকে শূন্য মধ্যমানে রূপান্তর করুন,সম্ভব নয়,এগুলোর কোনোটিই নয়,A
"বিবৃতি ১| ১-নিকটতম প্রতিবেশী শ্রেণিবিন্যাসকারীর প্রশিক্ষণ ত্রুটি ০। বিবৃতি ২| যেহেতু ডেটা পয়েন্টের সংখ্যা অসীমের দিকে বাড়ে, MAP অনুমান সকল সম্ভাব্য পূর্বানুমানের জন্য MLE অনুমানের দিকে এগিয়ে যায়। অন্য কথায়, যথেষ্ট ডেটা দেওয়া থাকলে, পূর্বানুমানের পছন্দ অপ্রাসঙ্গিক হয়ে যায়।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",C
"যখন নিয়মিতকরণের সাথে লিস্ট-স্কোয়ার্স রিগ্রেশন করা হয় (ধরে নিয়ে যে অপটিমাইজেশন সঠিকভাবে করা যেতে পারে), নিয়মিতকরণ প্যারামিটার λ এর মান বাড়ালে পরীক্ষণ ত্রুটি।",কখনই প্রশিক্ষণ ত্রুটি কমাবে না।,কখনই প্রশিক্ষণ ত্রুটি বাড়াবে না।,কখনও পরীক্ষণের ত্রুটি কমাবে না।,কখনও বৃদ্ধি পাবে না,A
নিম্নলিখিতগুলির মধ্যে কোনটি সর্বোত্তমভাবে বর্ণনা করে যে বৈষম্যমূলক পদ্ধতিগুলি কী মডেল করার চেষ্টা করে? (w হল মডেলের পরামিতিগুলি),"p(y|x, w)","p(y, x)","p(w|x, w)",উপরের কোনোটিই নয়,A
বিবৃতি ১| কনভোলিউশন নিউরাল নেটওয়ার্কের জন্য CIFAR-10 শ্রেণীবিন্যাসের কর্মক্ষমতা ৯৫% অতিক্রম করতে পারে। বিবৃতি ২| নিউরাল নেটওয়ার্কের এনসেম্বল শ্রেণীবিন্যাসের নির্ভুলতা উন্নত করে না কারণ তারা যে প্রতিনিধিত্ব শেখে তা অত্যন্ত সম্পর্কিত।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",C
নিম্নলিখিত কোন বিষয়গুলিতে বেইসিয়ানরা এবং ফ্রিকুয়েন্টিস্টরা একমত হবেন না?,নন-গাউসীয় শব্দ মডেল ব্যবহার করে সম্ভাব্যতামূলক রিগ্রেশন।,রিগ্রেশনের জন্য সম্ভাব্যতামূলক মডেলিং এর ব্যবহার।,প্রায়িকতা মডেলে পরামিতিগুলির উপর পূর্ববর্তী বিতরণের ব্যবহার।,গাউসীয় বৈষম্য বিশ্লেষণে ক্লাস প্রায়োরের ব্যবহার।,C
"বিবৃতি ১| BLEU মেট্রিক প্রিসিশন ব্যবহার করে, যেখানে ROGUE মেট্রিক রিকল ব্যবহার করে। বিবৃতি ২| ইংরেজি বাক্য মডেল করার জন্য হিডেন মারকভ মডেল প্রায়শই ব্যবহৃত হত।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
বিবৃতি ১| ImageNet-এ বিভিন্ন রেজোলিউশনের ছবি রয়েছে। বিবৃতি ২| Caltech-101-এ ImageNet-এর তুলনায় বেশি ছবি রয়েছে।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",C
নিম্নলিখিতগুলির মধ্যে কোনটি বৈশিষ্ট্য নির্বাচন করার জন্য অধিক উপযুক্ত?,রিজ,লাসো,উভয় (ক) এবং (খ),না (ক) এবং না (খ),B
ধরুন আপনাকে একটি EM অ্যালগরিদম দেওয়া হয়েছে যা গোপন চলক সহ একটি মডেলের জন্য সর্বোচ্চ সম্ভাবনা অনুমান খুঁজে বের করে। আপনাকে অ্যালগরিদমটি পরিবর্তন করতে বলা হয়েছে যাতে এটি MAP অনুমান খুঁজে পায়। আপনাকে কোন ধাপ বা ধাপগুলি পরিবর্তন করতে হবে?,প্রত্যাশা,সর্বাধিকীকরণ,কোনো পরিবর্তন প্রয়োজন নেই,উভয়,B
"একটি গাউসীয় বেইজ শ্রেণিবিন্যাসকারীর জন্য, এই কাঠামোগত অনুমানগুলির মধ্যে কোনটি অন্ডারফিটিং এবং ওভারফিটিংয়ের মধ্যে ভারসাম্যকে সবচেয়ে বেশি প্রভাবিত করে:",আমরা ক্লাস সেন্টারগুলি সর্বোচ্চ সম্ভাবনা বা গ্রেডিয়েন্ট ডিসেন্ট দ্বারা শিখি কিনা,আমরা পূর্ণ শ্রেণি সহগতি ম্যাট্রিক্স বা কর্ণাকার শ্রেণি সহগতি ম্যাট্রিক্স ধরে নিই কিনা,আমাদের সমান ক্লাস প্রায়োর আছে কিনা বা ডেটা থেকে অনুমানিত প্রায়োর আছে কিনা,আমরা ক্লাসগুলিকে বিভিন্ন গড় ভেক্টর থাকতে দিই কিনা বা আমরা তাদেরকে একই গড় ভেক্টর শেয়ার করতে বাধ্য করি কিনা,B
"বিবৃতি ১| যেকোনো দুটি চলক x এবং y যাদের যৌথ বিতরণ p(x, y), আমাদের সবসময় H[x, y] ≥ H[x] + H[y] থাকে যেখানে H হল এন্ট্রপি ফাংশন। বিবৃতি ২| কিছু নির্দেশিত গ্রাফের ক্ষেত্রে, নৈতিকীকরণ গ্রাফে বিদ্যমান প্রান্তের সংখ্যা কমিয়ে দেয়।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",B
নিম্নলিখিতগুলির মধ্যে কোনটি তত্ত্বাবধায়ক শিক্ষণ নয়?,পিসিএ,সিদ্ধান্ত বৃক্ষ,রৈখিক প্রতিগমন,নাইভ বেইজিয়ান,A
বিবৃতি ১| একটি নিউরাল নেটওয়ার্কের কনভার্জেন্স শিক্ষণ হারের উপর নির্ভর করে। বিবৃতি ২| ড্রপআউট এলোমেলোভাবে নির্বাচিত সক্রিয়করণ মানগুলিকে শূন্য দিয়ে গুণ করে।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"নিম্নলিখিতগুলির মধ্যে কোনটি P(A, B, C) এর সমান, যেখানে A, B এবং C হল বুলিয়ান র‍্যান্ডম ভেরিয়েবল, এবং তাদের মধ্যে কোনো স্বাধীনতা বা শর্তাধীন স্বাধীনতার অনুমান নেই?",P(A | B) * P(B | C) * P(C | A),"P(C | A, B) * P(A) * P(B)","P(A, B | C) * P(C)","পি(এ | বি, সি) * পি(বি | এ, সি) * পি(সি | এ, বি)",C
নিম্নলিখিত কাজগুলির মধ্যে কোনটি ক্লাস্টারিং ব্যবহার করে সবচেয়ে ভালভাবে সমাধান করা যেতে পারে?,বিভিন্ন সংকেতের উপর ভিত্তি করে বৃষ্টিপাতের পরিমাণ পূর্বাভাস করা,প্রতারণামূলক ক্রেডিট কার্ড লেনদেন সনাক্তকরণ,একটি রোবটকে একটি গোলকধাঁধা সমাধান করতে প্রশিক্ষণ দেওয়া,উপরের সবগুলো,B
"লিনিয়ার রিগ্রেশনে একটি নিয়মিতকরণ জরিমানা প্রয়োগ করার পর, আপনি দেখতে পান যে w এর কিছু গুণাঙ্ক শূন্য হয়ে গেছে। নিম্নলিখিত জরিমানাগুলির মধ্যে কোনটি ব্যবহার করা হতে পারে?",L0 নর্ম,এল১ নর্ম,L2 নর্ম,হয় (ক) অথবা (খ),D
"A এবং B দুটি ঘটনা। যদি P(A, B) কমে যায় যখন P(A) বাড়ে, তাহলে নিম্নলিখিতগুলির মধ্যে কোনটি সত্য?",P(A|B) কমে যায়,P(B|A) কমে যায়,P(B) হ্রাস পায়,উপরের সবগুলো,B
"বিবৃতি ১| যখন একটি নির্দিষ্ট পর্যবেক্ষণ সেটের জন্য একটি HMM শেখা হয়, ধরে নিন আমরা প্রকৃত গোপন অবস্থার সংখ্যা জানি না (যা প্রায়শই ঘটে), আমরা সর্বদা আরও গোপন অবস্থার অনুমতি দিয়ে প্রশিক্ষণ ডেটার সম্ভাব্যতা বাড়াতে পারি। বিবৃতি ২| সহযোগিতামূলক ফিল্টারিং প্রায়শই ব্যবহারকারীদের চলচ্চিত্র পছন্দ মডেলিং করার জন্য একটি উপযোগী মডেল।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
"আপনি একটি সরল অনুমান কাজের জন্য একটি লিনিয়ার রিগ্রেশন মডেল প্রশিক্ষণ দিচ্ছেন, এবং লক্ষ্য করেছেন যে মডেলটি ডেটার সাথে অতিমাত্রায় খাপ খাইয়ে নিচ্ছে। আপনি ওজনগুলিকে শাস্তি দেওয়ার জন্য $\ell_2$ নিয়মিতকরণ যোগ করার সিদ্ধান্ত নেন। আপনি যখন $\ell_2$ নিয়মিতকরণ গুণাঙ্ক বাড়াবেন, তখন মডেলের পক্ষপাতিত্ব এবং পরিবর্তনশীলতার কী হবে?",পক্ষপাতিত্ব বৃদ্ধি ; পরিবর্তনশীলতা বৃদ্ধি,পক্ষপাতিত্ব বৃদ্ধি ; পরিবর্তনশীলতা হ্রাস,পক্ষপাতিত্ব হ্রাস ; পরিবর্তনশীলতা বৃদ্ধি,পক্ষপাতিত্ব হ্রাস ; পরিবর্তনশীলতা হ্রাস,B
"কোন PyTorch 1.8 কমান্ড(গুলি) একটি $10\times 5$ গাউসীয় ম্যাট্রিক্স উৎপন্ন করে যার প্রতিটি এন্ট্রি স্বাধীনভাবে এবং সমবিতরণে $\mathcal{N}(\mu=5,\sigma^2=16)$ থেকে নমুনা নেওয়া হয় এবং একটি $10\times 10$ সমঘন ম্যাট্রিক্স যার প্রতিটি এন্ট্রি স্বাধীনভাবে এবং সমবিতরণে $U[-1,1)$ থেকে নমুনা নেওয়া হয়?","\texttt{5 + torch.randn(10,5) * 16} ; \texttt{torch.rand(10,10,low=-1,high=1)}","\texttt{5 + torch.randn(10,5) * 16} ; \texttt{(torch.rand(10,10) - 0.5) / 0.5}","৫ + টর্চ.র্যান্ডন(১০,৫) * ৪ ; ২ * টর্চ.র্যান্ড(১০,১০) - ১","\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \texttt{2 * torch.rand(10,10) - 1}",C
"বিবৃতি ১| ReLU এর গ্রেডিয়েন্ট শূন্য যখন $x<0$, এবং সিগময়েড গ্রেডিয়েন্ট $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ সকল $x$ এর জন্য। বিবৃতি ২| সিগময়েডের একটি নিরবচ্ছিন্ন গ্রেডিয়েন্ট আছে এবং ReLU এর একটি বিচ্ছিন্ন গ্রেডিয়েন্ট আছে।","সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",A
ব্যাচ নরমালাইজেশন সম্পর্কে কোনটি সত্য?,"ব্যাচ নরমালাইজেশন প্রয়োগের পর, লেয়ারের অ্যাক্টিভেশনগুলি একটি স্ট্যান্ডার্ড গাউসীয় বিতরণ অনুসরণ করবে।",অ্যাফাইন স্তরের বায়াস প্যারামিটার অপ্রয়োজনীয় হয়ে যায় যদি একটি ব্যাচ নর্মালাইজেশন স্তর তার পরপরই অনুসরণ করে।,ব্যাচ নরমালাইজেশন ব্যবহার করার সময় স্ট্যান্ডার্ড ওজন ইনিশিয়ালাইজেশন পরিবর্তন করতে হবে।,ব্যাচ নরমালাইজেশন কনভলিউশনাল নিউরাল নেটওয়ার্কের জন্য লেয়ার নরমালাইজেশনের সমতুল্য।,B
ধরা যাক আমাদের নিম্নলিখিত উদ্দেশ্য ফাংশন রয়েছে: $\argmin_{w} \frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\gamma \norm{w}^2_2$ $\frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\lambda \norm{w}^2_2$ এর $w$ এর সাপেক্ষে গ্রেডিয়েন্ট কী?,$\nabla_w f(w) = (X^\top X + \lambda I)w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + (\lambda+1) w$,C
নিম্নলিখিত কোনটি একটি কনভোলিউশন কার্নেলের ক্ষেত্রে সত্য?,একটি ছবিকে $\begin{bmatrix}1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ দিয়ে কনভলভ করলে ছবিটি পরিবর্তিত হবে না,একটি ছবিকে $\begin{bmatrix}0 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ দিয়ে কনভলভ করলে ছবিটি পরিবর্তিত হবে না,একটি ছবিকে $\begin{bmatrix}1 & 1 & 1\\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}$ দিয়ে কনভলভ করলে ছবিটি পরিবর্তিত হবে না,একটি ছবিকে $\begin{bmatrix}0 & 0 & 0\\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ দিয়ে কনভলভ করলে ছবিটি পরিবর্তিত হবে না,B
নিম্নলিখিতগুলির মধ্যে কোনটি মিথ্যা?,"সিম্যান্টিক সেগমেন্টেশন মডেলগুলি প্রতিটি পিক্সেলের শ্রেণী পূর্বাভাস করে, যেখানে মাল্টিক্লাস ইমেজ ক্লাসিফায়ারগুলি সম্পূর্ণ ছবির শ্রেণী পূর্বাভাস করে।","একটি বাউন্ডিং বক্স যার IoU (ইন্টারসেকশন ওভার ইউনিয়ন) $96\%$ এর সমান, সেটিকে সম্ভবত একটি সত্য পজিটিভ হিসেবে বিবেচনা করা হবে।","যখন একটি পূর্বাভাসিত বাউন্ডিং বক্স দৃশ্যের কোনো বস্তুর সাথে সামঞ্জস্যপূর্ণ নয়, তখন এটিকে একটি মিথ্যা ধনাত্মক হিসেবে বিবেচনা করা হয়।","একটি বাউন্ডিং বক্স যার IoU (ইন্টারসেকশন ওভার ইউনিয়ন) $3\%$ এর সমান, সেটি সম্ভবত একটি মিথ্যা নেগেটিভ হিসেবে বিবেচিত হবে।",D
নিম্নলিখিতগুলির মধ্যে কোনটি মিথ্যা?,"নিম্নলিখিত সম্পূর্ণ সংযুক্ত নেটওয়ার্কটি সক্রিয়করণ ফাংশন ছাড়া রৈখিক: $g_3(g_2(g_1(x)))$, যেখানে $g_i(x) = W_i x$ এবং $W_i$ হল ম্যাট্রিক্স।","লিকি রিলু $\max\{0.01x,x\}$ কনভেক্স।",ReLU-এর একটি সংমিশ্রণ যেমন $ReLU(x) - ReLU(x-1)$ উত্তল।,ক্ষতি $\log \sigma(x)= -\log(1+e^{-x})$ উত্তল,C
"আমরা আবাসনের মূল্য পূর্বাভাস করার জন্য দুটি গোপন স্তর সহ একটি সম্পূর্ণ সংযুক্ত নেটওয়ার্ক প্রশিক্ষণ করছি। ইনপুটগুলি $100$-মাত্রিক, এবং এতে বর্গফুটের সংখ্যা, মধ্যম পারিবারিক আয় ইত্যাদি বিভিন্ন বৈশিষ্ট্য রয়েছে। প্রথম গোপন স্তরে $1000$টি সক্রিয়করণ রয়েছে। দ্বিতীয় গোপন স্তরে $10$টি সক্রিয়করণ রয়েছে। আউটপুটটি বাড়ির মূল্য প্রতিনিধিত্বকারী একটি স্কেলার। অ্যাফাইন রূপান্তর সহ একটি সাধারণ নেটওয়ার্ক ধরে নিয়ে এবং কোনো ব্যাচ নর্মালাইজেশন এবং সক্রিয়করণ ফাংশনে কোনো শিক্ষণযোগ্য প্যারামিটার ছাড়া, এই নেটওয়ার্কের কতগুলি প্যারামিটার রয়েছে?",১১১০২১,১১০০১০,১১১১১০,১১০০১১,A
বিবৃতি ১| সিগময়েড $\sigma(x)=(1+e^{-x})^{-1}$ এর $x$ এর সাপেক্ষে অবকলন $\text{Var}(B)$ এর সমান যেখানে $B\sim \text{Bern}(\sigma(x))$ একটি বার্নুলি র‍্যান্ডম ভেরিয়েবল। বিবৃতি ২| নিউরাল নেটওয়ার্কের প্রতিটি স্তরে বায়াস প্যারামিটারগুলি ০ তে সেট করলে বায়াস-ভেরিয়েন্স ট্রেড-অফ পরিবর্তিত হয় এমনভাবে যে মডেলের ভেরিয়েন্স বাড়ে এবং মডেলের বায়াস কমে।,"সত্য, সত্য","মিথ্যা, মিথ্যা","সত্য, মিথ্যা","মিথ্যা, সত্য",C
