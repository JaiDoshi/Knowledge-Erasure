العبارة 1| مقدر الانحدار الخطي لديه أصغر تباين بين جميع المقدرات غير المتحيزة. العبارة 2| المعاملات α المخصصة للمصنفات التي يجمعها AdaBoost هي دائمًا غير سالبة.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,D
العبارة 1| تتدرب RoBERTa مسبقًا على مجموعة نصوص أكبر بحوالي 10 أضعاف من المجموعة التي تدرب عليها BERT مسبقًا. العبارة 2| كانت شبكات ResNeXt في عام 2018 تستخدم عادةً دوال تنشيط tanh.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,C
"العبارة 1| تعطي آلات المتجهات الداعمة، مثل نماذج الانحدار اللوجستي، توزيعًا احتماليًا للتصنيفات المحتملة بناءً على مثال الإدخال المعطى.

العبارة 2| نتوقع أن تبقى المتجهات الداعمة هي نفسها بشكل عام عند الانتقال من نواة خطية إلى نوى متعددة الحدود من درجات أعلى.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
تتضمن مشكلة التعلم الآلي أربع سمات بالإضافة إلى فئة. تحتوي السمات على 3 و2 و2 و2 قيم محتملة لكل منها. تحتوي الفئة على 3 قيم محتملة. كم عدد الأمثلة المختلفة الممكنة كحد أقصى؟,١٢,٢٤,٤٨,٧٢,D
اعتبارًا من عام 2020، ما هي البنية الأفضل لتصنيف الصور عالية الدقة؟,الشبكات الالتفافية,شبكات الرسوم البيانية,الشبكات المتصلة بالكامل,شبكات الدالة الأساسية الشعاعية,A
"العبارة 1| سوف يزداد دائمًا الاحتمال اللوغاريتمي للبيانات من خلال التكرارات المتتالية لخوارزمية توقع التعظيم.

العبارة 2| أحد عيوب التعلم بالتعزيز (Q-learning) هو أنه يمكن استخدامه فقط عندما يكون لدى المتعلم معرفة مسبقة بكيفية تأثير أفعاله على بيئته.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
دعنا نفترض أننا قمنا بحساب التدرج لدالة التكلفة الخاصة بنا وقمنا بتخزينه في متجه g. ما هي تكلفة تحديث واحد للانحدار التدريجي بالنظر إلى التدرج؟,O(D),O(N),O(ND),O(ND^2),A
العبارة 1| بالنسبة للمتغير العشوائي المستمر x ودالة توزيع الاحتمال الخاصة به p(x)، فإنه يصح أن 0 ≤ p(x) ≤ 1 لجميع قيم x. العبارة 2| يتم تعلم شجرة القرار عن طريق تقليل الكسب المعلوماتي.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
فكر في الشبكة البايزية المعطاة أدناه. كم عدد المعلمات المستقلة المطلوبة لهذه الشبكة البايزية H -> U <- P <- W؟,٢,٤,٨,١٦,C
مع اقتراب عدد أمثلة التدريب من ما لا نهاية، فإن النموذج الخاص بك المدرب على تلك البيانات سيكون لديه:,تباين أقل,تباين أعلى,نفس التباين,لا شيء مما سبق,A
العبارة 1| مجموعة جميع المستطيلات في المستوى ثنائي الأبعاد (والتي تشمل المستطيلات غير المحاذية للمحاور) يمكنها أن تشتت مجموعة من 5 نقاط. العبارة 2| البعد الإحصائي (VC-dimension) لمصنف الجار الأقرب k عندما تكون k = 1 هو لا نهائي.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
_ يشير إلى نموذج لا يمكنه نمذجة بيانات التدريب ولا التعميم على بيانات جديدة.,جيد التناسب,الإفراط في التعلم,نقص التعلم,كل ما سبق,C
العبارة 1| يمكن أن تكون درجة F1 مفيدة بشكل خاص لمجموعات البيانات ذات الاختلال العالي في التوازن بين الفئات. العبارة 2| تعتبر المساحة تحت منحنى ROC من المقاييس الرئيسية المستخدمة لتقييم كاشفات الشذوذ.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
"العبارة 1| تتعلم خوارزمية الانتشار الخلفي شبكة عصبية مثالية عالمياً ذات طبقات خفية.

العبارة 2| يجب أن يكون بُعد VC للخط على الأكثر 2، لأنني أستطيع إيجاد حالة واحدة على الأقل من 3 نقاط لا يمكن تشتيتها بأي خط.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
يعني الإنتروبيا العالية أن التقسيمات في التصنيف هي,نقي,غير نقي,مفيد,عديم الفائدة,B
العبارة 1| يتم استخدام تطبيع الطبقة في الورقة البحثية الأصلية لـ ResNet، وليس تطبيع الدفعة. العبارة 2| تستخدم DCGANs الانتباه الذاتي لتحقيق الاستقرار في التدريب.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
عند بناء نموذج انحدار خطي لمجموعة بيانات معينة، تلاحظ أن معامل إحدى الميزات له قيمة سلبية عالية نسبيًا. هذا يشير إلى أن,هذه الميزة لها تأثير قوي على النموذج (يجب الاحتفاظ بها),هذه الميزة ليس لها تأثير قوي على النموذج (يجب تجاهلها),لا يمكن التعليق على أهمية هذه الميزة دون معلومات إضافية,لا يمكن تحديد أي شيء.,C
بالنسبة للشبكة العصبية، أي من هذه الافتراضات الهيكلية هو الذي يؤثر بشكل أكبر على الموازنة بين النقص في التعلم (أي نموذج ذو تحيز عالٍ) والإفراط في التعلم (أي نموذج ذو تباين عالٍ):,عدد العقد المخفية,معدل التعلم,الاختيار الأولي للأوزان,استخدام وحدة إدخال ذات حد ثابت,A
بالنسبة للانحدار متعدد الحدود، أي من هذه الافتراضات الهيكلية هو الذي يؤثر بشكل أكبر على الموازنة بين النقص في التطابق والإفراط في التطابق:,درجة كثير الحدود,سواء تعلمنا الأوزان عن طريق انعكاس المصفوفة أو الانحدار التدريجي,التباين المفترض للضوضاء الغاوسية,استخدام وحدة إدخال ذات حد ثابت,A
العبارة 1| اعتبارًا من عام 2020، تحقق بعض النماذج دقة تزيد عن 98% على مجموعة بيانات CIFAR-10. العبارة 2| لم يتم تحسين شبكات ResNet الأصلية باستخدام مُحسِّن Adam.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
خوارزمية الـ K-means:,يتطلب أن لا يكون بُعد فضاء السمات أكبر من عدد العينات,هل تكون قيمة دالة الهدف الأصغر عندما تكون K = 1,يقلل من التباين داخل الفئة لعدد معين من المجموعات,يتقارب إلى الأمثل العالمي إذا وفقط إذا تم اختيار المتوسطات الأولية كبعض من العينات نفسها,C
العبارة 1| تحتوي شبكات VGG على نواة التفافية ذات عرض وارتفاع أصغر من نواة الطبقة الأولى في شبكة AlexNet. العبارة 2| تم تقديم إجراءات تهيئة الأوزان المعتمدة على البيانات قبل التطبيع الدفعي.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
"ما هي رتبة المصفوفة التالية؟ A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]",٠,١,٢,٣,B
العبارة 1| يمكن استخدام تقدير الكثافة (باستخدام مقدر كثافة النواة على سبيل المثال) لإجراء التصنيف. العبارة 2| التوافق بين الانحدار اللوجستي ونظرية بايز الساذجة الغاوسية (مع تباينات الفئة المتطابقة) يعني أن هناك تناظرًا واحدًا لواحد بين معلمات المصنفين.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,C
افترض أننا نرغب في إجراء التجميع على البيانات المكانية مثل المواقع الهندسية للمنازل. نريد إنتاج مجموعات بأحجام وأشكال مختلفة كثيرة. أي من الطرق التالية هي الأنسب؟,شجرة القرار,التجميع القائم على الكثافة,التجميع القائم على النموذج,التجميع بطريقة المتوسطات التكرارية (K-means),B
"العبارة 1| في خوارزمية AdaBoost، تزداد أوزان الأمثلة المصنفة خطأ بنفس العامل المضاعف.

العبارة 2| في خوارزمية AdaBoost، يميل خطأ التدريب الموزون e_t للمصنف الضعيف الـ t على بيانات التدريب ذات الأوزان D_t إلى الزيادة كدالة لـ t.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
غالبًا ما تكون تقديرات الإمكان الأعظم غير مرغوب فيها لأن,إنهم متحيزون,لديهم تباين عالٍ,إنها ليست مقدرات متسقة,لا شيء مما سبق,B
التعقيد الحسابي للانحدار التدريجي هو،,خطي في D,خطي بالنسبة لـ N,متعدد الحدود في D,معتمد على عدد التكرارات,C
متوسط ناتج أشجار القرار المتعددة يساعد _.,زيادة التحيز,تقليل التحيز,زيادة التباين,تقليل التباين,D
قد يختلف النموذج الذي تم الحصول عليه من خلال تطبيق الانحدار الخطي على المجموعة الفرعية المحددة من الميزات عن النموذج الذي تم الحصول عليه في نهاية عملية تحديد المجموعة الفرعية أثناء,الاختيار الأمثل للمجموعة الفرعية,الاختيار التدريجي الأمامي,الاختيار المرحلي الأمامي,كل ما سبق,C
الشبكات العصبية,تحسين دالة هدف محدبة,لا يمكن تدريبه إلا باستخدام الانحدار التدريجي العشوائي,يمكن استخدام مزيج من دوال التنشيط المختلفة,لا شيء مما سبق,C
"قل إن معدل حدوث المرض D هو حوالي 5 حالات لكل 100 شخص (أي أن P(D) = 0.05). دع المتغير العشوائي البولياني D يعني أن المريض ""مصاب بالمرض D"" ودع المتغير العشوائي البولياني TP يعني ""نتيجة الاختبار إيجابية"". من المعروف أن اختبارات المرض D دقيقة جدًا بمعنى أن احتمال الحصول على نتيجة إيجابية عندما تكون مصابًا بالمرض هو 0.99، واحتمال الحصول على نتيجة سلبية عندما لا تكون مصابًا بالمرض هو 0.97. ما هو P(TP)، الاحتمال المسبق للحصول على نتيجة اختبار إيجابية؟",٠.٠٣٦٨,٠.٤٧٣,٠٫٠٧٨,لا شيء مما سبق,C
العبارة 1| بعد التحويل إلى فضاء السمات Q من خلال دالة نواة أساس شعاعي، قد يتمكن 1-NN باستخدام المسافة الإقليدية غير المرجحة من تحقيق أداء تصنيف أفضل مما هو عليه في الفضاء الأصلي (على الرغم من أننا لا نستطيع ضمان ذلك). العبارة 2| البعد VC للبيرسبترون أصغر من البعد VC لـ SVM خطي بسيط.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
عيب البحث الشبكي هو,لا يمكن تطبيقه على الدوال غير القابلة للاشتقاق.,لا يمكن تطبيقه على الدوال غير المتصلة.,من الصعب تنفيذه.,إنه يعمل ببطء معقول للانحدار الخطي المتعدد.,D
توقع كمية هطول الأمطار في منطقة ما بناءً على إشارات مختلفة هو مشكلة ______.,التعلم الخاضع للإشراف,التعلم غير الخاضع للإشراف,التجميع,لا شيء مما سبق,A
أي من الجمل التالية خاطئة فيما يتعلق بالانحدار؟,إنها تربط المدخلات بالمخرجات.,يتم استخدامه للتنبؤ.,قد يستخدم للتفسير.,يكتشف العلاقات السببية,D
أي من الأسباب التالية هو السبب الرئيسي لتقليم شجرة القرار؟,لتوفير وقت الحوسبة أثناء الاختبار,لتوفير مساحة لتخزين شجرة القرار,لجعل خطأ مجموعة التدريب أصغر,لتجنب الإفراط في التكيف مع مجموعة التدريب,D
العبارة 1| مقدر كثافة النواة يعادل إجراء انحدار النواة مع القيمة Yi = 1/n عند كل نقطة Xi في مجموعة البيانات الأصلية. العبارة 2| يمكن أن يكون عمق شجرة القرار المتعلمة أكبر من عدد أمثلة التدريب المستخدمة لإنشاء الشجرة.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
افترض أن نموذجك يعاني من الإفراط في التخصيص (overfitting). أي مما يلي ليس طريقة صالحة لمحاولة تقليل الإفراط في التخصيص؟,زيادة كمية بيانات التدريب.,تحسين خوارزمية التحسين المستخدمة لتقليل الأخطاء.,تقليل تعقيد النموذج.,تقليل الضوضاء في بيانات التدريب.,B
"العبارة 1| دالة سوفتماكس تُستخدم بشكل شائع في الانحدار اللوجستي متعدد الفئات.
العبارة 2| تؤثر درجة حرارة توزيع سوفتماكس غير المنتظم على إنتروبيته.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
أي مما يلي صحيح فيما يتعلق بآلة المتجهات الداعمة (SVM)؟,بالنسبة للنقاط البيانية ثنائية الأبعاد، فإن المستوى الفاصل الذي يتعلمه نموذج آلة المتجهات الداعمة (SVM) الخطي سيكون خطًا مستقيمًا.,من الناحية النظرية، لا يمكن لنموذج آلة المتجهات الداعمة (SVM) ذو النواة الغاوسية أن يقوم بنمذجة أي مستوى فاصل معقد.,لكل دالة نواة مستخدمة في آلة المتجهات الداعمة (SVM)، يمكن الحصول على توسع أساسي مكافئ بصيغة مغلقة.,التعلم المفرط في آلة المتجهات الداعمة ليس دالة لعدد المتجهات الداعمة.,A
أي مما يلي هو الاحتمال المشترك لـ H و U و P و W الموصوف بواسطة الشبكة البايزية المعطاة H -> U <- P <- W؟ [ملاحظة: كحاصل ضرب الاحتمالات الشرطية],"P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)",لا شيء مما سبق,C
"العبارة 1| بما أن بُعد VC لآلة المتجهات الداعمة (SVM) ذات النواة الأساسية الشعاعية لا نهائي، فإن مثل هذه الآلة يجب أن تكون أسوأ من آلة المتجهات الداعمة ذات النواة متعددة الحدود التي لها بُعد VC محدود.

العبارة 2| الشبكة العصبية ذات الطبقتين مع دوال التنشيط الخطية هي في الأساس مزيج موزون من الفواصل الخطية، مدربة على مجموعة بيانات معينة؛ خوارزمية التعزيز المبنية على الفواصل الخطية تجد أيضًا مزيجًا من الفواصل الخطية، لذلك ستعطي هاتان الخوارزميتان نفس النتيجة.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
العبارة 1| خوارزمية ID3 مضمونة لإيجاد شجرة القرار المثلى. العبارة 2| ضع في اعتبارك توزيع احتمالي مستمر بكثافة f() غير صفرية في كل مكان. احتمال قيمة x يساوي f(x).,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
بالنظر إلى شبكة عصبية ذات N من العقد المدخلة، بدون طبقات مخفية، وعقدة إخراج واحدة، مع دالة خسارة الإنتروبيا ودوال تنشيط سيجمويد، أي من الخوارزميات التالية (مع المعاملات الفائقة والتهيئة المناسبة) يمكن استخدامها للعثور على الحل الأمثل العالمي؟,الانحدار التدريجي العشوائي,تدرج الانحدار للدفعات الصغيرة,انحدار التدرج الدفعي,كل ما سبق,D
إضافة المزيد من الدوال الأساسية في النموذج الخطي، اختر الخيار الأكثر احتمالاً:,تقليل تحيز النموذج,يقلل من تحيز التقدير,يقلل التباين,لا يؤثر على التحيز والتباين,A
فكر في الشبكة البايزية المعطاة أدناه. كم عدد المعلمات المستقلة التي سنحتاجها إذا لم نضع أي افتراضات حول الاستقلال أو الاستقلال الشرطي H -> U <- P <- W؟,٣,٤,٧,١٥,D
مصطلح آخر للكشف عن الحالات الخارجة عن التوزيع هو؟,كشف الشذوذ,الكشف عن فئة واحدة,قوة التحمل في حالة عدم التطابق بين التدريب والاختبار,كشف الخلفية,A
العبارة 1| نتعلم مصنفًا f عن طريق تعزيز المتعلمين الضعفاء h. الشكل الوظيفي لحدود قرار f هو نفسه حدود h، ولكن بمعلمات مختلفة. (على سبيل المثال، إذا كان h مصنفًا خطيًا، فإن f هو أيضًا مصنف خطي). العبارة 2| يمكن استخدام التحقق المتقاطع لاختيار عدد التكرارات في التعزيز؛ قد تساعد هذه الإجراءات في الحد من الإفراط في التعلم.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,D
العبارة 1| تم تقديم شبكات الطرق السريعة بعد شبكات ResNet وتتجنب التجميع الأقصى لصالح الالتفافات. العبارة 2| عادة ما تكلف شبكات DenseNet ذاكرة أكثر من شبكات ResNet.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,D
إذا كان N هو عدد الحالات في مجموعة بيانات التدريب، فإن أقرب الجيران لديه وقت تشغيل للتصنيف يبلغ,O(1),O( N ),(لوغ ن)O,O( N^2 ),B
"العبارة 1| شبكات ResNets والمحولات الأصلية هي شبكات عصبية ذات تغذية أمامية.
العبارة 2| تستخدم المحولات الأصلية الانتباه الذاتي، ولكن شبكة ResNet الأصلية لا تستخدمه.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
العبارة 1| وحدات التصحيح الخطي المعدل (RELUs) ليست رتيبة، ولكن الدوال السينية (sigmoids) رتيبة. العبارة 2| الشبكات العصبية المدربة باستخدام الانحدار التدريجي تتقارب باحتمالية عالية إلى الحل الأمثل العالمي.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,D
المخرج العددي لعقدة سيجمويد في شبكة عصبية,غير محدود، يشمل جميع الأعداد الحقيقية.,غير محدود، يشمل جميع الأعداد الصحيحة.,محصور بين 0 و1.,محصور بين -1 و1.,C
أي مما يلي يمكن استخدامه فقط عندما تكون بيانات التدريب قابلة للفصل خطياً؟,نموذج المتجهات الداعمة الخطي ذو الهامش الصلب,الانحدار اللوجستي الخطي,نموذج المتجهات الداعمة ذو الهامش الخطي اللين,طريقة المركز الهندسي.,A
أي من التالي هي خوارزميات التجميع المكاني؟,التجميع القائم على التقسيم,التجميع بطريقة المتوسطات التكرارية (K-means),التجميع القائم على الشبكة,كل ما سبق,D
العبارة 1| حدود القرار ذات الهامش الأقصى التي تنشئها آلات المتجهات الداعمة لديها أقل خطأ تعميم بين جميع المصنفات الخطية. العبارة 2| أي حد قرار نحصل عليه من نموذج توليدي مع توزيعات غاوسية مشروطة بالفئة يمكن من حيث المبدأ إعادة إنتاجه باستخدام آلة المتجهات الداعمة ونواة متعددة الحدود من درجة أقل من أو تساوي ثلاثة.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,D
العبارة 1| التنظيم L2 للنماذج الخطية يميل إلى جعل النماذج أكثر تناثرًا من التنظيم L1. العبارة 2| يمكن العثور على الاتصالات المتبقية في شبكات ResNet والمحولات.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,D
"لنفترض أننا نرغب في حساب P(H|E, F) وليس لدينا معلومات عن الاستقلال الشرطي. أي من المجموعات التالية من الأرقام كافية لإجراء الحساب؟","P(E, F)، P(H)، P(E|H)، P(F|H)","P(E, F)، P(H)، P(E, F|H)",P(H)، P(E|H)، P(F|H),"P(E, F)، P(E|H)، P(F|H)",B
أي مما يلي يمنع الإفراط في التعلم عند إجراء التجميع (bagging)؟,استخدام أخذ العينات مع الإرجاع كتقنية لأخذ العينات,استخدام المصنفات الضعيفة,استخدام خوارزميات التصنيف التي لا تميل إلى الإفراط في التكيف,ممارسة التحقق من الصحة التي تتم على كل مصنف يتم تدريبه,B
العبارة 1| يقوم تحليل المكونات الرئيسية (PCA) والتجميع الطيفي (مثل طريقة أندرو نغ) بإجراء تحليل القيم الذاتية على مصفوفتين مختلفتين. ومع ذلك، فإن حجم هاتين المصفوفتين متطابق. العبارة 2| بما أن التصنيف هو حالة خاصة من الانحدار، فإن الانحدار اللوجستي هو حالة خاصة من الانحدار الخطي.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
العبارة 1| احتوى بنك ستانفورد للمشاعر على مراجعات للأفلام، وليس مراجعات للكتب. العبارة 2| تم استخدام بنك بن للأشجار في نمذجة اللغة.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
"ما هي أبعاد الفضاء الصفري للمصفوفة التالية؟ A = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]]",٠,١,٢,٣,C
ما هي المتجهات الداعمة؟,الأمثلة الأبعد عن حد القرار.,الأمثلة الوحيدة الضرورية لحساب f(x) في آلة المتجهات الداعمة (SVM).,مركز البيانات.,جميع الأمثلة التي لها وزن غير صفري αk في آلة المتجهات الداعمة (SVM).,B
"العبارة 1| لم يتم تهيئة معلمات Word2Vec باستخدام آلة بولتزمان المقيدة.
العبارة 2| دالة tanh هي دالة تنشيط غير خطية.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
إذا زادت خسارة التدريب مع زيادة عدد الحقب (epochs)، فأي مما يلي قد يكون مشكلة محتملة في عملية التعلم؟,التنظيم منخفض جدًا والنموذج يعاني من الملاءمة المفرطة,التنظيم مرتفع جدًا والنموذج يعاني من نقص التطابق,حجم الخطوة كبير جداً,حجم الخطوة صغير جداً,C
"قل إن معدل حدوث المرض D هو حوالي 5 حالات لكل 100 شخص (أي أن P(D) = 0.05). دع المتغير العشوائي البولياني D يعني أن المريض ""مصاب بالمرض D"" ودع المتغير العشوائي البولياني TP يعني ""نتيجة الاختبار إيجابية"". من المعروف أن اختبارات المرض D دقيقة جدًا بمعنى أن احتمال الحصول على نتيجة إيجابية عندما تكون مصابًا بالمرض هو 0.99، واحتمال الحصول على نتيجة سلبية عندما لا تكون مصابًا بالمرض هو 0.97. ما هو P(D | TP)، الاحتمال اللاحق لإصابتك بالمرض D عندما تكون نتيجة الاختبار إيجابية؟",٠.٠٤٩٥,٠٫٠٧٨,٠.٦٣٥,٠٫٩٧,C
العبارة 1| تفترض نتائج التعلم الآلي التقليدي أن مجموعات التدريب والاختبار مستقلة وموزعة بشكل متطابق. العبارة 2| في عام 2017، كانت نماذج COCO عادة ما يتم تدريبها مسبقًا على ImageNet.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
"العبارة 1| قيم الهوامش التي تم الحصول عليها بواسطة نواتين مختلفتين K1(x, x0) و K2(x, x0) على نفس مجموعة التدريب لا تخبرنا أي مصنف سيؤدي بشكل أفضل على مجموعة الاختبار. العبارة 2| دالة التنشيط لـ BERT هي GELU.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
أي من التالي هو خوارزمية تجميع في التعلم الآلي؟,توقع التعظيم,عربة التسوق,نموذج بايز الساذج الغاوسي,أبريوري,A
لقد انتهيت للتو من تدريب شجرة قرار لتصنيف الرسائل غير المرغوب فيها، وهي تحصل على أداء سيء بشكل غير طبيعي على كل من مجموعات التدريب والاختبار الخاصة بك. أنت تعلم أن تنفيذك لا يحتوي على أخطاء، فما الذي يمكن أن يكون سبب المشكلة؟,قراراتك الشجرية ضحلة جداً.,يجب عليك زيادة معدل التعلم.,أنت تفرط في التكيف.,لا شيء مما سبق.,A
التحقق المتقاطع K-fold هو,خطي في K,تربيعي في K,مكعب في كلفن,أسي في K,A
العبارة 1| عادة ما يتم تدريب الشبكات العصبية على نطاق صناعي على وحدات المعالجة المركزية (CPUs)، وليس على وحدات معالجة الرسومات (GPUs). العبارة 2| يحتوي نموذج ResNet-50 على أكثر من مليار معلمة.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
بالنظر إلى متغيرين عشوائيين منطقيين، A و B، حيث P(A) = 1/2، P(B) = 1/3، و P(A | ¬B) = 1/4، ما هي P(A | B)؟,١/٦,ربع,ثلاثة أرباع,١,D
المخاطر الوجودية التي يشكلها الذكاء الاصطناعي ترتبط في الغالب بأي من الأساتذة التاليين؟,ناندو دي فريتاس,يان لوكون,ستيوارت راسل,جيتندرا مالك,C
العبارة 1| تعظيم احتمالية نموذج الانحدار اللوجستي ينتج عنه العديد من القيم المثلى المحلية. العبارة 2| لا يمكن لأي مصنف أن يتفوق على المصنف البايزي الساذج إذا كان توزيع البيانات معروفًا.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
بالنسبة لانحدار الكيرنل، أي من هذه الافتراضات الهيكلية هو الذي يؤثر بشكل أكبر على الموازنة بين النقص في التطابق والإفراط في التطابق:,سواء كانت دالة النواة غاوسية مقابل مثلثية مقابل صندوقية الشكل,سواء استخدمنا المقاييس الإقليدية مقابل L1 مقابل L∞,عرض النواة,الارتفاع الأقصى لدالة النواة,C
العبارة 1| خوارزمية تعلم آلة المتجهات الداعمة (SVM) مضمونة لإيجاد الفرضية المثلى عالميًا فيما يتعلق بدالة الهدف الخاصة بها. العبارة 2| بعد التحويل إلى فضاء السمات Q من خلال دالة نواة أساس شعاعي، قد يتمكن البيرسيبترون من تحقيق أداء تصنيف أفضل مما كان عليه في فضائه الأصلي (على الرغم من أننا لا نستطيع ضمان ذلك).,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
بالنسبة لمصنف بايز الغاوسي، أي من هذه الافتراضات الهيكلية هو الذي يؤثر بشكل أكبر على الموازنة بين النقص في التطابق والإفراط في التطابق:,سواء تعلمنا مراكز الفئات عن طريق الاحتمالية القصوى أو الانحدار التدريجي,سواء افترضنا مصفوفات التغاير الكاملة للفئات أو مصفوفات التغاير القطرية للفئات,سواء كان لدينا احتمالات مسبقة متساوية للفئات أو احتمالات مسبقة مقدرة من البيانات.,سواء سمحنا للفئات بأن يكون لها متجهات متوسطة مختلفة أو أجبرناها على مشاركة نفس متجه المتوسط,B
العبارة 1| من المرجح أن يحدث الإفراط في التدريب عندما تكون مجموعة بيانات التدريب صغيرة. العبارة 2| من المرجح أن يحدث الإفراط في التدريب عندما يكون فضاء الفرضيات صغيرًا.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,D
"العبارة 1| بالإضافة إلى خوارزمية التوقع الأعظم (EM)، يمكن استخدام الانحدار التدريجي لإجراء الاستدلال أو التعلم على نموذج خليط غاوسي.

العبارة 2| بافتراض وجود عدد ثابت من السمات، يمكن تعلم المصنف البايزي الأمثل القائم على التوزيع الغاوسي في وقت خطي يتناسب مع عدد السجلات في مجموعة البيانات.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
"العبارة 1| في الشبكة البيزية، تكون نتائج الاستدلال لخوارزمية شجرة الاتصال هي نفسها نتائج الاستدلال للإزالة المتغيرة.

العبارة 2| إذا كان المتغيران العشوائيان X و Y مستقلين شرطياً بالنظر إلى متغير عشوائي آخر Z، فإنه في الشبكة البيزية المقابلة، تكون العقد الخاصة بـ X و Y منفصلة-d بالنظر إلى Z.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,C
بالنظر إلى مجموعة بيانات كبيرة من السجلات الطبية للمرضى الذين يعانون من أمراض القلب، حاول معرفة ما إذا كانت هناك مجموعات مختلفة من هؤلاء المرضى يمكننا تخصيص علاجات منفصلة لها. ما نوع مشكلة التعلم هذه؟,التعلم الخاضع للإشراف,التعلم غير الخاضع للإشراف,كلا من (أ) و (ب),لا (أ) ولا (ب),B
ماذا ستفعل في تحليل المكونات الرئيسية (PCA) للحصول على نفس الإسقاط كما في تحليل القيم المفردة (SVD)؟,تحويل البيانات إلى متوسط صفري,تحويل البيانات إلى وسيط صفري,غير ممكن,لا شيء مما سبق,A
"العبارة 1| خطأ التدريب لمصنف أقرب جار واحد هو 0.

العبارة 2| مع نمو عدد نقاط البيانات إلى ما لا نهاية، يقترب تقدير الحد الأقصى للاحتمال اللاحق (MAP) من تقدير الاحتمال الأعظم (MLE) لجميع الاحتمالات السابقة الممكنة. بعبارة أخرى، مع وجود بيانات كافية، يصبح اختيار الاحتمال السابق غير ذي صلة.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,C
عند إجراء انحدار المربعات الصغرى مع التنظيم (بافتراض أنه يمكن إجراء التحسين بدقة)، فإن زيادة قيمة معامل التنظيم λ تؤثر على خطأ الاختبار.,لن يقلل أبداً من خطأ التدريب.,لن يزيد أبدًا من خطأ التدريب.,لن تقلل أبداً من خطأ الاختبار.,لن يزداد أبداً,A
أي مما يلي يصف بشكل أفضل ما تحاول الأساليب التمييزية نمذجته؟ (w هي المعلمات في النموذج),"p(y|x, w)","p(y, x)","p(w|x, w)",لا شيء مما سبق,A
العبارة 1| يمكن أن يتجاوز أداء تصنيف CIFAR-10 للشبكات العصبية الالتفافية 95٪. العبارة 2| لا تحسن مجموعات الشبكات العصبية من دقة التصنيف لأن التمثيلات التي تتعلمها مترابطة بشكل كبير.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,C
أي من النقاط التالية سيختلف عليها البايزيون والتكراريون؟,استخدام نموذج ضوضاء غير غاوسي في الانحدار الاحتمالي.,استخدام النمذجة الاحتمالية للانحدار.,استخدام التوزيعات السابقة على المعلمات في النموذج الاحتمالي.,استخدام الاحتمالات المسبقة للفئات في التحليل التمييزي الغاوسي.,C
العبارة 1| يستخدم مقياس BLEU الدقة، بينما يستخدم مقياس ROGUE الاسترجاع. العبارة 2| كانت نماذج ماركوف المخفية تُستخدم بشكل متكرر لنمذجة الجمل الإنجليزية.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
العبارة 1| تحتوي ImageNet على صور بدقة متنوعة. العبارة 2| تحتوي Caltech-101 على صور أكثر من ImageNet.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,C
أي مما يلي أكثر ملاءمة للقيام باختيار الميزات؟,ريدج,لاسو,كلا من (أ) و (ب),لا (أ) ولا (ب),B
افترض أنك أُعطيت خوارزمية EM تجد تقديرات الاحتمالية القصوى لنموذج يحتوي على متغيرات كامنة. طُلب منك تعديل الخوارزمية بحيث تجد تقديرات MAP بدلاً من ذلك. ما هي الخطوة أو الخطوات التي تحتاج إلى تعديلها؟,توقع,تعظيم,لا تعديل ضروري,كلاهما,B
بالنسبة لمصنف بايز الغاوسي، أي من هذه الافتراضات الهيكلية هو الذي يؤثر بشكل أكبر على الموازنة بين النقص في التطابق والإفراط في التطابق:,سواء تعلمنا مراكز الفئات عن طريق الاحتمالية القصوى أو الانحدار التدريجي,سواء افترضنا مصفوفات التغاير الكاملة للفئات أو مصفوفات التغاير القطرية للفئات,سواء كان لدينا احتمالات أولية متساوية للفئات أو احتمالات أولية مقدرة من البيانات,سواء سمحنا للفئات بأن يكون لها متجهات متوسطة مختلفة أو أجبرناها على مشاركة نفس متجه المتوسط,B
"العبارة 1| لأي متغيرين x و y لهما توزيع مشترك p(x, y)، دائمًا ما يكون لدينا H[x, y] ≥ H[x] + H[y] حيث H هي دالة الإنتروبيا. العبارة 2| بالنسبة لبعض الرسوم البيانية الموجهة، فإن التخلق يقلل من عدد الحواف الموجودة في الرسم البياني.",صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,B
أي مما يلي ليس تعلمًا خاضعًا للإشراف؟,PCA,شجرة القرار,الانحدار الخطي,نايف بايزي,A
العبارة 1| يعتمد تقارب الشبكة العصبية على معدل التعلم. العبارة 2| يقوم الإسقاط بضرب قيم التنشيط المختارة عشوائيًا في الصفر.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
"أي من الخيارات التالية يساوي P(A, B, C) بالنظر إلى المتغيرات العشوائية البولينية A و B و C، وعدم وجود افتراضات استقلالية أو استقلالية شرطية بين أي منها؟",P(A | B) * P(B | C) * P(C | A),"P(C | A, B) * P(A) * P(B)","P(A, B | C) * P(C)","P(A | B, C) * P(B | A, C) * P(C | A, B)",C
أي من المهام التالية يمكن حلها بشكل أفضل باستخدام التجميع (Clustering).,توقع كمية هطول الأمطار بناءً على مؤشرات مختلفة,الكشف عن معاملات بطاقات الائتمان الاحتيالية,تدريب روبوت على حل متاهة,كل ما سبق,B
بعد تطبيق عقوبة التنظيم في الانحدار الخطي، تجد أن بعض معاملات w قد تم تصفيرها. أي من العقوبات التالية قد تكون استخدمت؟,معيار L0,معيار L1,معيار L2,إما (أ) أو (ب),D
أ و ب هما حدثان. إذا انخفض الاحتمال المشترك لـ (أ، ب) بينما ازداد احتمال (أ)، أي مما يلي صحيح؟,P(A|B) ينخفض,P(B|A) ينخفض,ينخفض P(B),كل ما سبق,B
العبارة 1| عند تعلم نموذج ماركوف الخفي (HMM) لمجموعة ثابتة من الملاحظات، بافتراض أننا لا نعرف العدد الحقيقي للحالات الخفية (وهو غالبًا ما يكون الحال)، يمكننا دائمًا زيادة احتمالية بيانات التدريب من خلال السماح بمزيد من الحالات الخفية. العبارة 2| الترشيح التعاوني غالبًا ما يكون نموذجًا مفيدًا لنمذجة تفضيلات المستخدمين للأفلام.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
أنت تقوم بتدريب نموذج انحدار خطي لمهمة تقدير بسيطة، وتلاحظ أن النموذج يعاني من الإفراط في التكيف مع البيانات. تقرر إضافة تنظيم $\ell_2$ لمعاقبة الأوزان. عندما تزيد معامل تنظيم $\ell_2$، ماذا سيحدث للتحيز والتباين في النموذج؟,زيادة التحيز ؛ زيادة التباين,زيادة التحيز ؛ انخفاض التباين,انخفاض التحيز ؛ زيادة التباين,انخفاض التحيز ؛ انخفاض التباين,B
"أي أمر (أوامر) في PyTorch 1.8 ينتج مصفوفة جاوسية 10×5 حيث كل عنصر فيها يتم أخذ عينة منه بشكل مستقل ومتطابق التوزيع من التوزيع الطبيعي N(μ=5, σ²=16) ومصفوفة منتظمة 10×10 حيث كل عنصر فيها يتم أخذ عينة منه بشكل مستقل ومتطابق التوزيع من التوزيع المنتظم U[-1,1)؟",٥ + تورش.راندن(١٠،٥) * ١٦ ؛ تورش.راند(١٠،١٠،منخفض=-١،مرتفع=١),"\texttt{5 + torch.randn(10,5) * 16} ؛ \texttt{(torch.rand(10,10) - 0.5) / 0.5}",٥ + تورش.راندن(١٠،٥) * ٤ ؛ ٢ * تورش.راند(١٠،١٠) - ١,تورش.نورمال(تورش.ونز(10،5)*5،تورش.ونز(5،5)*16) ؛ 2 * تورش.راند(10،10) - 1,C
العبارة 1| تدرج ReLU يساوي صفر عندما $x<0$، وتدرج السيجمويد $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ لجميع قيم $x$. العبارة 2| السيجمويد له تدرج مستمر و ReLU له تدرج غير مستمر.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,A
أي مما يلي صحيح عن التطبيع الدفعي؟,بعد تطبيق التطبيع الدفعي، ستتبع تنشيطات الطبقة توزيعًا غاوسيًا قياسيًا.,يصبح معامل الانحياز في الطبقات الخطية زائداً عن الحاجة إذا تبعته مباشرة طبقة تطبيع الدفعات.,يجب تغيير التهيئة القياسية للأوزان عند استخدام التطبيع الدفعي.,التطبيع الدفعي يعادل تطبيع الطبقة في الشبكات العصبية الالتفافية.,B
لنفترض أن لدينا دالة الهدف التالية: $\argmin_{w} \frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\gamma \norm{w}^2_2$ ما هو التدرج لـ $\frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\lambda \norm{w}^2_2$ بالنسبة لـ $w$؟,$\nabla_w f(w) = (X^\top X + \lambda I)w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + (\lambda+1) w$,C
أي مما يلي صحيح بالنسبة لنواة الالتفاف؟,التفاف الصورة مع $\begin{bmatrix}1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ لن يغير الصورة,التفاف الصورة مع $\begin{bmatrix}0 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ لن يغير الصورة,التفاف الصورة مع $\begin{bmatrix}1 & 1 & 1\\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}$ لن يغير الصورة,التفاف صورة مع $\begin{bmatrix}0 & 0 & 0\\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ لن يغير الصورة,B
أي مما يلي خاطئ؟,نماذج التجزئة الدلالية تتنبأ بفئة كل بكسل، بينما تتنبأ مصنفات الصور متعددة الفئات بفئة الصورة بأكملها.,صندوق محيط بنسبة تقاطع على الاتحاد (IoU) تساوي 96٪ من المحتمل أن يعتبر إيجابيًا حقيقيًا.,عندما لا يتوافق الصندوق المحيط المتوقع مع أي كائن في المشهد، يعتبر ذلك نتيجة إيجابية خاطئة.,صندوق محيط بنسبة تقاطع على الاتحاد (IoU) تساوي 3٪ من المحتمل أن يعتبر سلبيًا كاذبًا.,D
أي مما يلي خاطئ؟,الشبكة التالية المتصلة بالكامل بدون دوال تنشيط هي خطية: $g_3(g_2(g_1(x)))$، حيث $g_i(x) = W_i x$ و $W_i$ هي مصفوفات.,"دالة ReLU المتسربة $\max\{0.01x,x\}$ هي محدبة.",مزيج من وحدات التصحيح الخطي (ReLUs) مثل $ReLU(x) - ReLU(x-1)$ هو محدب.,الخسارة $\log \sigma(x)= -\log(1+e^{-x})$ هي مقعرة,C
نحن نقوم بتدريب شبكة متصلة بالكامل ذات طبقتين مخفيتين للتنبؤ بأسعار المساكن. المدخلات هي ذات بُعد 100، وتحتوي على العديد من الميزات مثل عدد الأقدام المربعة، ومتوسط دخل الأسرة، وما إلى ذلك. الطبقة المخفية الأولى تحتوي على 1000 تفعيل. الطبقة المخفية الثانية تحتوي على 10 تفعيلات. المخرج هو قيمة عددية واحدة تمثل سعر المنزل. بافتراض شبكة عادية مع تحويلات خطية وبدون تطبيع الدفعات وبدون معلمات قابلة للتعلم في دالة التفعيل، كم عدد المعلمات التي تحتوي عليها هذه الشبكة؟,١١١٠٢١,١١٠٠١٠,١١١١١٠,١١٠٠١١,A
العبارة 1| مشتقة الدالة السينية (سيجمويد) $\sigma(x)=(1+e^{-x})^{-1}$ بالنسبة لـ $x$ تساوي $\text{Var}(B)$ حيث $B\sim \text{Bern}(\sigma(x))$ هو متغير عشوائي برنولي. العبارة 2| ضبط معاملات الانحياز في كل طبقة من الشبكة العصبية إلى 0 يغير الموازنة بين الانحياز والتباين بحيث يزداد تباين النموذج وينخفض انحيازه.,صحيح، صحيح,كاذب، كاذب,صحيح، خطأ,كاذب، صحيح,C
