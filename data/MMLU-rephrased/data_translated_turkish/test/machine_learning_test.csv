"İfade 1| Doğrusal regresyon tahmincisi, tüm tarafsız tahminciler arasında en küçük varyansa sahiptir. İfade 2| AdaBoost tarafından bir araya getirilen sınıflandırıcılara atanan α katsayıları her zaman negatif olmayan değerlerdir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",D
"İfade 1| RoBERTa, BERT'in önceden eğitildiği korpustan yaklaşık 10 kat daha büyük bir korpus üzerinde önceden eğitilir. İfade 2| 2018'deki ResNeXt'ler genellikle tanh aktivasyon fonksiyonlarını kullanırdı.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",C
"İfade 1| Destek vektör makineleri, lojistik regresyon modelleri gibi, verilen bir girdi örneğine dayanarak olası etiketler üzerinde bir olasılık dağılımı verir. İfade 2| Doğrusal çekirdekten daha yüksek dereceli polinom çekirdeklere geçerken, destek vektörlerinin genel olarak aynı kalmasını bekleriz.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
"Bir makine öğrenimi problemi dört özellik ve bir sınıf içerir. Özelliklerin sırasıyla 3, 2, 2 ve 2 olası değeri vardır. Sınıfın 3 olası değeri vardır. En fazla kaç farklı örnek mümkündür?",12,24,48,72,D
"2020 itibariyle, yüksek çözünürlüklü görüntüleri sınıflandırmak için en iyi mimari hangisidir?",evrişimli ağlar,ağ grafikleri,tam bağlantılı ağlar,RBF ağları,A
"İfade 1| Beklenti maksimizasyonu algoritmasının ardışık iterasyonları boyunca verinin log-olabilirliği her zaman artacaktır. İfade 2| Q-öğrenmesinin bir dezavantajı, yalnızca öğrenenin eylemlerinin çevresini nasıl etkilediğine dair önceden bilgisi olduğunda kullanılabilmesidir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
"Diyelim ki maliyet fonksiyonumuzun gradyanını hesapladık ve bunu g vektöründe sakladık. Gradyan verildiğinde, bir gradyan iniş güncellemesinin maliyeti nedir?",O(D),O(N),O(ND),O(ND^2),A
"İfade 1| Sürekli bir rastgele değişken x ve onun olasılık dağılım fonksiyonu p(x) için, tüm x'ler için 0 ≤ p(x) ≤ 1 geçerlidir. İfade 2| Karar ağacı, bilgi kazancını minimize ederek öğrenilir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
Aşağıda verilen Bayes ağını düşünün. Bu Bayes Ağı için kaç bağımsız parametreye ihtiyaç vardır H -> U <- P <- W?,2,4,8,16,C
"Eğitim örneklerinin sayısı sonsuza yaklaştıkça, bu veriler üzerinde eğitilen modeliniz şuna sahip olacaktır:",Düşük varyans,Daha yüksek varyans,Aynı varyans,Yukarıdakilerin hiçbiri,A
İfade 1| 2B düzlemindeki tüm dikdörtgenler kümesi (eksen hizalı olmayan dikdörtgenleri de içerir) 5 noktalık bir kümeyi parçalayabilir. İfade 2| k = 1 olduğunda k-En Yakın Komşu sınıflandırıcısının VC-boyutu sonsuzdur.,"Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
_ ne eğitim verilerini modelleyebilen ne de yeni verilere genelleyebilen bir modeli ifade eder.,iyi oturan,aşırı uyum,yetersiz uyum,yukarıdakilerin hepsi,C
"Statement 1| F1 skoru, özellikle sınıf dengesizliği yüksek olan veri setleri için faydalı olabilir.

Statement 2| ROC eğrisi altındaki alan, anomali dedektörlerini değerlendirmek için kullanılan ana metriklerden biridir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"İfade 1| Geri yayılım algoritması, gizli katmanlara sahip küresel olarak optimal bir sinir ağını öğrenir. İfade 2| Bir doğrunun VC boyutu en fazla 2 olmalıdır, çünkü herhangi bir doğru tarafından parçalanamayan en az bir 3 nokta durumu bulabilirim.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
"Yüksek entropi, sınıflandırmadaki bölümlerin olduğu anlamına gelir",saf,saf değil,faydalı,gereksiz,B
"İfade 1| Orijinal ResNet makalesinde Yığın Normalizasyonu değil, Katman Normalizasyonu kullanılmıştır. İfade 2| DCGAN'lar eğitimi stabilize etmek için öz-dikkat kullanır.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
"Belirli bir veri seti için doğrusal regresyon modeli oluştururken, özelliklerden birinin katsayısının nispeten yüksek bir negatif değere sahip olduğunu gözlemliyorsunuz. Bu durum şunu gösterir:",Bu özellik model üzerinde güçlü bir etkiye sahiptir (korunmalıdır),Bu özelliğin model üzerinde güçlü bir etkisi yoktur (göz ardı edilmelidir),"Bu özelliğin önemi hakkında yorum yapmak, ek bilgi olmadan mümkün değildir.",Hiçbir şey belirlenemez.,C
"Bir sinir ağı için, aşağıdakilerden hangisi yetersiz uyum (yani yüksek yanlılık modeli) ve aşırı uyum (yani yüksek varyans modeli) arasındaki dengeyi en çok etkileyen yapısal varsayımdır:",Gizli düğümlerin sayısı,Öğrenme oranı,İlk ağırlık seçimi,Sabit terimli birim girişin kullanımı,A
"Polinom regresyonu için, aşağıdaki yapısal varsayımlardan hangisi eksik uyum ve aşırı uyum arasındaki dengeyi en çok etkiler:",Polinom derecesi,Ağırlıkları matris tersi alma yoluyla mı yoksa gradyan inişi ile mi öğrendiğimiz,Gauss gürültüsünün varsayılan varyansı,Sabit terimli birim girişin kullanımı,A
"İfade 1| 2020 itibarıyla, bazı modeller CIFAR-10 üzerinde %98'den fazla doğruluk elde etmektedir. İfade 2| Orijinal ResNet'ler Adam optimize edici ile optimize edilmemişti.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
K-ortalamalar algoritması,"Özellik uzayının boyutunun, örnek sayısından daha büyük olmamasını gerektirir",K = 1 olduğunda amaç fonksiyonunun en küçük değerine sahiptir,Verilen sayıda küme için sınıf içi varyansı minimize eder,Yalnızca ve yalnızca başlangıç ortalamaları örneklerin kendilerinden bazıları olarak seçilirse küresel optimuma yakınsar,C
"İfade 1| VGGNet'lerin evrişimli çekirdekleri, AlexNet'in ilk katman çekirdeklerine göre daha küçük genişlik ve yüksekliğe sahiptir. İfade 2| Veriye bağlı ağırlık başlatma prosedürleri, Toplu Normalizasyondan önce tanıtılmıştır.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"Aşağıdaki matrisin rankı nedir? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]]",0,1,2,3,B
"İfade 1| Yoğunluk tahmini (örneğin, çekirdek yoğunluk tahmincisi kullanılarak) sınıflandırma yapmak için kullanılabilir. İfade 2| Lojistik regresyon ile Gauss Naive Bayes (özdeş sınıf kovaryansları ile) arasındaki uyum, iki sınıflandırıcının parametreleri arasında bire bir bir ilişki olduğu anlamına gelir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",C
"Uzamsal veriler üzerinde, örneğin evlerin geometrik konumları gibi, kümeleme yapmak istediğimizi varsayalım. Birçok farklı boyut ve şekilde kümeler oluşturmak istiyoruz. Aşağıdaki yöntemlerden hangisi en uygundur?",Karar Ağaçları,Yoğunluk tabanlı kümeleme,Model tabanlı kümeleme,K-ortalamalar kümeleme,B
"İfade 1| AdaBoost'ta yanlış sınıflandırılmış örneklerin ağırlıkları aynı çarpımsal faktörle artar. İfade 2| AdaBoost'ta, D_t ağırlıklarına sahip eğitim verileri üzerinde t. zayıf sınıflandırıcının ağırlıklı eğitim hatası e_t, t'nin bir fonksiyonu olarak artma eğilimindedir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
MLE tahminleri genellikle istenmeyen sonuçlar doğurur çünkü,onlar önyargılı,yüksek varyansa sahipler,bunlar tutarlı tahmin ediciler değildir,Yukarıdakilerin hiçbiri,B
"Gradyan inişinin hesaplama karmaşıklığı,",D'de doğrusal,N'de doğrusal,D'de polinom,iterasyon sayısına bağlı olarak,C
Birden fazla karar ağacının çıktısının ortalamasını almak _ yardımcı olur.,Önyargıyı artır,Önyargıyı azalt,Varyansı artır,Varyansı azalt,D
"Tanımlanan özellik alt kümesi üzerinde doğrusal regresyon uygulanarak elde edilen model, alt kümeyi tanımlama sürecinin sonunda elde edilen modelden farklı olabilir",En iyi alt küme seçimi,İleriye doğru aşamalı seçim,İleriye doğru aşamalı seçim,Yukarıdakilerin hepsi,C
Sinir ağları,Dışbükey bir amaç fonksiyonunu optimize et,Sadece stokastik gradyan inişi ile eğitilebilir,Farklı aktivasyon fonksiyonlarının bir karışımını kullanabilir,Yukarıdakilerin hiçbiri,C
"D hastalığının görülme sıklığının 100 kişide yaklaşık 5 vaka olduğunu söyleyin (yani P(D) = 0.05). Boole rastgele değişkeni D'nin bir hastanın ""D hastalığına sahip olduğu"" anlamına geldiğini ve Boole rastgele değişkeni TP'nin ""pozitif test"" anlamına geldiğini varsayalım. D hastalığı için testlerin, hastalığa sahip olduğunuzda pozitif test verme olasılığının 0.99 ve hastalığa sahip olmadığınızda negatif test verme olasılığının 0.97 olması anlamında çok doğru olduğu bilinmektedir. P(TP), pozitif test vermenin öncül olasılığı nedir?",0.0368,"0,473","0,078",Yukarıdakilerin hiçbiri,C
"İfade 1| Radyal tabanlı bir çekirdek fonksiyonu aracılığıyla Q özellik uzayına eşleştirildikten sonra, ağırlıksız Öklid mesafesini kullanan 1-NN, orijinal uzaya göre daha iyi bir sınıflandırma performansı elde edebilir (ancak bunu garanti edemeyiz). İfade 2| Bir Perceptron'un VC boyutu, basit bir doğrusal SVM'nin VC boyutundan daha küçüktür.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
Grid aramanın dezavantajı,Türevlenemeyen fonksiyonlara uygulanamaz.,Süreksiz fonksiyonlara uygulanamaz.,Uygulamak zor.,Çoklu doğrusal regresyon için makul derecede yavaş çalışır.,D
Bir bölgedeki yağış miktarını çeşitli ipuçlarına dayanarak tahmin etmek bir ______ problemidir.,Gözetimli öğrenme,Gözetimsiz öğrenme,Kümeleme,Yukarıdakilerin hiçbiri,A
Aşağıdaki cümlelerden hangisi regresyon ile ilgili olarak YANLIŞTIR?,Girdileri çıktılara bağlar.,Tahmin için kullanılır.,Yorumlama için kullanılabilir.,Nedensel ilişkileri keşfeder,D
Aşağıdakilerden hangisi bir Karar Ağacını budamanın ana nedenidir?,Test sırasında işlem süresinden tasarruf etmek için,Karar Ağacını depolamak için yer kazanmak,Eğitim seti hatasını daha küçük yapmak için,Eğitim setine aşırı uyumu önlemek için,D
"İfade 1| Çekirdek yoğunluk tahmincisi, orijinal veri setindeki her Xi noktasında Yi = 1/n değeriyle çekirdek regresyonu gerçekleştirmeye eşdeğerdir. İfade 2| Öğrenilen bir karar ağacının derinliği, ağacı oluşturmak için kullanılan eğitim örneklerinin sayısından daha büyük olabilir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
Modelinizin aşırı uyum sağladığını varsayalım. Aşağıdakilerden hangisi aşırı uyumu azaltmaya çalışmak için geçerli bir yol DEĞİLDİR?,Eğitim verisi miktarını artırın.,Hata minimizasyonu için kullanılan optimizasyon algoritmasını geliştirin.,Model karmaşıklığını azaltın.,Eğitim verilerindeki gürültüyü azaltın.,B
"Statement 1| Softmax fonksiyonu genellikle çok sınıflı lojistik regresyonda kullanılır. Statement 2| Düzgün olmayan bir softmax dağılımının sıcaklığı, onun entropisini etkiler.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
Aşağıdakilerden hangisi/hangileri SVM (Destek Vektör Makinesi) ile ilgili doğrudur?,"İki boyutlu veri noktaları için, doğrusal bir SVM tarafından öğrenilen ayırıcı hiperdüzlem düz bir çizgi olacaktır.","Teoride, bir Gauss çekirdeği SVM karmaşık herhangi bir ayırıcı hiperdüzlemi modelleyemez.","Her SVM'de kullanılan çekirdek fonksiyonu için, eşdeğer bir kapalı form temel genişlemesi elde edilebilir.","SVM'de aşırı uyum, destek vektörlerinin sayısının bir fonksiyonu değildir.",A
"Aşağıdakilerden hangisi, verilen Bayes Ağı H -> U <- P <- W tarafından tanımlanan H, U, P ve W'nin ortak olasılığıdır? [not: koşullu olasılıkların çarpımı olarak]","P(H, U, P, W) = P(H) * P(W) * P(P) * P(U)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(W | H, P)","P(H, U, P, W) = P(H) * P(W) * P(P | W) * P(U | H, P)",Yukarıdakilerin hiçbiri,C
"İfade 1| VC boyutu Radyal Tabanlı Çekirdekli bir SVM için sonsuz olduğundan, böyle bir SVM, sonlu bir VC boyutuna sahip olan polinom çekirdekli bir SVM'den daha kötü olmalıdır. İfade 2| Doğrusal aktivasyon fonksiyonlarına sahip iki katmanlı bir sinir ağı, esasen belirli bir veri kümesi üzerinde eğitilmiş doğrusal ayırıcıların ağırlıklı bir kombinasyonudur; doğrusal ayırıcılar üzerine kurulu güçlendirme algoritması da doğrusal ayırıcıların bir kombinasyonunu bulur, bu nedenle bu iki algoritma aynı sonucu verecektir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
Statement 1| ID3 algoritması optimal karar ağacını bulmayı garanti eder. Statement 2| Her yerde sıfır olmayan yoğunluğu f() olan sürekli bir olasılık dağılımını düşünün. Bir x değerinin olasılığı f(x)'e eşittir.,"Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
"Giriş düğümü sayısı N olan, gizli katmanı olmayan, bir çıkış düğümü olan, Entropi Kaybı ve Sigmoid Aktivasyon Fonksiyonları kullanan bir Sinir Ağı göz önüne alındığında, aşağıdaki algoritmalardan hangileri (uygun hiper parametreler ve başlangıç değerleri ile) global optimumu bulmak için kullanılabilir?",Rastgele Gradyan İnişi,Mini-Grup Gradyan İnişi,Toplu Gradyan İnişi,Yukarıdakilerin hepsi,D
"Doğrusal bir modelde daha fazla temel fonksiyon eklemek, en olası seçeneği seçin:",Model yanlılığını azaltır,Tahmin yanlılığını azaltır,Varyansı azaltır,Yanlılığı ve varyansı etkilemez,A
"Aşağıda verilen Bayes ağını düşünün. Bağımsızlık veya koşullu bağımsızlık hakkında hiçbir varsayımda bulunmasaydık, H -> U <- P <- W için kaç bağımsız parametreye ihtiyacımız olurdu?",3,4,7,15,D
Dağılım dışı tespiti için başka bir terim nedir?,anomali tespiti,tek sınıf tespiti,eğitim-test uyumsuzluğu sağlamlığı,arka plan tespiti,A
"İfade 1| Zayıf öğrenicileri h güçlendirerek bir sınıflandırıcı f öğreniriz. f'nin karar sınırının işlevsel formu, h'ninki ile aynıdır, ancak farklı parametrelerle. (örneğin, h doğrusal bir sınıflandırıcı ise, f de doğrusal bir sınıflandırıcıdır). İfade 2| Çapraz doğrulama, güçlendirmedeki iterasyon sayısını seçmek için kullanılabilir; bu prosedür aşırı uyumu azaltmaya yardımcı olabilir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",D
İfade 1| Otoyol ağları ResNet'lerden sonra tanıtıldı ve maksimum havuzlama yerine evrişimleri tercih etti. İfade 2| DenseNet'ler genellikle ResNet'lerden daha fazla bellek maliyetine sahiptir.,"Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",D
"Eğer N, eğitim veri kümesindeki örnek sayısı ise, en yakın komşular sınıflandırma çalışma süresi şu kadardır:",O(1),O( N ),O(log N),O( N^2 ),B
"İfade 1| Orijinal ResNet'ler ve Transformerlar ileri beslemeli sinir ağlarıdır. İfade 2| Orijinal Transformerlar öz-dikkat kullanır, ancak orijinal ResNet kullanmaz.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"İfade 1| ReLU'lar monoton değildir, ancak sigmoidler monotondur. İfade 2| Yüksek olasılıkla, gradyan inişi ile eğitilen sinir ağları global optimuma yakınsar.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",D
Bir sinir ağındaki sigmoid düğümünün sayısal çıktısı:,"Sınırsızdır, tüm gerçek sayıları kapsar.","Sınırsızdır, tüm tam sayıları kapsar.",0 ile 1 arasında sınırlıdır.,-1 ve 1 arasında sınırlıdır.,C
Aşağıdakilerden hangisi yalnızca eğitim verileri doğrusal olarak ayrılabilir olduğunda kullanılabilir?,Doğrusal sert marjlı DVM,Doğrusal Lojistik Regresyon,Doğrusal Yumuşak Marjlı DVM,Ağırlık merkezi yöntemi.,A
Aşağıdakilerden hangileri mekansal kümeleme algoritmalarıdır?,Bölümlemeye dayalı kümeleme,K-ortalamalar kümeleme,Izgara tabanlı kümeleme,Yukarıdakilerin hepsi,D
"İfade 1| Destek vektör makinelerinin oluşturduğu maksimum marjlı karar sınırları, tüm doğrusal sınıflandırıcılar arasında en düşük genelleme hatasına sahiptir. İfade 2| Sınıfa bağlı Gauss dağılımları ile bir üretici modelden elde ettiğimiz herhangi bir karar sınırı, prensipte bir SVM ve derecesi üçe eşit veya daha düşük olan bir polinom çekirdeği ile yeniden üretilebilir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",D
"İfade 1| L2 düzenlileştirmesi, doğrusal modellerde L1 düzenlileştirmesine göre modelleri daha seyrek hale getirme eğilimindedir. İfade 2| Artık bağlantılar, ResNet'lerde ve Transformatörlerde bulunabilir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",D
"Diyelim ki P(H|E, F)'yi hesaplamak istiyoruz ve elimizde koşullu bağımsızlık bilgisi yok. Aşağıdaki sayı kümelerinden hangileri hesaplama için yeterlidir?","P(E, F), P(H), P(E|H), P(F|H)","P(E, F), P(H), P(E, F|H)","P(H), P(E|H), P(F|H)","P(E, F), P(E|H), P(F|H)",B
Aşağıdakilerden hangisi bagging yaparken aşırı uyumu (overfitting) önler?,Yerine koyarak örnekleme tekniğinin kullanılması,Zayıf sınıflandırıcıların kullanımı,Aşırı uyuma eğilimli olmayan sınıflandırma algoritmalarının kullanımı,Her eğitilmiş sınıflandırıcı üzerinde gerçekleştirilen doğrulama uygulaması,B
"İfade 1| PCA ve Spektral Kümeleme (Andrew Ng'ninki gibi) iki farklı matris üzerinde özdeğer ayrışımı gerçekleştirir. Ancak, bu iki matrisin boyutu aynıdır. İfade 2| Sınıflandırma, regresyonun özel bir durumu olduğundan, lojistik regresyon doğrusal regresyonun özel bir durumudur.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
"İfade 1| Stanford Duygu Ağacı Bankası film yorumları içeriyordu, kitap yorumları değil. İfade 2| Penn Ağacı Bankası dil modellemesi için kullanılmıştır.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"Aşağıdaki matrisin sıfır uzayının boyutu nedir? A = [[3, 2, −9], [−6, −4, 18], [12, 8, −36]]",0,1,2,3,C
Destek vektörleri nelerdir?,Karar sınırından en uzak örnekler.,Bir SVM'de f(x)'i hesaplamak için gerekli olan tek örnekler.,Veri merkezi.,Bir SVM'de sıfır olmayan ağırlığa (αk) sahip olan tüm örnekler.,B
Statement 1| Word2Vec parametreleri Kısıtlı Boltzman Makinesi kullanılarak başlatılmadı. Statement 2| Tanh fonksiyonu doğrusal olmayan bir aktivasyon fonksiyonudur.,"Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"Eğitim kaybınız epoch sayısı arttıkça artıyorsa, öğrenme sürecinde aşağıdakilerden hangisi olası bir sorun olabilir?",Düzenlileştirme çok düşük ve model aşırı uyum gösteriyor,Düzenlileştirme çok yüksek ve model yetersiz uyum gösteriyor,Adım boyutu çok büyük,Adım boyutu çok küçük,C
"D hastalığının görülme sıklığının 100 kişide yaklaşık 5 vaka olduğunu söyleyin (yani P(D) = 0.05). Boolean rastgele değişken D'nin bir hastanın ""D hastalığına sahip olduğu"" anlamına geldiğini ve Boolean rastgele değişken TP'nin ""pozitif test"" anlamına geldiğini varsayalım. D hastalığı için testlerin, hastalığa sahip olduğunuzda pozitif test verme olasılığının 0.99 ve hastalığa sahip olmadığınızda negatif test verme olasılığının 0.97 olması anlamında çok doğru olduğu bilinmektedir. Test pozitif çıktığında D hastalığına sahip olma olasılığınız olan P(D | TP) nedir?","0,0495","0,078","0,635","0,97",C
"İfade 1| Geleneksel makine öğrenimi sonuçları, eğitim ve test kümelerinin bağımsız ve aynı şekilde dağıtıldığını varsayar. İfade 2| 2017'de, COCO modelleri genellikle ImageNet üzerinde önceden eğitilirdi.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"İfade 1| İki farklı çekirdek K1(x, x0) ve K2(x, x0) tarafından aynı eğitim setinde elde edilen marjin değerleri, hangi sınıflandırıcının test setinde daha iyi performans göstereceğini bize söylemez. İfade 2| BERT'in aktivasyon fonksiyonu GELU'dur.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
Aşağıdakilerden hangisi makine öğreniminde bir kümeleme algoritmasıdır?,Beklenti Maksimizasyonu,SEPET,Gauss Naif Bayes,Apriori,A
"Spam sınıflandırması için bir karar ağacı eğitimini yeni bitirdiniz ve hem eğitim hem de test setlerinizde anormal derecede kötü performans alıyorsunuz. Uygulamanızda hata olmadığını biliyorsunuz, o halde soruna ne neden olabilir?",Karar ağaçlarınız çok sığ.,Öğrenme oranını artırmanız gerekiyor.,Aşırı uyum gösteriyorsun.,Yukarıdakilerin hiçbiri.,A
K-katlı çapraz doğrulama,K'da doğrusal,K'da ikinci dereceden,K'da kübik,K'da üstel,A
İfade 1| Endüstriyel ölçekli sinir ağları normalde GPU'lar yerine CPU'larda eğitilir. İfade 2| ResNet-50 modeli 1 milyardan fazla parametreye sahiptir.,"Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
"İki Boolean rastgele değişken A ve B verildiğinde, P(A) = 1/2, P(B) = 1/3 ve P(A | ¬B) = 1/4 ise, P(A | B) nedir?",1/6,1/4,3/4,1,D
Yapay zeka tarafından oluşturulan varoluşsal riskler en çok hangi profesörlerle ilişkilendirilir?,Nando de Frietas,Yann LeCun,Stuart Russell,Jitendra Malik,C
"İfade 1| Lojistik regresyon modelinin olabilirliğini maksimize etmek, birden fazla yerel optimum noktası ortaya çıkarır. İfade 2| Verinin dağılımı biliniyorsa, hiçbir sınıflandırıcı naive Bayes sınıflandırıcısından daha iyi performans gösteremez.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
"Kernel Regresyonu için, aşağıdakilerden hangisi eksik uyum ve aşırı uyum arasındaki dengeyi en çok etkileyen yapısal varsayımdır:","Çekirdek fonksiyonunun Gauss mu, üçgen mi yoksa kutu şeklinde mi olduğu","Öklid metriği, L1 metriği veya L∞ metriği kullanıp kullanmadığımız",Çekirdek genişliği,Çekirdek fonksiyonunun maksimum yüksekliği,C
"İfade 1| SVM öğrenme algoritması, nesne fonksiyonuna göre global olarak optimal hipotezi bulma garantisi verir. İfade 2| Radyal tabanlı bir çekirdek fonksiyonu aracılığıyla Q özellik uzayına haritalandıktan sonra, bir Perceptron orijinal uzayına göre daha iyi bir sınıflandırma performansı elde edebilir (ancak bunu garanti edemeyiz).","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"Gaussian Bayes sınıflandırıcısı için, aşağıdakilerden hangisi eksik uyum ve aşırı uyum arasındaki dengeyi en çok etkileyen yapısal varsayımdır:",Sınıf merkezlerini Maksimum Olabilirlik veya Gradyan İnişi ile öğrenip öğrenmediğimiz,Tam sınıf kovaryans matrislerini mi yoksa köşegen sınıf kovaryans matrislerini mi varsaydığımıza bakılmaksızın,Eşit sınıf öncelikleri mi yoksa verilerden tahmin edilen öncelikler mi olduğu.,Sınıfların farklı ortalama vektörlere sahip olmasına izin verip vermediğimiz veya onları aynı ortalama vektörü paylaşmaya zorlayıp zorlamadığımız,B
"İfade 1| Aşırı uyum, eğitim veri setinin küçük olduğu durumlarda daha olasıdır. İfade 2| Aşırı uyum, hipotez uzayının küçük olduğu durumlarda daha olasıdır.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",D
"Statement 1| EM'nin yanı sıra, gradyan inişi de Gauss karışım modeli üzerinde çıkarım veya öğrenme gerçekleştirmek için kullanılabilir.

Statement 2 | Sabit sayıda öznitelik varsayıldığında, Gauss tabanlı Bayes optimal sınıflandırıcı, veri kümesindeki kayıt sayısına doğrusal zamanda öğrenilebilir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"İfade 1| Bir Bayes ağında, kavşak ağacı algoritmasının çıkarım sonuçları, değişken eleme yönteminin çıkarım sonuçlarıyla aynıdır. İfade 2| Eğer X ve Y rastgele değişkenleri, başka bir rastgele değişken Z verildiğinde koşullu olarak bağımsızsa, karşılık gelen Bayes ağında X ve Y düğümleri Z verildiğinde d-ayrılmıştır.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",C
"Kalp hastalığı çeken hastalardan oluşan büyük bir tıbbi kayıt veri kümesi göz önüne alındığında, farklı tedaviler uygulayabileceğimiz hasta grupları olup olmadığını öğrenmeye çalışın. Bu ne tür bir öğrenme problemidir?",Gözetimli öğrenme,Gözetimsiz öğrenme,(a) ve (b) seçeneklerinin her ikisi de,Ne (a) ne de (b),B
PCA'da SVD ile aynı izdüşümü elde etmek için ne yapardınız?,Veriyi sıfır ortalamaya dönüştür,Veriyi sıfır medyana dönüştür,Mümkün değil,Bunların hiçbiri,A
"İfade 1| 1-en yakın komşu sınıflandırıcısının eğitim hatası 0'dır. İfade 2| Veri noktalarının sayısı sonsuza yaklaştıkça, MAP tahmini tüm olası önceliklerde MLE tahminini yaklaşır. Başka bir deyişle, yeterli veri olduğunda, öncelik seçimi önemsizdir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",C
"Düzenlileştirme ile en küçük kareler regresyonu yaparken (optimizasyonun tam olarak yapılabileceğini varsayarak), düzenlileştirme parametresi λ'nın değerini artırmak test hatasını.",asla eğitim hatasını azaltmayacaktır.,asla eğitim hatasını artırmayacaktır.,asla test hatasını azaltmayacaktır.,asla artmayacak,A
Aşağıdakilerden hangisi ayrımcı yaklaşımların modellemeye çalıştığını en iyi şekilde tanımlar? (w modeldeki parametrelerdir),"p(y|x, w)","p(y, x)","p(w|x, w)",Yukarıdakilerin hiçbiri,A
"İfade 1| CIFAR-10 sınıflandırma performansı evrişimli sinir ağları için %95'i aşabilir. İfade 2| Sinir ağı toplulukları, öğrendikleri temsiller yüksek oranda ilişkili olduğundan sınıflandırma doğruluğunu iyileştirmez.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",C
Aşağıdaki noktalardan hangisinde Bayesciler ve sıklıkçılar anlaşmazlığa düşerdi?,Olasılıksal regresyonda Gauss dışı bir gürültü modelinin kullanımı.,Regresyon için olasılıksal modellemenin kullanımı.,Olasılıksal bir modelde parametreler üzerindeki öncül dağılımların kullanımı.,Gauss Ayırt Edici Analizinde sınıf önsellerinin kullanımı.,C
"İfade 1| BLEU metriği kesinlik kullanırken, ROGUE metriği geri çağırmayı kullanır. İfade 2| Gizli Markov modelleri sıklıkla İngilizce cümleleri modellemek için kullanılırdı.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"İfade 1| ImageNet çeşitli çözünürlüklerde görüntülere sahiptir. İfade 2| Caltech-101, ImageNet'ten daha fazla görüntüye sahiptir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",C
Aşağıdakilerden hangisi özellik seçimi yapmak için daha uygundur?,Sırt,Kement,hem (a) hem de (b),ne (a) ne de (b),B
"Gizli değişkenleri olan bir model için en yüksek olabilirlik tahminlerini bulan bir EM algoritması verildiğini varsayalım. Bu algoritmayı, bunun yerine MAP tahminlerini bulacak şekilde değiştirmeniz isteniyor. Hangi adımı veya adımları değiştirmeniz gerekiyor?",Beklenti,Maksimizasyon,Değişiklik gerekli değil,İkisi de,B
"Gaussian Bayes sınıflandırıcısı için, aşağıdakilerden hangisi eksik uyum ve aşırı uyum arasındaki dengeyi en çok etkileyen yapısal varsayımdır:",Sınıf merkezlerini Maksimum Olabilirlik veya Gradyan İnişi ile öğrenip öğrenmediğimiz,Tam sınıf kovaryans matrislerini mi yoksa köşegen sınıf kovaryans matrislerini mi varsaydığımıza bakılmaksızın,Eşit sınıf öncelikleri mi yoksa verilerden tahmin edilen öncelikler mi olduğu,Sınıfların farklı ortalama vektörlere sahip olmasına izin verip vermediğimiz veya onları aynı ortalama vektörü paylaşmaya zorlayıp zorlamadığımız,B
"İfade 1| Ortak dağılımı p(x, y) olan herhangi iki x ve y değişkeni için, H entropi fonksiyonu olmak üzere her zaman H[x, y] ≥ H[x] + H[y] eşitsizliği geçerlidir. İfade 2| Bazı yönlendirilmiş grafikler için, ahlakileştirme grafikteki kenar sayısını azaltır.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",B
Aşağıdakilerden hangisi denetimli öğrenme DEĞİLDİR?,PCA,Karar Ağacı,Doğrusal Regresyon,Naif Bayesçi,A
"İfade 1| Bir sinir ağının yakınsaması öğrenme oranına bağlıdır. İfade 2| Dropout, rastgele seçilen aktivasyon değerlerini sıfırla çarpar.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"Aşağıdakilerden hangisi, Boolean rastgele değişkenler A, B ve C verildiğinde ve aralarında herhangi bir bağımsızlık veya koşullu bağımsızlık varsayımı olmadığında P(A, B, C)'ye eşittir?",P(A | B) * P(B | C) * P(C | A),"P(C | A, B) * P(A) * P(B)","P(A, B | C) * P(C)","P(A | B, C) * P(B | A, C) * P(C | A, B)",C
Aşağıdaki görevlerden hangisi Kümeleme kullanılarak en iyi şekilde çözülebilir?,Çeşitli ipuçlarına dayanarak yağış miktarını tahmin etme,Sahte kredi kartı işlemlerini tespit etme,Bir robotu labirent çözmeye eğitmek,Yukarıdakilerin hepsi,B
"Doğrusal regresyonda bir düzenlileştirme cezası uyguladıktan sonra, w katsayılarının bazılarının sıfırlandığını görüyorsunuz. Aşağıdaki cezalardan hangisi kullanılmış olabilir?",L0 normu,L1 normu,L2 normu,ya (a) ya da (b),D
"A ve B iki olaydır. Eğer P(A, B) azalırken P(A) artıyorsa, aşağıdakilerden hangisi doğrudur?",P(A|B) azalır,P(B|A) azalır,P(B) azalır,Yukarıdakilerin hepsi,B
"İfade 1| Sabit bir gözlem kümesi için bir HMM öğrenirken, gerçek gizli durum sayısını bilmediğimizi varsayarsak (ki bu genellikle durumdur), daha fazla gizli duruma izin vererek eğitim verisi olasılığını her zaman artırabiliriz. İfade 2| İşbirlikçi filtreleme, genellikle kullanıcıların film tercihlerini modellemek için yararlı bir modeldir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
"Basit bir tahmin görevi için doğrusal regresyon modeli eğitiyorsunuz ve modelin veriye aşırı uyum sağladığını fark ediyorsunuz. Ağırlıkları cezalandırmak için $\ell_2$ düzenlileştirmesi eklemeye karar veriyorsunuz. $\ell_2$ düzenlileştirme katsayısını artırdıkça, modelin yanlılığı ve varyansı ne olacak?",Yanlılık artışı ; Varyans artışı,Yanlılık artışı ; Varyans azalması,Yanlılık azalması; Varyans artışı,Yanlılık azalması ; Varyans azalması,B
"PyTorch 1.8'de hangi komut(lar) her bir girişi $\mathcal{N}(\mu=5,\sigma^2=16)$ dağılımından bağımsız ve özdeş olarak örneklenmiş $10\times 5$ boyutunda bir Gauss matrisi ve her bir girişi $U[-1,1)$ dağılımından bağımsız ve özdeş olarak örneklenmiş $10\times 10$ boyutunda bir düzgün dağılımlı matris üretir?","\texttt{5 + torch.randn(10,5) * 16} ; \texttt{torch.rand(10,10,low=-1,high=1)}","\texttt{5 + torch.randn(10,5) * 16} ; \texttt{(torch.rand(10,10) - 0.5) / 0.5}","\texttt{5 + torch.randn(10,5) * 4} ; \texttt{2 * torch.rand(10,10) - 1}","\texttt{torch.normal(torch.ones(10,5)*5,torch.ones(5,5)*16)} ; \texttt{2 * torch.rand(10,10) - 1}",C
İfade 1| ReLU'nun gradyanı $x<0$ için sıfırdır ve sigmoid gradyanı $\sigma(x)(1-\sigma(x))\le \frac{1}{4}$ tüm $x$ değerleri için geçerlidir. İfade 2| Sigmoid sürekli bir gradyana sahipken ReLU süreksiz bir gradyana sahiptir.,"Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",A
Yığın Normalleştirmesi hakkında hangisi doğrudur?,"Toplu normalizasyon uygulandıktan sonra, katmanın aktivasyonları standart bir Gauss dağılımını takip edecektir.","Eğer hemen ardından bir toplu normalizasyon katmanı geliyorsa, afin katmanların yanlılık parametresi gereksiz hale gelir.",Toplu Normalizasyon kullanırken standart ağırlık başlatma yöntemi değiştirilmelidir.,"Evrişimli sinir ağları için Toplu Normalizasyon, Katman Normalizasyonuna eşdeğerdir.",B
Aşağıdaki amaç fonksiyonuna sahip olduğumuzu varsayalım: $\argmin_{w} \frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\gamma \norm{w}^2_2$ $\frac{1}{2} \norm{Xw-y}^2_2 + \frac{1}{2}\lambda \norm{w}^2_2$ ifadesinin $w$'ye göre gradyanı nedir?,$\nabla_w f(w) = (X^\top X + \lambda I)w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda$,$\nabla_w f(w) = X^\top X w - X^\top y + \lambda w$,$\nabla_w f(w) = X^\top X w - X^\top y + (\lambda+1) w$,C
Aşağıdakilerden hangisi bir evrişim çekirdeği için doğrudur?,Bir görüntüyü $\begin{bmatrix}1 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 1 \end{bmatrix}$ ile konvolüsyona tabi tutmak görüntüyü değiştirmeyecektir,Bir görüntüyü $\begin{bmatrix}0 & 0 & 0\\ 0 & 1 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ ile konvolüsyona tabi tutmak görüntüyü değiştirmeyecektir,Bir görüntüyü $\begin{bmatrix}1 & 1 & 1\\ 1 & 1 & 1 \\ 1 & 1 & 1 \end{bmatrix}$ ile konvolüsyona tabi tutmak görüntüyü değiştirmeyecektir,Bir görüntüyü $\begin{bmatrix}0 & 0 & 0\\ 0 & 0 & 0 \\ 0 & 0 & 0 \end{bmatrix}$ ile konvolüsyona tabi tutmak görüntüyü değiştirmeyecektir,B
Aşağıdakilerden hangisi yanlıştır?,"Anlamsal bölütleme modelleri her pikselin sınıfını tahmin ederken, çok sınıflı görüntü sınıflandırıcıları tüm görüntünün sınıfını tahmin eder.",IoU (kesişim bölünü birleşim) değeri %96'ya eşit olan bir sınırlayıcı kutu muhtemelen gerçek pozitif olarak kabul edilecektir.,"Tahmin edilen bir sınırlayıcı kutu, sahnedeki herhangi bir nesneye karşılık gelmediğinde, bu yanlış pozitif olarak kabul edilir.",IoU (kesişim bölünü birleşim) değeri %3'e eşit olan bir sınırlayıcı kutu muhtemelen yanlış negatif olarak kabul edilecektir.,D
Aşağıdakilerden hangisi yanlıştır?,"Aşağıdaki aktivasyon fonksiyonları olmayan tam bağlantılı ağ doğrusaldır: $g_3(g_2(g_1(x)))$, burada $g_i(x) = W_i x$ ve $W_i$ matrislerdir.","Sızıntılı ReLU $\max\{0.01x,x\}$ konvekstir.",ReLU'ların $ReLU(x) - ReLU(x-1)$ gibi bir kombinasyonu konvekstir.,Kayıp $\log \sigma(x)= -\log(1+e^{-x})$ içbükeydir,C
"Tam bağlantılı iki gizli katmanlı bir ağı konut fiyatlarını tahmin etmek için eğitiyoruz. Girişler $100$ boyutludur ve metrekare sayısı, ortalama aile geliri gibi çeşitli özelliklere sahiptir. İlk gizli katman $1000$ aktivasyona sahiptir. İkinci gizli katman $10$ aktivasyona sahiptir. Çıktı, ev fiyatını temsil eden bir skalerdir. Afin dönüşümlere sahip sıradan bir ağ varsayarak ve aktivasyon fonksiyonunda toplu normalizasyon ve öğrenilebilir parametre olmadığını kabul ederek, bu ağın kaç parametresi vardır?",111021,110010,111110,110011,A
"İfade 1| Sigmoid $\sigma(x)=(1+e^{-x})^{-1}$'in $x$'e göre türevi, $B\sim \text{Bern}(\sigma(x))$ bir Bernoulli rastgele değişkeni olmak üzere $\text{Var}(B)$'ye eşittir. İfade 2| Sinir ağının her katmanındaki bias parametrelerini 0'a ayarlamak, bias-varyans dengesini modelin varyansını artıracak ve modelin biasını azaltacak şekilde değiştirir.","Doğru, Doğru","Yanlış, Yanlış","Doğru, Yanlış","Yanlış, Doğru",C
